# views.py
import datetime
import shutil
import os
import re
from io import BytesIO
from collections import OrderedDict

import pandas as pd
import numpy as np
from django.conf import settings
from django.contrib import messages
from django.shortcuts import render, redirect, get_object_or_404
from django.http import JsonResponse, HttpResponse
from django.views import View
from .forms import ExcelUploadForm
from django.core.cache import cache

from django.views.decorators.cache import cache_control
import json, traceback, os
from datetime import date
from django.db.models import Q
from django.template.loader import render_to_string
from calendar import month_abbr, month_name
import calendar as calendar_module

from django.views.decorators.csrf import csrf_exempt
from django.utils.decorators import method_decorator
from django.utils.text import slugify

from .models import MeetingPoint
from . import context_helpers


def make_json_serializable(df):

    def convert_value(x):
        if isinstance(x, (pd.Timestamp, pd.Timedelta)):
            return x.isoformat()
        elif isinstance(x, (datetime.datetime, datetime.date, datetime.time)):
            return x.isoformat()
        elif isinstance(x, (np.int64, np.int32)):
            return int(x)
        elif isinstance(x, (np.float64, np.float32)):
            return float(x)
        elif isinstance(x, (np.ndarray, list, dict)):
            return str(x)
        else:
            return x

    return df.applymap(convert_value)


def _sanitize_for_json(obj):
    """Convert numpy/pandas types to native Python for JsonResponse."""
    if obj is None or isinstance(obj, (bool, str)):
        return obj
    if isinstance(obj, np.ndarray):
        return [_sanitize_for_json(v) for v in obj.tolist()]
    if isinstance(obj, (np.integer, np.int64, np.int32)):
        return int(obj)
    if isinstance(obj, (np.floating, np.float64, np.float32)):
        try:
            v = float(obj)
            if np.isnan(v) or np.isinf(v):
                return None
            return v
        except (ValueError, TypeError):
            return None
    if isinstance(obj, (pd.Timestamp, pd.Timedelta, datetime.datetime, datetime.date)):
        return obj.isoformat() if hasattr(obj, "isoformat") else str(obj)
    if isinstance(obj, (int, float)) and (obj != obj or abs(obj) == float("inf")):
        return None  # NaN or Inf
    try:
        if pd.isna(obj) and not isinstance(obj, (dict, list, tuple)):
            return None
    except (ValueError, TypeError):
        pass
    if isinstance(obj, dict):
        return {k: _sanitize_for_json(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple)):
        return [_sanitize_for_json(v) for v in obj]
    return obj


def _get_excel_path_for_request(request):
    """ÙŠØ±Ø¬Ø¹ Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„ Ø§Ù„Ù…Ø±ÙÙˆØ¹ Ù…Ù† Ø§Ù„Ø¬Ù„Ø³Ø© Ø£Ùˆ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ."""
    if not request:
        return None
    folder = os.path.join(settings.MEDIA_ROOT, "excel_uploads")
    if not os.path.isdir(folder):
        return None
    path = request.session.get("uploaded_excel_path")
    if path and os.path.isfile(path):
        return path
    for name in ["latest.xlsm", "latest.xlsx", "all sheet.xlsm", "all sheet.xlsx", "all_sheet.xlsm", "all_sheet.xlsx"]:
        p = os.path.join(folder, name)
        if os.path.isfile(p):
            return p
    return None


# Ø§Ø³Ù… Ù…Ù„Ù Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø§Ù„Ø«Ø§Ø¨Øª (Ø´ÙŠØª ØªØ§Ù†ÙŠ Ù„Ù„ØªØ§Ø¨ Dashboard ÙÙ‚Ø·)
DASHBOARD_EXCEL_FILENAME = "Aramco_Tamer3PL_KPI_Dashboard.xlsx"

# Ø¯Ø§ØªØ§ Inbound Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© (Ù„Ù„ÙƒØ±ÙˆØª ÙˆØ§Ù„Ø´Ø§Ø±Øª) â€” Ù†ÙØ³ ÙÙƒØ±Ø© chart_data ÙÙŠ rejection
INBOUND_DEFAULT_KPI = {
    "number_of_vehicles": 12,
    "number_of_shipments": 287,
    "number_of_pallets": 1105,
    "total_quantity": 65400,
    "total_quantity_display": "65.4k",
}
# Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„Ù„ÙŠ Ø¨ØªØ¸Ù‡Ø± Ø¹Ù„Ù‰ Ø´Ø§Ø±Øª Pending Shipments (label, value, pct, color)
INBOUND_DEFAULT_PENDING_SHIPMENTS = [
    {"label": "In Transit", "value": "1%", "pct": 1, "color": "#87CEEB"},
    {"label": "Receiving Complete", "value": "96%", "pct": 96, "color": "#2E7D32"},
    {"label": "Verified", "value": "3%", "pct": 3, "color": "#1565C0"},
]

# Ø¯Ø§ØªØ§ Ø§Ù„Ø´Ø§Ø±ØªØ§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ (Ù†ÙØ³ ÙÙƒØ±Ø© chart_data ÙÙŠ rejection â€” Ù„Ùˆ Ù…ÙÙŠØ´ Ø¥ÙƒØ³Ù„ Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§)
DASHBOARD_DEFAULT_CHART_DATA = {
    "outbound_chart_data": {
        "categories": ["Jan", "Feb", "Mar", "Apr", "May", "Jun"],
        "series": [40, 55, 48, 62, 58, 70],
    },
    "returns_chart_data": {
        "categories": ["Mar", "Apr", "May", "Jun", "Jul", "Aug"],
        "series": [280, 320, 300, 350, 380, 400],
    },
    "inventory_capacity_data": {"used": 78, "available": 22},
}


def _read_dashboard_charts_from_excel(excel_path):
    """
    ÙŠÙ‚Ø±Ø£ Ø¯Ø§ØªØ§ Ø§Ù„Ø´Ø§Ø±ØªØ§Øª (Outbound, Returns, Inventory) Ù…Ù† Ù…Ù„Ù Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù„Ùˆ Ø§Ù„Ø´ÙŠØªØ§Øª Ù…ÙˆØ¬ÙˆØ¯Ø©.
    ØªØ±Ø¬Ø¹ Ø¯ÙŠÙƒØª Ø¨Ø§Ù„Ù„ÙŠ Ø§ØªÙ‚Ø±Ø§ ÙÙ‚Ø· (Ù„Ùˆ Ù…ÙÙŠØ´ Ø¯Ø§ØªØ§ Ù„Ù„Ø´Ø§Ø±Øª ØªØ±Ø¬Ø¹ None Ù„Ù„ÙƒØ§ÙŠ) â€” Ø¹Ø´Ø§Ù† Ù†Ø¹Ù…Ù„ Ø§Ù„Ø´Ø§Ø±ØªØ§Øª Ø¯ÙŠÙ†Ø§Ù…Ùƒ.
    """
    result = {}
    try:
        xls = pd.ExcelFile(excel_path, engine="openpyxl")
    except Exception:
        return result
    sheet_names = [str(s).strip() for s in xls.sheet_names]

    # Outbound: Ù…Ù† Ø´ÙŠØª Outbound_Data Ø£Ùˆ Outbound â€” ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø´Ù‡Ø± Ù„Ùˆ ÙÙŠÙ‡ Ø¹Ù…ÙˆØ¯ Ø´Ù‡Ø±/ØªØ§Ø±ÙŠØ®
    for out_name in ["Outbound_Data", "Outbound Data", "Outbound"]:
        if not any(out_name.lower().replace(" ", "") in s.lower().replace(" ", "") for s in sheet_names):
            continue
        sheet_name = next((s for s in sheet_names if out_name.lower() in s.lower()), None)
        if not sheet_name:
            continue
        try:
            df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl", header=0)
            if df.empty or len(df) < 2:
                break
            df.columns = [str(c).strip() for c in df.columns]
            cols_lower = {c.lower(): c for c in df.columns}
            month_col = None
            for c in cols_lower:
                if "month" in c or "date" in c:
                    month_col = cols_lower[c]
                    break
            if month_col:
                df["_m"] = pd.to_datetime(df[month_col], errors="coerce").dt.strftime("%b")
                by_month = df.groupby("_m").size().reindex(
                    ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]
                ).dropna()
                if not by_month.empty:
                    result["outbound_chart_data"] = {
                        "categories": by_month.index.tolist(),
                        "series": by_month.values.tolist(),
                    }
            break
        except Exception:
            break

    # Returns: Ù…Ù† Ø´ÙŠØª Return Ø£Ùˆ Rejection
    for ret_name in ["Return", "Rejection", "Returns"]:
        sheet_name = next((s for s in sheet_names if ret_name.lower() in s.lower()), None)
        if not sheet_name:
            continue
        try:
            df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl", header=0)
            if df.empty or len(df) < 2:
                break
            df.columns = [str(c).strip() for c in df.columns]
            month_col = next((c for c in df.columns if "month" in c.lower()), None)
            val_col = next(
                (c for c in df.columns if "order" in c.lower() or "booking" in c.lower() or "count" in c.lower()),
                df.columns[1] if len(df.columns) > 1 else None,
            )
            if month_col and val_col:
                summary = df[[month_col, val_col]].dropna()
                if not summary.empty:
                    try:
                        summary[val_col] = pd.to_numeric(summary[val_col].astype(str).str.replace("%", "", regex=False), errors="coerce")
                        summary = summary.dropna(subset=[val_col])
                        categories = summary[month_col].astype(str).tolist()
                        series = summary[val_col].astype(int).tolist()
                        if categories and series:
                            result["returns_chart_data"] = {"categories": categories, "series": series}
                    except Exception:
                        pass
            break
        except Exception:
            break

    # Inventory capacity: Ù…Ù† Ø´ÙŠØª Inventory Ø£Ùˆ Capacity
    for inv_name in ["Inventory", "Capacity", "Warehouse"]:
        sheet_name = next((s for s in sheet_names if inv_name.lower() in s.lower()), None)
        if not sheet_name:
            continue
        try:
            df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl", header=0)
            if df.empty:
                break
            df.columns = [str(c).strip() for c in df.columns]
            used_col = next((c for c in df.columns if "used" in c.lower() or "utilization" in c.lower()), None)
            if used_col:
                vals = pd.to_numeric(df[used_col], errors="coerce").dropna()
                if len(vals) > 0:
                    used = int(min(100, max(0, vals.mean())))
                    result["inventory_capacity_data"] = {"used": used, "available": 100 - used}
            break
        except Exception:
            break

    return result


def _get_dashboard_excel_path(request):
    """
    ÙŠØ±Ø¬Ù‘Ø¹ Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø¥ÙƒØ³Ù„ Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ (Aramco_Tamer3PL_KPI_Dashboard.xlsx) Ø¥Ù† ÙˆÙØ¬Ø¯.
    Ù…ØµØ¯Ø± Ø§Ù„Ø¯Ø§ØªØ§ Ù„ØªØ§Ø¨ Dashboard ÙÙ‚Ø·Ø› Ø¨Ø§Ù‚ÙŠ Ø§Ù„ØªØ§Ø¨Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (all_sheet / latest).
    """
    if not request:
        return None
    folder = os.path.join(settings.MEDIA_ROOT, "excel_uploads")
    path = request.session.get("dashboard_excel_path")
    if path and os.path.isfile(path):
        return path
    p = os.path.join(folder, DASHBOARD_EXCEL_FILENAME)
    if os.path.isfile(p):
        try:
            request.session["dashboard_excel_path"] = p
            request.session.save()
        except Exception:
            pass
        return p
    return None


def _is_dashboard_excel_filename(name):
    """ÙŠØ¹Ø±Ù Ø¥Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹ Ù‡Ùˆ Ù…Ù„Ù Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ (Ø´ÙŠØª ØªØ§Ù†ÙŠ)."""
    if not name:
        return False
    n = (name or "").strip().lower()
    return "kpi_dashboard" in n or "aramco_tamer3pl" in n


def _read_inbound_data_from_excel(excel_path):
    """
    ÙŠÙ‚Ø±Ø£ Ø¨ÙŠØ§Ù†Ø§Øª Inbound (KPI + Pending Shipments) Ù…Ù† Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„.
    Ø§Ù„Ø´ÙŠØª: "Inbound" Ø£Ùˆ Ø£ÙˆÙ„ Ø´ÙŠØª Ø§Ø³Ù…Ù‡ ÙŠØ­ØªÙˆÙŠ "inbound".
    Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù€ KPI (Ø­Ø³Ø¨ Ø§Ù„Ø·Ù„Ø¨):
    - Vehicle_ID: ÙƒÙ„ ÙŠÙˆÙ… Ø¨ÙŠÙˆÙ…Ù‡ Ù†Ø´ÙŠÙ„ Ø§Ù„Ù…ØªÙƒØ±Ø± (unique per day) Ø«Ù… Ù†Ø¬Ù…Ø¹ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª Ù„ÙƒÙ„ Ø§Ù„Ø£ÙŠØ§Ù… â†’ Number of Vehicles
    - Shipment_ID: Ù†ÙØ³ Ø§Ù„Ù…Ù†Ø·Ù‚ ÙŠÙˆÙ… Ø¨ÙŠÙˆÙ… unique Ø«Ù… Ø¬Ù…Ø¹ â†’ Number of Shipments
    - Nbr_LPNs: Ù…Ø¬Ù…ÙˆØ¹ ÙƒÙ„ Ø§Ù„Ù‚ÙŠÙ… (27+18+13+...) â†’ Number of Pallets (LPNs)
    - Total_Qty: Ù…Ø¬Ù…ÙˆØ¹ ÙƒÙ„ Ø§Ù„Ù‚ÙŠÙ… â†’ Total Quantity
    Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ®: Ø£ÙŠ Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù…Ù‡ ÙŠØ­ØªÙˆÙŠ date/receipt/shipment date (Ù„Ù„ØªØ¬Ù…ÙŠØ¹ ÙŠÙˆÙ… Ø¨ÙŠÙˆÙ…).
    Ø¥Ù† Ù„Ù… ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ ØªØ§Ø±ÙŠØ®ØŒ Ù†Ø¹ØªØ¨Ø± ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯.
    Pending Shipments: Ø¥Ù† ÙˆÙØ¬Ø¯Øª Ø£Ø¹Ù…Ø¯Ø© Label/Status, Value, Pct, Color ÙÙŠ Ù†ÙØ³ Ø§Ù„Ø´ÙŠØª Ø£Ùˆ Ø´ÙŠØª Ø¢Ø®Ø± Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§.
    """
    try:
        xls = pd.ExcelFile(excel_path, engine="openpyxl")
    except Exception:
        return None
    sheet_name = None
    for name in xls.sheet_names:
        if "inbound" in name.lower():
            sheet_name = name
            break
    if not sheet_name:
        sheet_name = xls.sheet_names[0] if xls.sheet_names else None
    if not sheet_name:
        return None
    try:
        df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl", header=0)
    except Exception:
        return None
    if df.empty or len(df) < 1:
        return None

    # ØªØ·Ø¨ÙŠØ¹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: strip + lower Ù„Ù„Ø¨Ø­Ø«
    df.columns = [str(c).strip() for c in df.columns]
    cols_lower = {c.lower(): c for c in df.columns if c}

    def _col(*keys):
        for k in keys:
            if k.lower() in cols_lower:
                return cols_lower[k.lower()]
        return None

    # Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ® (Ù„Ù„ØªØ¬Ù…ÙŠØ¹ ÙŠÙˆÙ… Ø¨ÙŠÙˆÙ…)
    date_col = None
    for c in df.columns:
        cl = c.lower()
        if "date" in cl or "receipt" in cl or ("shipment" in cl and "date" in cl) or cl == "day":
            date_col = c
            break
    if not date_col and df.columns.size > 0:
        for c in df.columns:
            try:
                pd.to_datetime(df[c].dropna().head(20), errors="coerce")
                date_col = c
                break
            except Exception:
                continue

    vehicle_col = _col("Vehicle_ID", "Vehicle ID", "Vehicle_ID")
    shipment_col = _col("Shipment_ID", "Shipment ID", "Shipment_ID")
    lpn_col = _col("Nbr_LPNs", "Nbr LPNs", "LPNs")
    qty_col = _col("Total_Qty", "Total_Qty", "Total Qty", "Total_Qty")

    def _to_int(val):
        if val is None or (isinstance(val, float) and pd.isna(val)):
            return None
        try:
            return int(float(val))
        except (ValueError, TypeError):
            return None

    n_vehicles = 0
    n_shipments = 0
    n_pallets = 0
    n_qty = 0

    if date_col and (vehicle_col or shipment_col):
        # ØªØ¬Ù…ÙŠØ¹ ÙŠÙˆÙ… Ø¨ÙŠÙˆÙ…
        df_date = df.copy()
        df_date["_date"] = pd.to_datetime(df_date[date_col], errors="coerce")
        df_date = df_date.dropna(subset=["_date"])
        df_date["_day"] = df_date["_date"].dt.normalize()

        if vehicle_col:
            # ÙƒÙ„ ÙŠÙˆÙ…: Ø¹Ø¯Ø¯ Ø§Ù„Ù€ Vehicle_ID Ø§Ù„Ù…Ù…ÙŠØ²Ø©ØŒ Ø«Ù… Ù†Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø£ÙŠØ§Ù…
            per_day_vehicles = df_date.groupby("_day")[vehicle_col].nunique()
            n_vehicles = int(per_day_vehicles.sum())
        if shipment_col:
            # ÙƒÙ„ ÙŠÙˆÙ…: Ø¹Ø¯Ø¯ Ø§Ù„Ù€ Shipment_ID Ø§Ù„Ù…Ù…ÙŠØ²Ø©ØŒ Ø«Ù… Ù†Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø£ÙŠØ§Ù…
            per_day_shipments = df_date.groupby("_day")[shipment_col].nunique()
            n_shipments = int(per_day_shipments.sum())
    else:
        # Ø¨Ø¯ÙˆÙ† ØªØ§Ø±ÙŠØ®: Ù†Ø¹ØªØ¨Ø± ÙƒÙ„ Ø§Ù„ØµÙÙˆÙ ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯ (unique Ù„Ù„Ù…Ø±ÙƒØ¨Ø§Øª ÙˆØ§Ù„Ø´Ø­Ù†Ø§Øª)
        if vehicle_col:
            n_vehicles = int(df[vehicle_col].nunique())
        if shipment_col:
            n_shipments = int(df[shipment_col].nunique())

    if lpn_col:
        n_pallets = _to_int(df[lpn_col].sum()) or 0
    if qty_col:
        n_qty = _to_int(df[qty_col].sum()) or 0

    # Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ùˆ Ù…ÙÙŠØ´ Ø£Ø¹Ù…Ø¯Ø© Ù…Ù†Ø§Ø³Ø¨Ø©
    if not vehicle_col:
        n_vehicles = 12
    if not shipment_col:
        n_shipments = 287
    if not lpn_col:
        n_pallets = 1105
    if not qty_col:
        n_qty = 65400

    if n_qty >= 1000:
        qty_display = f"{n_qty / 1000:.1f}k".rstrip("0").rstrip(".")
        if not qty_display.endswith("k"):
            qty_display += "k"
    else:
        qty_display = str(n_qty)

    inbound_kpi = {
        "number_of_vehicles": n_vehicles,
        "number_of_shipments": n_shipments,
        "number_of_pallets": n_pallets,
        "total_quantity": n_qty,
        "total_quantity_display": qty_display,
    }

    # Pending Shipments: Ù…Ù† Ø¹Ù…ÙˆØ¯ Status ÙÙŠ Ù†ÙØ³ Ø´ÙŠØª Inbound â€” In Transit, Receiving Complete, Verified
    # ÙŠÙˆÙ… Ø¨ÙŠÙˆÙ… Ù†Ø¬Ù…Ø¹ Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø­Ù†Ø§Øª Ù„ÙƒÙ„ Ø­Ø§Ù„Ø© Ø«Ù… Ù†Ø¬Ù…Ø¹ Ø§Ù„ØªÙˆØªØ§Ù„ØŒ Ø«Ù… Ø§Ù„Ù†Ø³Ø¨Ø© = (Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø§Ù„Ø© / Ø§Ù„ØªÙˆØªØ§Ù„) * 100
    pending = []
    status_col = _col("Status", "status")
    STATUS_LABELS = (
        ("in transit", "In Transit", "#87CEEB"),
        ("receiving complete", "Receiving Complete", "#2E7D32"),
        ("verified", "Verified", "#1565C0"),
    )
    if status_col:
        df_status = df.copy()
        # ØªØ·Ø¨ÙŠØ¹ Status: Ø­Ø±ÙˆÙ ØµØºÙŠØ±Ø© + Ø¥Ø²Ø§Ù„Ø© Ù…Ø³Ø§ÙØ§Øª Ø²Ø§Ø¦Ø¯Ø© Ù„ØªØ­Ù…Ù„ Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„ÙƒØªØ§Ø¨Ø©
        s = df_status[status_col].fillna("").astype(str).str.strip().str.lower()
        df_status["_status_norm"] = s.str.replace(r"\s+", " ", regex=True)
        if date_col:
            df_status["_date"] = pd.to_datetime(df_status[date_col], errors="coerce")
            df_status = df_status.dropna(subset=["_date"])
            df_status["_day"] = df_status["_date"].dt.normalize()
            # ÙƒÙ„ ÙŠÙˆÙ…: Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ (Ø´Ø­Ù†Ø§Øª) Ù„ÙƒÙ„ Ø­Ø§Ù„Ø©ØŒ Ø«Ù… Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø£ÙŠØ§Ù…
            count_in_transit = 0
            count_receiving_complete = 0
            count_verified = 0
            for _day, grp in df_status.groupby("_day"):
                count_in_transit += (grp["_status_norm"] == "in transit").sum()
                count_receiving_complete += (grp["_status_norm"] == "receiving complete").sum()
                count_verified += (grp["_status_norm"] == "verified").sum()
        else:
            count_in_transit = (df_status["_status_norm"] == "in transit").sum()
            count_receiving_complete = (df_status["_status_norm"] == "receiving complete").sum()
            count_verified = (df_status["_status_norm"] == "verified").sum()
        total_pending = count_in_transit + count_receiving_complete + count_verified
        if total_pending > 0:
            for key, label, color in STATUS_LABELS:
                if key == "in transit":
                    c = count_in_transit
                elif key == "receiving complete":
                    c = count_receiving_complete
                else:
                    c = count_verified
                pct = round((c / total_pending) * 100)
                pending.append({
                    "label": label,
                    "value": f"{pct}%",
                    "pct": pct,
                    "color": color,
                })
    if not pending:
        pending = [
            {"label": "In Transit", "value": "1%", "pct": 1, "color": "#87CEEB"},
            {"label": "Receiving Complete", "value": "96%", "pct": 96, "color": "#2E7D32"},
            {"label": "Verified", "value": "3%", "pct": 3, "color": "#1565C0"},
        ]

    return {"inbound_kpi": inbound_kpi, "pending_shipments": pending}


def _read_outbound_data_from_excel(excel_path):
    """
    ÙŠÙ‚Ø±Ø£ Ø¨ÙŠØ§Ù†Ø§Øª Outbound Ù…Ù† Ø´ÙŠØª Outbound_Data ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯.
    - Ø¹Ù…ÙˆØ¯ Status: Ù†ÙÙ„ØªØ± "Released" â†’ released_ordersØŒ "Picked" â†’ picked_orders
    - Ø¹Ù…ÙˆØ¯ Order_ID: Ù†Ø­Ø°Ù Ø§Ù„Ù…ØªÙƒØ±Ø± (unique) ÙˆÙ†Ø­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ù„ÙƒÙ„ Ø­Ø§Ù„Ø©
    """
    try:
        xls = pd.ExcelFile(excel_path, engine="openpyxl")
    except Exception:
        return None
    sheet_name = None
    for name in xls.sheet_names:
        if "outbound_data" in name.lower().replace(" ", "").replace("_", ""):
            sheet_name = name
            break
    if not sheet_name:
        for name in xls.sheet_names:
            if "outbound" in name.lower():
                sheet_name = name
                break
    if not sheet_name:
        return None
    try:
        df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl", header=0)
    except Exception:
        return None
    if df.empty or len(df) < 1:
        return None

    df.columns = [str(c).strip() for c in df.columns]
    cols_lower = {c.lower(): c for c in df.columns if c}

    def _col(*keys):
        for k in keys:
            k_norm = k.lower().replace(" ", "").replace("_", "")
            for col in cols_lower:
                if col.replace(" ", "").replace("_", "") == k_norm:
                    return cols_lower[col]
            if k.lower() in cols_lower:
                return cols_lower[k.lower()]
        return None

    status_col = _col("Status", "status")
    order_col = _col("Order_ID", "Order ID", "Order_ID", "OrderID")
    if not status_col or not order_col:
        return None

    # ØªØ·Ø¨ÙŠØ¹ Status Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    s = df[status_col].fillna("").astype(str).str.strip().str.lower()
    df["_status_norm"] = s.str.replace(r"\s+", " ", regex=True)

    released_mask = df["_status_norm"] == "released"
    picked_mask = df["_status_norm"] == "picked"

    released_orders = 0
    picked_orders = 0
    if released_mask.any():
        released_orders = df.loc[released_mask, order_col].dropna().astype(str).str.strip().nunique()
    if picked_mask.any():
        picked_orders = df.loc[picked_mask, order_col].dropna().astype(str).str.strip().nunique()

    return {
        "released_orders": int(released_orders),
        "picked_orders": int(picked_orders),
    }


def _read_pods_data_from_excel(excel_path):
    """
    ÙŠÙ‚Ø±Ø£ Ù…Ù† Ø´ÙŠØª PODs_Data: Ø¹Ù…ÙˆØ¯ POD_Status (On Time, Pending, Late)ØŒ
    Delivery_Date Ù„Ù„Ø´Ù‡ÙˆØ±ØŒ POD_ID Ù„Ù„Ø¹Ø¯Ø¯. ÙŠØ±Ø¬Ù‘Ø¹ Ø¯Ø§ØªØ§ Ù„Ø´Ø§Ø±Øª Ø®Ø·: ÙƒÙ„ Ø´Ù‡Ø± ÙˆÙ†Ø³Ø¨Ø© ÙƒÙ„ Ø­Ø§Ù„Ø© %.
    """
    try:
        xls = pd.ExcelFile(excel_path, engine="openpyxl")
    except Exception:
        return None
    sheet_name = None
    for name in xls.sheet_names:
        n = str(name).strip().lower().replace(" ", "").replace("_", "")
        if "podsdata" in n or "pods_data" in n or (n == "pods" and "data" in n):
            sheet_name = name
            break
    if not sheet_name:
        for name in xls.sheet_names:
            if "pod" in str(name).lower():
                sheet_name = name
                break
    if not sheet_name:
        return None
    try:
        df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl", header=0)
    except Exception:
        return None
    if df.empty or len(df) < 1:
        return None

    df.columns = [str(c).strip() for c in df.columns]
    cols_lower = {c.lower(): c for c in df.columns if c}

    def _col(*keys):
        for k in keys:
            k_norm = k.lower().replace(" ", "").replace("_", "")
            for col in cols_lower:
                if col.replace(" ", "").replace("_", "") == k_norm:
                    return cols_lower[col]
            if k.lower() in cols_lower:
                return cols_lower[k.lower()]
        return None

    status_col = _col("POD_Status", "POD Status", "PODStatus")
    date_col = _col("Delivery_Date", "Delivery Date", "DeliveryDate", "Date")
    pod_id_col = _col("POD_ID", "POD ID", "PODID")
    if not status_col or not date_col:
        return None
    if not pod_id_col:
        pod_id_col = df.columns[0]

    s = df[status_col].fillna("").astype(str).str.strip().str.lower()
    df["_status_norm"] = s.str.replace(r"\s+", " ", regex=True)
    valid_statuses = {"on time", "pending", "late"}
    df = df[df["_status_norm"].isin(valid_statuses)].copy()
    if df.empty:
        return None

    df["_date"] = pd.to_datetime(df[date_col], errors="coerce")
    df = df.dropna(subset=["_date"])
    df["_month"] = df["_date"].dt.strftime("%b")
    month_order = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]
    months_in_data = df["_month"].unique().tolist()
    months_sorted = sorted(months_in_data, key=lambda m: month_order.index(m) if m in month_order else 99)

    series_on_time = []
    series_pending = []
    series_late = []
    for m in months_sorted:
        grp = df[df["_month"] == m]
        on_time = (grp["_status_norm"] == "on time").sum()
        pending = (grp["_status_norm"] == "pending").sum()
        late = (grp["_status_norm"] == "late").sum()
        total = on_time + pending + late
        if total == 0:
            series_on_time.append(0)
            series_pending.append(0)
            series_late.append(0)
        else:
            series_on_time.append(round(100.0 * on_time / total, 1))
            series_pending.append(round(100.0 * pending / total, 1))
            series_late.append(round(100.0 * late / total, 1))

    return {
        "categories": months_sorted,
        "series": [
            {"name": "On Time", "data": series_on_time},
            {"name": "Pending", "data": series_pending},
            {"name": "Late", "data": series_late},
        ],
    }


def _read_returns_data_from_excel(excel_path):
    """
    ÙŠÙ‚Ø±Ø£ Ù…Ù† Ø´ÙŠØª Returns_Data: Ø¹Ù…ÙˆØ¯ Return_Status (ÙÙ„ØªØ±Ø© Ù…Ø«Ù„ PODs: On Time, Pending, Late)ØŒ
    Request_Date Ù„Ù„Ø´Ù‡ÙˆØ±ØŒ Return_ID Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø­Ù†Ø§Øª (unique). ÙŠØ±Ø¬Ù‘Ø¹ returns_kpi Ùˆ returns_chart_data.
    """
    try:
        xls = pd.ExcelFile(excel_path, engine="openpyxl")
    except Exception:
        return None
    sheet_name = None
    for name in xls.sheet_names:
        n = str(name).strip().lower().replace(" ", "").replace("_", "")
        if "returnsdata" in n or "returns_data" in n:
            sheet_name = name
            break
    if not sheet_name:
        for name in xls.sheet_names:
            if "returns" in str(name).lower() and "data" in str(name).lower():
                sheet_name = name
                break
    if not sheet_name:
        for name in xls.sheet_names:
            if "return" in str(name).lower():
                sheet_name = name
                break
    if not sheet_name:
        return None
    try:
        df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl", header=0)
    except Exception:
        return None
    if df.empty or len(df) < 1:
        return None

    df.columns = [str(c).strip() for c in df.columns]
    cols_lower = {c.lower(): c for c in df.columns if c}

    def _col(*keys):
        for k in keys:
            k_norm = k.lower().replace(" ", "").replace("_", "")
            for col in cols_lower:
                if col.replace(" ", "").replace("_", "") == k_norm:
                    return cols_lower[col]
            if k.lower() in cols_lower:
                return cols_lower[k.lower()]
        return None

    status_col = _col("Return_Status", "Return Status", "ReturnStatus")
    date_col = _col("Request_Date", "Request Date", "RequestDate", "Date")
    return_id_col = _col("Return_ID", "Return ID", "ReturnID")
    nbr_skus_col = _col("Nbr_SKUs", "Nbr SKUs", "NbrSKUs")
    nbr_items_col = _col("Nbr_Items", "Nbr Items", "NbrItems")
    if not status_col or not date_col:
        return None
    if not return_id_col:
        return_id_col = df.columns[0]

    s = df[status_col].fillna("").astype(str).str.strip().str.lower()
    df["_status_norm"] = s.str.replace(r"\s+", " ", regex=True)
    valid_statuses = {"on time", "pending", "late"}
    df = df[df["_status_norm"].isin(valid_statuses)].copy()
    if df.empty:
        return None

    df["_date"] = pd.to_datetime(df[date_col], errors="coerce")
    df = df.dropna(subset=["_date"])
    df["_month"] = df["_date"].dt.strftime("%b")
    month_order = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]
    months_in_data = df["_month"].unique().tolist()
    months_sorted = sorted(months_in_data, key=lambda m: month_order.index(m) if m in month_order else 99)

    total_unique_returns = df[return_id_col].dropna().astype(str).str.strip().nunique()
    total_rows = len(df)

    total_skus_kpi = total_unique_returns
    total_lpns_kpi = total_rows
    if nbr_skus_col:
        total_skus_kpi = int(pd.to_numeric(df[nbr_skus_col], errors="coerce").fillna(0).sum())
    if nbr_items_col:
        total_lpns_kpi = int(pd.to_numeric(df[nbr_items_col], errors="coerce").fillna(0).sum())

    series_on_time = []
    series_pending = []
    series_late = []
    for m in months_sorted:
        grp = df[df["_month"] == m]
        on_time = (grp["_status_norm"] == "on time").sum()
        pending = (grp["_status_norm"] == "pending").sum()
        late = (grp["_status_norm"] == "late").sum()
        total = on_time + pending + late
        if total == 0:
            series_on_time.append(0)
            series_pending.append(0)
            series_late.append(0)
        else:
            series_on_time.append(round(100.0 * on_time / total, 1))
            series_pending.append(round(100.0 * pending / total, 1))
            series_late.append(round(100.0 * late / total, 1))

    return {
        "returns_kpi": {
            "total_skus": total_skus_kpi,
            "total_lpns": total_lpns_kpi,
        },
        "returns_chart_data": {
            "categories": months_sorted,
            "series": [
                {"name": "On Time", "data": series_on_time},
                {"name": "Pending", "data": series_pending},
                {"name": "Late", "data": series_late},
            ],
        },
    }


def _read_inventory_data_from_excel(excel_path):
    """
    ÙŠÙ‚Ø±Ø£ Ù…Ù† Ø´ÙŠØª Inventory_Lots:
    - Ø¹Ù…ÙˆØ¯ LPNs: ØªØ¬Ù…ÙŠØ¹ ÙƒÙ„ Ø§Ù„Ù‚ÙŠÙ… (Ù…Ø¬Ù…ÙˆØ¹) = Total LPNs.
    - Ø¹Ù…ÙˆØ¯ Snapshot_Date: ÙƒÙ„ ÙŠÙˆÙ… Ø¨ÙŠÙˆÙ…Ù‡ (Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„Ø§Ø­Ù‚Ø§Ù‹ ÙÙŠ Ø´Ø§Ø±Øª/ØªØ­Ù„ÙŠÙ„).
    - Ø¹Ù…ÙˆØ¯ SKU: Ø­Ø°Ù Ø§Ù„Ù…ØªÙƒØ±Ø± ÙˆØ¹Ø¯Ù‘ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø© ÙÙ‚Ø· = Total SKUs.
    """
    try:
        xls = pd.ExcelFile(excel_path, engine="openpyxl")
    except Exception:
        return None
    sheet_name = None
    for name in xls.sheet_names:
        n = str(name).strip().lower().replace(" ", "").replace("_", "")
        if "inventorylots" in n or "inventory_lots" in n:
            sheet_name = name
            break
    if not sheet_name:
        for name in xls.sheet_names:
            if "inventory" in str(name).lower() and "lot" in str(name).lower():
                sheet_name = name
                break
    if not sheet_name:
        for name in xls.sheet_names:
            if "inventory" in str(name).lower():
                sheet_name = name
                break
    if not sheet_name:
        return None
    try:
        df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl", header=0)
    except Exception:
        return None
    if df.empty or len(df) < 1:
        return None

    df.columns = [str(c).strip() for c in df.columns]
    cols_lower = {c.lower(): c for c in df.columns if c}

    def _col(*keys):
        for k in keys:
            k_norm = k.lower().replace(" ", "").replace("_", "")
            for col in cols_lower:
                if col.replace(" ", "").replace("_", "") == k_norm:
                    return cols_lower[col]
            if k.lower() in cols_lower:
                return cols_lower[k.lower()]
        return None

    lpns_col = _col("LPNs", "LPN")
    snapshot_date_col = _col("Snapshot_Date", "Snapshot Date", "SnapshotDate", "Date")
    sku_col = _col("SKU", "Sku")

    total_lpns = 0
    total_skus = 0

    if lpns_col:
        total_lpns = int(pd.to_numeric(df[lpns_col], errors="coerce").fillna(0).sum())

    if sku_col:
        sku_series = df[sku_col].dropna().astype(str).str.strip()
        sku_series = sku_series[sku_series != ""]
        total_skus = int(sku_series.nunique())

    return {
        "inventory_kpi": {
            "total_skus": total_skus,
            "total_lpns": total_lpns,
            "utilization_pct": "78",
        },
    }


def _read_inventory_snapshot_capacity_from_excel(excel_path):
    """
    ÙŠÙ‚Ø±Ø£ Ù…Ù† Ø´ÙŠØª Inventory_Snapshot:
    - Used_Space_m3 â†’ Used (Ù…Ø¬Ù…ÙˆØ¹ Ø«Ù… Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©).
    - Available_Space_m3 â†’ Available (Ù…Ø¬Ù…ÙˆØ¹ Ø«Ù… Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©).
    ÙŠØ±Ø¬Ø¹ inventory_capacity_data: { used: Ù†Ø³Ø¨Ø© Used %, available: Ù†Ø³Ø¨Ø© Available % }.
    """
    try:
        xls = pd.ExcelFile(excel_path, engine="openpyxl")
    except Exception:
        return None
    sheet_name = None
    for name in xls.sheet_names:
        n = str(name).strip().lower().replace(" ", "").replace("_", "")
        if "inventorysnapshot" in n or "inventory_snapshot" in n:
            sheet_name = name
            break
    if not sheet_name:
        for name in xls.sheet_names:
            if "inventory" in str(name).lower() and "snapshot" in str(name).lower():
                sheet_name = name
                break
    if not sheet_name:
        return None
    try:
        df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl", header=0)
    except Exception:
        return None
    if df.empty or len(df) < 1:
        return None

    df.columns = [str(c).strip() for c in df.columns]
    cols_lower = {c.lower(): c for c in df.columns if c}

    def _col(*keys):
        for k in keys:
            k_norm = k.lower().replace(" ", "").replace("_", "")
            for col in cols_lower:
                if col.replace(" ", "").replace("_", "") == k_norm:
                    return cols_lower[col]
            if k.lower() in cols_lower:
                return cols_lower[k.lower()]
        return None

    used_col = _col("Used_Space_m3", "Used Space m3", "UsedSpace_m3")
    avail_col = _col("Available_Space_m3", "Available Space m3", "AvailableSpace_m3")
    if not used_col or not avail_col:
        return None

    total_used = pd.to_numeric(df[used_col], errors="coerce").fillna(0).sum()
    total_avail = pd.to_numeric(df[avail_col], errors="coerce").fillna(0).sum()
    total = total_used + total_avail
    if total <= 0:
        return {"inventory_capacity_data": {"used": 78, "available": 22}}

    used_pct = round(100.0 * total_used / total, 1)
    available_pct = round(100.0 - used_pct, 1)
    return {
        "inventory_capacity_data": {
            "used": used_pct,
            "available": available_pct,
        },
    }


def _read_inventory_warehouse_table_from_excel(excel_path):
    """
    ÙŠÙ‚Ø±Ø£ Ù…Ù† Ø´ÙŠØª Inventory_Snapshot Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù€ Warehouse:
    - Warehouse Ù…Ù† Ø¹Ù…ÙˆØ¯ Warehouse
    - SKUs Ù…Ù† Ø¹Ù…ÙˆØ¯ Total_SKUs
    - Available Space Ù…Ù† Ø¹Ù…ÙˆØ¯ Available_Space_m3
    - Utilization % Ù…Ù† Ø¹Ù…ÙˆØ¯ Utilization_%
    ÙƒÙ„ ØµÙ ÙƒÙ…Ø§ Ù‡Ùˆ Ù…Ù† Ø§Ù„Ø´ÙŠØª Ø¨Ø¯ÙˆÙ† Ø¬Ù…Ø¹.
    """
    try:
        xls = pd.ExcelFile(excel_path, engine="openpyxl")
    except Exception:
        return None
    sheet_name = None
    for name in xls.sheet_names:
        n = str(name).strip().lower().replace(" ", "").replace("_", "")
        if "inventorysnapshot" in n or "inventory_snapshot" in n:
            sheet_name = name
            break
    if not sheet_name:
        for name in xls.sheet_names:
            if "inventory" in str(name).lower() and "snapshot" in str(name).lower():
                sheet_name = name
                break
    if not sheet_name:
        return None
    try:
        df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl", header=0)
    except Exception:
        return None
    if df.empty or len(df) < 1:
        return None

    df.columns = [str(c).strip() for c in df.columns]
    cols_lower = {c.lower(): c for c in df.columns if c}

    def _col(*keys):
        for k in keys:
            k_norm = k.lower().replace(" ", "").replace("_", "")
            for col in cols_lower:
                if col.replace(" ", "").replace("_", "") == k_norm:
                    return cols_lower[col]
            if k.lower() in cols_lower:
                return cols_lower[k.lower()]
        return None

    warehouse_col = _col("Warehouse")
    total_skus_col = _col("Total_SKUs", "Total SKUs", "TotalSKUs")
    avail_space_col = _col("Available_Space_m3", "Available Space m3", "AvailableSpace_m3")
    util_col = _col("Utilization_%", "Utilization %", "UtilizationPct", "Utilization")
    if not warehouse_col:
        return None

    def _val(col, r):
        if not col or col not in r.index:
            return ""
        v = r[col]
        if pd.isna(v):
            return ""
        if isinstance(v, (int, float)):
            return str(int(v)) if v == int(v) else str(v)
        return str(v).strip()

    def _util_pct(col, r):
        if not col or col not in r.index:
            return ""
        v = r[col]
        if pd.isna(v):
            return ""
        try:
            num = float(v)
            if 0 <= num <= 1:
                return f"{round(num * 100, 2)}%"
            return f"{round(num, 2)}%"
        except (TypeError, ValueError):
            s = str(v).strip()
            return f"{s}%" if s and not s.endswith("%") else s

    rows = []
    for _, r in df.iterrows():
        warehouse = "" if pd.isna(r[warehouse_col]) else str(r[warehouse_col]).strip()
        rows.append({
            "warehouse": warehouse,
            "skus": _val(total_skus_col, r),
            "available_space": _val(avail_space_col, r),
            "utilization_pct": _util_pct(util_col, r),
        })
    if not rows:
        return None
    return {"inventory_warehouse_table": rows}


def _read_returns_region_table_from_excel(excel_path):
    """
    ÙŠØ¨Ù†ÙŠ returns_region_table Ù…Ù† Inventory_Lots + Inventory_Snapshot:
    - Region Ù…Ù† Ø¹Ù…ÙˆØ¯ Warehouse ÙÙŠ Inventory_Lots (ÙÙ„ØªØ±Ø© Ø¨Ø§Ù„Ù€ Warehouse).
    - SKUs: Ø¹Ø¯Ø¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø© Ù„Ø¹Ù…ÙˆØ¯ SKU Ù„ÙƒÙ„ Warehouse Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ„ØªØ±Ø© Ø¨Ø§Ù„ØªØ§Ø±ÙŠØ®.
    - Available: Ù…Ø¬Ù…ÙˆØ¹ LPNs Ù„ÙƒÙ„ Warehouse Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ„ØªØ±Ø© Ø¨Ù€ Snapshot_Date (Ø¢Ø®Ø± ØªØ§Ø±ÙŠØ®).
    - Utilization %: (LPNs Ù„Ù„Ù…Ù†Ø·Ù‚Ø© ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®) / Capacity_m3 Ù…Ù† Inventory_Snapshot Ù„Ù†ÙØ³ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©ØŒ ÙƒÙ†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©.
    """
    try:
        xls = pd.ExcelFile(excel_path, engine="openpyxl")
    except Exception:
        return None

    def _find_sheet(*names):
        for want in names:
            want_n = want.lower().replace(" ", "").replace("_", "")
            for s in xls.sheet_names:
                if want_n in str(s).lower().replace(" ", "").replace("_", ""):
                    return s
        return None

    lots_sheet = _find_sheet("Inventory_Lots", "Inventory Lots")
    snapshot_sheet = _find_sheet("Inventory_Snapshot", "Inventory Snapshot")
    if not lots_sheet:
        return None

    try:
        df_lots = pd.read_excel(excel_path, sheet_name=lots_sheet, engine="openpyxl", header=0)
    except Exception:
        return None
    if df_lots.empty:
        return None

    df_lots.columns = [str(c).strip() for c in df_lots.columns]
    cols_lots = {c.lower(): c for c in df_lots.columns if c}

    def _col_lots(*keys):
        for k in keys:
            k_norm = k.lower().replace(" ", "").replace("_", "")
            for col in cols_lots:
                if col.replace(" ", "").replace("_", "") == k_norm:
                    return cols_lots[col]
        return None

    wh_col = _col_lots("Warehouse")
    sku_col = _col_lots("SKU", "Sku")
    lpns_col = _col_lots("LPNs", "LPN")
    snap_col = _col_lots("Snapshot_Date", "Snapshot Date", "SnapshotDate", "Date")
    if not wh_col or not snap_col:
        return None
    if not lpns_col:
        lpns_col = df_lots.columns[1] if len(df_lots.columns) > 1 else None
    if not lpns_col:
        return None

    df_lots["_date"] = pd.to_datetime(df_lots[snap_col], errors="coerce")
    df_lots = df_lots.dropna(subset=["_date"])
    if df_lots.empty:
        return None

    latest_date = df_lots["_date"].max()
    df_filtered = df_lots[df_lots["_date"] == latest_date].copy()

    capacity_by_warehouse = {}
    if snapshot_sheet:
        try:
            df_snap = pd.read_excel(excel_path, sheet_name=snapshot_sheet, engine="openpyxl", header=0)
            if not df_snap.empty:
                df_snap.columns = [str(c).strip() for c in df_snap.columns]
                snap_cols = {c.lower(): c for c in df_snap.columns if c}
                snap_wh = next((snap_cols[c] for c in snap_cols if "warehouse" in c.replace(" ", "").replace("_", "")), None)
                cap_col = next((snap_cols[c] for c in snap_cols if "capacity_m3" in c.replace(" ", "").replace("_", "") or ("capacity" in c and "m3" in c)), None)
                if not cap_col:
                    used_c = next((snap_cols[c] for c in snap_cols if "used_space" in c.replace(" ", "").replace("_", "")), None)
                    avail_c = next((snap_cols[c] for c in snap_cols if "available_space" in c.replace(" ", "").replace("_", "")), None)
                    if used_c and avail_c:
                        df_snap["_cap"] = pd.to_numeric(df_snap[used_c], errors="coerce").fillna(0) + pd.to_numeric(df_snap[avail_c], errors="coerce").fillna(0)
                        cap_col = "_cap"
                if snap_wh and cap_col:
                    for _, r in df_snap.iterrows():
                        w = r.get(snap_wh)
                        if pd.isna(w):
                            continue
                        w = str(w).strip()
                        if not w:
                            continue
                        c = r.get(cap_col)
                        if cap_col == "_cap":
                            val = c
                        else:
                            val = pd.to_numeric(c, errors="coerce")
                        if pd.notna(val) and val > 0:
                            capacity_by_warehouse[w] = float(val)
        except Exception:
            pass

    df_filtered["_lpns_num"] = pd.to_numeric(df_filtered[lpns_col], errors="coerce").fillna(0)
    rows = []
    for wh, grp in df_filtered.groupby(wh_col, dropna=False):
        wh_name = "" if pd.isna(wh) else str(wh).strip()
        skus = grp[sku_col].dropna().astype(str).str.strip() if sku_col else pd.Series(dtype=object)
        skus = skus[skus != ""].nunique() if not skus.empty else 0
        available = int(grp["_lpns_num"].sum())
        cap = capacity_by_warehouse.get(wh_name) or capacity_by_warehouse.get(wh)
        if cap and cap > 0:
            util = round(100.0 * available / cap, 2)
            utilization_pct = f"{util}%"
        else:
            utilization_pct = "â€”"
        rows.append({
            "region": wh_name,
            "skus": str(int(skus)) if isinstance(skus, (int, float)) else str(skus),
            "available": str(available),
            "utilization_pct": utilization_pct,
        })

    if not rows:
        return None
    return {"returns_region_table": rows}


def get_dashboard_tab_context(request):
    """
    ÙŠØ¨Ù†ÙŠ Ø³ÙŠØ§Ù‚ ØªØ§Ø¨ Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ (Ù†ÙØ³ Ø¨ÙŠØ§Ù†Ø§Øª Dashboard view).
    Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª Ø§Ù„ÙÙŠÙˆ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ dashboard Ø£Ùˆ inbound ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ØŒ ÙˆØ¥Ù„Ø§ ÙŠÙØ±Ø¬Ø¹ Ø³ÙŠØ§Ù‚ Ø§ÙØªØ±Ø§Ø¶ÙŠ.
    """
    try:
        for app_label in ["dashboard", "inbound"]:
            try:
                view_module = __import__(f"{app_label}.views", fromlist=["DashboardView"])
                ViewClass = getattr(view_module, "DashboardView", None)
                if ViewClass is not None:
                    view = ViewClass()
                    view.request = request
                    view.object = None
                    return view.get_context_data()
            except (ImportError, AttributeError):
                continue
    except Exception:
        pass
    # Ø³ÙŠØ§Ù‚ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¹Ù†Ø¯ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª/Ø§Ù„ÙÙŠÙˆ (Ù…Ø¹ Ø¯Ø§ØªØ§ ÙˆÙ‡Ù…ÙŠØ© Ù„Ù€ Inbound)
    return {
        "title": "Dashboard",
        "breadcrumb": {"title": "Healthcare Dashboard", "parent": "Dashboard", "child": "Default"},
        "is_admin": False,
        "is_employee": False,
        "inbound_data": [],
        "transportation_outbound_data": [],
        "wh_outbound_data": [],
        "returns_data": [],
        "expiry_data": [],
        "damage_data": [],
        "inventory_data": [],
        "pallet_location_availability_data": [],
        "hse_data": [],
        "number_of_shipments": 0,
        "total_vehicles_daily": 0,
        "total_pallets": 0,
        "total_pending_shipments": 0,
        "total_number_of_shipments": 0,
        "total_quantity": 0,
        "total_number_of_line": 0,
        # Inbound KPI + Ø¯Ø§ØªØ§ Ø´Ø§Ø±Øª Pending Shipments (Ù…Ù† Ø§Ù„Ø¯ÙŠÙƒØª ÙÙŠ Ø§Ù„ÙÙŠÙˆ)
        "inbound_kpi": INBOUND_DEFAULT_KPI.copy(),
        "pending_shipments": list(INBOUND_DEFAULT_PENDING_SHIPMENTS),
        "shipment_data": {"bulk": 0, "loose": 0, "cold": 0, "frozen": 0, "ambient": 0},
        "wh_total_released_order": 0,
        "wh_total_piked_order": 0,
        "wh_total_pending_pick_orders": 0,
        "wh_total_number_of_PODs_collected_on_time": 0,
        "wh_total_number_of_PODs_collected_Late": 0,
        "total_orders_items_returned": 0,
        "total_number_of_return_items_orders_updated_on_time": 0,
        "total_number_of_return_items_orders_updated_late": 0,
        "total_SKUs_expired": 0,
        "total_expired_SKUS_disposed": 0,
        "total_nearly_expired_1_to_3_months": 0,
        "total_nearly_expired_3_to_6_months": 0,
        "total_SKUs_expired_calculated": 0,
        "Total_QTYs_Damaged_by_WH": 0,
        "Total_Number_of_Damaged_during_receiving": 0,
        "Total_Araive_Damaged": 0,
        "Total_Locations_match": 0,
        "Total_Locations_not_match": 0,
        "last_shipment": None,
        "Total_Storage_Pallet": 0,
        "Total_Storage_pallet_empty": 0,
        "Total_Storage_Bin": 0,
        "Total_occupied_pallet_location": 0,
        "Total_Storage_Bin_empty": 0,
        "Total_occupied_Bin_location": 0,
        "Total_Incidents_on_the_side": 0,
        "total_no_of_employees": 0,
        "admin_data": [],
        "user_type": "Unknown",
        "years": [],
        "months": list(calendar_module.month_name)[1:],
        "days": list(range(1, 32)),
        "returns_region_table": [
            {"region": "Main warehouse", "skus": "2,538", "available": "1118", "utilization_pct": "71%"},
            {"region": "Dammam DC", "skus": "501", "available": "200", "utilization_pct": "â€”"},
            {"region": "Riyadh DC", "skus": "3,996", "available": "209", "utilization_pct": "â€”"},
            {"region": "Jeddah DC", "skus": "7,996", "available": "300", "utilization_pct": "â€”"},
        ],
    }


@method_decorator(csrf_exempt, name="dispatch")
@method_decorator(
    cache_control(no_cache=True, no_store=True, must_revalidate=True, max_age=0),
    name="dispatch",
)
class UploadExcelViewRoche(View):
    template_name = "index.html"
    excel_file_name = "all sheet.xlsm"
    correct_code = "1234"

    # ØªØ§Ø¨Ø§Øª ØªØ­Ø°Ù Ù…Ù† Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ (Ø£Ø¶Ù Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´ÙŠØªØ§Øª ÙƒÙ…Ø§ Ù‡ÙŠ ÙÙŠ Ø§Ù„Ø¥ÙƒØ³Ù„)
    EXCLUDE_TABS = []  # Ù…Ø«Ø§Ù„: ["Sheet2", "ØªÙ‚Ø§Ø±ÙŠØ± Ù‚Ø¯ÙŠÙ…Ø©", "Backup"]
    # Ø£Ùˆ: Ø§Ø¹Ø±Ø¶ ØªØ§Ø¨Ø§Øª Ù…Ø¹ÙŠÙ†Ø© ÙÙ‚Ø· (Ù„Ùˆ Ø¶Ø¹Øª Ù‚Ø§Ø¦Ù…Ø© Ù‡Ù†Ø§ØŒ Ø§Ù„ØªØ§Ø¨Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ ÙƒÙ„Ù‡Ø§ ØªØ®ØªÙÙŠ)
    INCLUDE_ONLY_TABS = (
        None  # Ù…Ø«Ø§Ù„: ["Overview", "Dock to stock", "Order General Information"]
    )
    # ØªØ§Ø¨Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù†Ø¹Ø±Ø¶Ù‡Ø§ Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø´ÙŠØª Ù…Ø¨Ø§Ø´Ø±
    DASHBOARD_TAB_NAME = "Dashboard"
    # Ø¹Ø±Ø¶ ØªØ§Ø¨ Warehouse ÙÙ‚Ø· (ÙƒØ±ÙˆØª Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹Ø§Øª Ù…Ù† Ø§Ù„Ø£Ø¯Ù…Ù†) ÙˆØ¥Ø®ÙØ§Ø¡ ÙƒÙ„ Ø§Ù„ØªØ§Ø¨Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰
    USE_WAREHOUSE_TAB_ONLY = True
    DEFAULT_EXCEL_FILENAMES = [
        "all sheet.xlsm",
        "all sheet.xlsx",
        "all_sheet.xlsm",
        "all_sheet.xlsx",
    ]

    MONTH_LOOKUP = {}
    MONTH_PREFIXES = set()
    for idx in range(1, 13):
        abbr = month_abbr[idx]
        full = month_name[idx]
        if abbr:
            MONTH_LOOKUP[abbr.lower()] = abbr
            MONTH_PREFIXES.add(abbr.lower())
        if full:
            MONTH_LOOKUP[full.lower()] = abbr
        MONTH_LOOKUP[str(idx)] = abbr
        MONTH_LOOKUP[f"{idx:02d}"] = abbr
    MONTH_LOOKUP["sept"] = "Sep"

    AGGREGATE_COLUMN_KEYWORDS = {
        "total",
        "grand total",
        "overall total",
        "sum",
        "ytd",
        "y.t.d.",
        "avg",
        "average",
        "target",
        "target (%)",
        "target %",
        "target%",
        "cumulative",
    }

    # Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¥Ø°Ø§ ÙˆÙØ¶Ø¹ ÙÙŠ excel_uploads Ø¨Ø¯ÙˆÙ† Ø±ÙØ¹ (Ù…Ø«Ù„Ø§Ù‹ all sheet.xlsm)
    def get_excel_path(self):
        folder_path = os.path.join(settings.MEDIA_ROOT, "excel_uploads")
        os.makedirs(folder_path, exist_ok=True)
        priority_files = ["latest.xlsm", "latest.xlsx"] + self.DEFAULT_EXCEL_FILENAMES
        for name in priority_files:
            path = os.path.join(folder_path, name)
            if os.path.exists(path):
                return path
        return os.path.join(folder_path, "latest.xlsx")

    def get_uploaded_file_path(self, request):
        folder = os.path.join(settings.MEDIA_ROOT, "excel_uploads")
        os.makedirs(folder, exist_ok=True)

        # Ø£ÙˆÙ„ÙˆÙŠØ©: Ù…Ù„Ù Ø§Ù„Ø¬Ù„Ø³Ø© Ø«Ù… latest.xlsm Ø«Ù… latest.xlsx Ø«Ù… all sheet
        if request:
            saved_path = request.session.get("uploaded_excel_path")
            if saved_path and os.path.exists(saved_path):
                return saved_path
        priority_files = ["latest.xlsm", "latest.xlsx"] + self.DEFAULT_EXCEL_FILENAMES
        for name in priority_files:
            path = os.path.join(folder, name)
            if os.path.exists(path):
                if request:
                    try:
                        request.session["uploaded_excel_path"] = path
                        request.session.save()
                    except Exception:
                        pass
                return path
        return os.path.join(folder, "latest.xlsx")

    @staticmethod
    def safe_format_value(val):
        if pd.isna(val) or val is pd.NaT:
            return ""
        elif isinstance(val, pd.Timestamp):
            if val.tzinfo is not None:
                val = val.tz_convert(None)
            return val.strftime("%Y-%m-%d %H:%M:%S")
        return val

    # ----------------------------------------------------
    # ğŸ”§ Helper methods for month normalization & filtering
    # ----------------------------------------------------
    def normalize_month_label(self, month_value):
        if month_value is None:
            return None

        raw = str(month_value).strip()
        if not raw:
            return None

        lower = raw.lower()
        if lower in self.MONTH_LOOKUP:
            return self.MONTH_LOOKUP[lower]

        first_three = lower[:3]
        if first_three in self.MONTH_LOOKUP:
            return self.MONTH_LOOKUP[first_three]

        try:
            parsed = pd.to_datetime(raw, errors="coerce")
            if not pd.isna(parsed):
                return parsed.strftime("%b")
        except Exception:
            pass

        return raw[:3].capitalize()

    def _value_matches_month(self, value, month_lower):
        if value is None:
            return False
        normalized = self.normalize_month_label(value)
        return normalized is not None and normalized.lower() == month_lower

    def _column_matches_month(self, column, month_lower):
        if column is None:
            return False
        col_lower = str(column).strip().lower()
        if col_lower == month_lower:
            return True
        if col_lower.startswith(month_lower + " "):
            return True
        if col_lower.endswith(" " + month_lower):
            return True
        if col_lower.startswith(month_lower + "-") or col_lower.endswith(
            "-" + month_lower
        ):
            return True
        if col_lower.startswith(month_lower + "/") or col_lower.endswith(
            "/" + month_lower
        ):
            return True
        if col_lower.startswith(month_lower + "("):
            return True
        if col_lower.split(" ")[0] == month_lower:
            return True
        if col_lower.replace(".", "").startswith(month_lower):
            return True
        return False

    def _is_month_column(self, column):
        if column is None:
            return False
        col_lower = str(column).strip().lower()
        if col_lower in self.MONTH_LOOKUP:
            return True
        first_three = col_lower[:3]
        if first_three in self.MONTH_PREFIXES:
            return True
        col_split = col_lower.replace("/", " ").replace("-", " ").split()
        if col_split and col_split[0][:3] in self.MONTH_PREFIXES:
            return True
        return False

    def _is_aggregate_column(self, column):
        if column is None:
            return False
        col_lower = str(column).strip().lower()
        if col_lower in self.AGGREGATE_COLUMN_KEYWORDS:
            return True
        compact = col_lower.replace(" ", "")
        if compact in {"target%", "target(%)", "total%"}:
            return True
        if col_lower.isdigit():
            try:
                if int(col_lower) >= 1900:
                    return True
            except ValueError:
                pass
        return False

    def _append_missing_month_messages(self, tab_data, missing_months):
        if not missing_months:
            return

        message_table = {
            "title": "Missing Months",
            "columns": ["Message"],
            "data": [
                {"Message": f"No data available for month {month}."}
                for month in missing_months
            ],
        }

        if isinstance(tab_data.get("sub_tables"), list):
            tab_data["sub_tables"] = [
                sub
                for sub in tab_data["sub_tables"]
                if sub.get("title") != "Missing Months"
            ]
            tab_data["sub_tables"].append(message_table)
            return

        # ÙÙŠ Ø­Ø§Ù„ ÙƒØ§Ù† Ø§Ù„ØªØ§Ø¨ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·ØŒ Ù†Ø­ÙˆÙ„Ù‡ Ø¥Ù„Ù‰ sub_tables
        columns = tab_data.pop("columns", None)
        data_rows = tab_data.pop("data", None)
        if columns is not None and data_rows is not None:
            existing_table = {
                "title": tab_data.get("name", "Data"),
                "columns": columns,
                "data": data_rows,
            }
            tab_data["sub_tables"] = [existing_table, message_table]
        else:
            tab_data["sub_tables"] = [message_table]

    def apply_month_filter_to_tab(
        self, tab_data, selected_month=None, selected_months=None
    ):
        if not tab_data:
            return None

        selected_months_norm = []
        if selected_months:
            if isinstance(selected_months, str):
                selected_months = [selected_months]
            seen = set()
            for month in selected_months:
                norm = self.normalize_month_label(month)
                if norm and norm.lower() not in seen:
                    seen.add(norm.lower())
                    selected_months_norm.append(norm)

        month_norm = self.normalize_month_label(selected_month)
        month_filters = []
        if selected_months_norm:
            month_filters = selected_months_norm
        elif month_norm:
            month_filters = [month_norm]
        else:
            tab_data.pop("selected_month", None)
            tab_data.pop("selected_months", None)
            return None

        month_filters_lower = [m.lower() for m in month_filters]
        matched_months = set()

        def matches_any_month(column):
            if not month_filters_lower:
                return False
            for month_lower in month_filters_lower:
                if self._column_matches_month(column, month_lower):
                    matched_months.add(month_lower)
                    return True
            return False

        def value_matches_month(value):
            if not month_filters_lower:
                return False
            normalized = self.normalize_month_label(value)
            if not normalized:
                return False
            val_lower = normalized.lower()
            if val_lower in month_filters_lower:
                matched_months.add(val_lower)
                return True
            return False

        def filter_columns(columns):
            filtered = []
            for col in columns:
                if self._is_month_column(col):
                    if matches_any_month(col):
                        filtered.append(col)
                elif self._is_aggregate_column(col) and not self._column_matches_month(
                    col,
                    month_filters_lower[0] if month_filters_lower else "",
                ):
                    continue
                else:
                    filtered.append(col)
            return filtered if filtered else columns

        def filter_rows(data_rows, columns):
            if not data_rows:
                return data_rows

            month_cols = [
                col
                for col in columns
                if str(col).strip().lower() in {"month", "month name", "monthname"}
            ]
            if not month_cols:
                return data_rows

            month_col = month_cols[0]
            scoped_rows = []
            for row in data_rows:
                value = None
                if isinstance(row, dict):
                    value = row.get(month_col)
                if value_matches_month(value):
                    scoped_rows.append(row)
            return scoped_rows if scoped_rows else data_rows

        if "sub_tables" in tab_data and isinstance(tab_data["sub_tables"], list):
            for sub in tab_data["sub_tables"]:
                if not isinstance(sub, dict):
                    continue
                # âœ… Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ chart_data ÙÙŠ sub_table
                sub_chart_data = sub.get("chart_data", [])

                columns = sub.get("columns", [])
                if columns:
                    filtered_columns = filter_columns(columns)
                    if sub.get("data"):
                        new_data = []
                        for row in sub["data"]:
                            if isinstance(row, dict):
                                new_row = {
                                    col: row.get(col, "") for col in filtered_columns
                                }
                            else:
                                new_row = row
                            new_data.append(new_row)
                        sub["data"] = filter_rows(new_data, filtered_columns)
                    sub["columns"] = filtered_columns

                # âœ… Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ø¶Ø§ÙØ© chart_data Ø¥Ù„Ù‰ sub_table Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ (Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª ÙØ§Ø±ØºØ©)
                sub["chart_data"] = sub_chart_data
        else:
            columns = tab_data.get("columns", [])
            data_rows = tab_data.get("data", [])
            if columns:
                filtered_columns = filter_columns(columns)
                if data_rows:
                    new_rows = []
                    for row in data_rows:
                        if isinstance(row, dict):
                            new_row = {
                                col: row.get(col, "") for col in filtered_columns
                            }
                        else:
                            new_row = row
                        new_rows.append(new_row)
                    tab_data["data"] = filter_rows(new_rows, filtered_columns)
                tab_data["columns"] = filtered_columns

        if "chart_data" in tab_data and isinstance(tab_data["chart_data"], list):
            for chart in tab_data["chart_data"]:
                if not isinstance(chart, dict):
                    continue
                points = chart.get("dataPoints")
                if not points:
                    continue
                filtered_points = []
                for point in points:
                    label_norm = self.normalize_month_label(point.get("label"))
                    if label_norm and label_norm.lower() in month_filters_lower:
                        matched_months.add(label_norm.lower())
                        filtered_points.append(point)
                if filtered_points:
                    chart["dataPoints"] = filtered_points

        if selected_months_norm:
            tab_data["selected_months"] = selected_months_norm
            return selected_months_norm[0]
        else:
            tab_data["selected_month"] = month_filters[0]
            return month_filters[0]

    @method_decorator(cache_control(max_age=3600, public=True), name="get")
    def get(self, request):
        # --------------------------
        # Ø·Ù„Ø¨Ø§Øª AJAX Ù„Ù„ØªØ§Ø¨Ø§Øª (Ø­ØªÙ‰ Ù…Ø¹ USE_WAREHOUSE_TAB_ONLY): Ø¥Ø±Ø¬Ø§Ø¹ JSON ÙˆÙ„ÙŠØ³ Ø§Ù„ØµÙØ­Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        # --------------------------
        if request.headers.get("X-Requested-With") == "XMLHttpRequest":
            selected_tab = (request.GET.get("tab") or "").strip().lower()
            if selected_tab == "meeting points":
                return self.meeting_points_tab(request)
            if getattr(self, "USE_WAREHOUSE_TAB_ONLY", False) and selected_tab == "warehouse":
                wh_result = self.warehouse_tab(request)
                return JsonResponse(wh_result, safe=False)
            if selected_tab == "recommendation":
                recommendations = context_helpers.get_recommendations_list()
                weekly_tracker_rows = context_helpers.get_weekly_project_tracker_list()
                progress_status_rows = context_helpers.get_progress_status_list()
                potential_challenges_rows = context_helpers.get_potential_challenges_list()
                recommendation_html = render_to_string(
                    "components/ui-kits/tab-bootstrap/components/recommendation-cards.html",
                    {
                        "recommendations": recommendations,
                        "weekly_tracker_rows": weekly_tracker_rows,
                        "progress_status_rows": progress_status_rows,
                        "potential_challenges_rows": potential_challenges_rows,
                        "dashboard_theme": context_helpers.get_dashboard_theme_dict(),
                    },
                    request=request,
                )
                return JsonResponse({"detail_html": recommendation_html}, safe=False)
            if selected_tab == "project tracker":
                project_type_filter = request.GET.get("project_type", "").strip().lower()
                if project_type_filter not in ("idea", "automation"):
                    project_type_filter = None
                project_tracker_items = context_helpers.get_project_tracker_list(project_type=project_type_filter)
                project_tracker_html = render_to_string(
                    "components/ui-kits/tab-bootstrap/components/project-tracker-cards.html",
                    {"project_tracker_items": project_tracker_items},
                    request=request,
                )
                return JsonResponse({"detail_html": project_tracker_html}, safe=False)

        # ÙÙ„ØªØ± Meeting Points: Ø·Ù„Ø¨ Ø¨Ù€ status ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† tab) â€” Ù†Ø±Ø¬Ø¹ JSON Ø­ØªÙ‰ Ø¨Ø¯ÙˆÙ† Ù‡ÙŠØ¯Ø± AJAX
        if request.GET.get("status") and not request.GET.get("tab"):
            status_filter = request.GET.get("status", "all")
            meeting_html = self.get_meeting_points_section_html(
                request, status_filter
            )
            meeting_points = MeetingPoint.objects.all()
            done_count = meeting_points.filter(is_done=True).count()
            total_count = meeting_points.count()
            return JsonResponse(
                {
                    "meeting_section_html": meeting_html,
                    "detail_html": meeting_html,
                    "done_count": done_count,
                    "total_count": total_count,
                },
                safe=False,
            )

        # --------------------------
        # ÙˆØ¶Ø¹ Warehouse ÙÙ‚Ø·: Ù„Ø§ Ù†ÙØªØ­ Ø§Ù„Ø¥ÙƒØ³Ù„ ÙˆÙ„Ø§ Ù†Ø³ØªØ¯Ø¹ÙŠ Ø£ÙŠ Ø¯ÙˆØ§Ù„ Ø«Ù‚ÙŠÙ„Ø© â€” ØªØ­Ù…ÙŠÙ„ Ø³Ø±ÙŠØ¹
        # --------------------------
        if getattr(self, "USE_WAREHOUSE_TAB_ONLY", False):
            meeting_points = MeetingPoint.objects.all().order_by("is_done", "-created_at")
            render_context = {
                "data_is_uploaded": True,
                "months": [],
                "excel_tabs": [],
                "active_tab": "warehouse",
                "tab_summaries": [],
                "form": ExcelUploadForm(),
                "meeting_points": meeting_points,
                "done_count": meeting_points.filter(is_done=True).count(),
                "total_count": meeting_points.count(),
                "all_tab_data": {"detail_html": ""},
                "raw_tab_data": None,
                "warehouse_overview": context_helpers.get_warehouse_overview_list(),
                "clerk_interview_rows": context_helpers.get_clerk_interview_list(),
                "dashboard_theme": context_helpers.get_dashboard_theme_dict(),
                "phases_sections": context_helpers.get_phases_sections_list(),
                "recommendations": context_helpers.get_recommendations_list(),
                "weekly_tracker_rows": context_helpers.get_weekly_project_tracker_list(),
                "progress_status_rows": context_helpers.get_progress_status_list(),
                "potential_challenges_rows": context_helpers.get_potential_challenges_list(),
                "project_tracker_items": context_helpers.get_project_tracker_list(
                    project_type=request.GET.get("project_type") or None
                ),
            }
            return render(request, self.template_name, render_context)

        # --------------------------
        # Ù…Ø³Ø§Ø± Ø§Ù„Ø¥ÙƒØ³Ù„ (Ø¹Ù†Ø¯ Ø¥ÙŠÙ‚Ø§Ù USE_WAREHOUSE_TAB_ONLY)
        # --------------------------
        print("ğŸŸ¢ [GET] Loading dashboard with Excel tabs")
        cache.clear()
        excel_path = self.get_uploaded_file_path(request) or self.get_excel_path()
        data_is_uploaded = os.path.exists(excel_path)

        if not data_is_uploaded:
            form = ExcelUploadForm()
            return render(
                request, self.template_name, {"form": form, "data_is_uploaded": False}
            )

        # --------------------------
        # Read request parameters
        # --------------------------
        selected_tab = request.GET.get("tab", "").lower() or "all"
        selected_month = request.GET.get("month", "").strip()
        selected_quarter = request.GET.get("quarter", "").strip()
        action = request.GET.get("action", "").lower()
        status = request.GET.get("status")

        print(f"ğŸ”¹ Selected tab: {selected_tab}")
        print(f"ğŸ”¹ Selected month: {selected_month}")
        print(f"ğŸ”¹ Selected quarter: {selected_quarter}")
        print(f"ğŸ”¹ Action: {action}")

        print("ğŸ›°ï¸ Quarter AJAX Triggered:", request.GET.get("quarter"))

        quarter_months = []
        quarter_error = None
        if selected_quarter:
            try:
                quarter_months = self._resolve_quarter_months(selected_quarter)
            except ValueError as exc:
                quarter_error = str(exc)

        effective_month = None if quarter_months else selected_month

        if action == "meeting_points_tab":
            return self.meeting_points_tab(request)

        # âœ… Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø·Ù„Ø¨ AJAX ÙˆØ¨Ù‡ status ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† tab)ØŒ Ù†Ø¹ÙŠØ¯ Ù‚Ø³Ù… Meeting Points ÙÙ‚Ø·
        if (
            request.headers.get("X-Requested-With") == "XMLHttpRequest"
            and request.GET.get("status")
            and not request.GET.get("tab")
        ):
            status_filter = request.GET.get("status", "all")
            meeting_html = self.get_meeting_points_section_html(
                request, status_filter
            )
            meeting_points = MeetingPoint.objects.all()
            done_count = meeting_points.filter(is_done=True).count()
            total_count = meeting_points.count()
            return JsonResponse(
                {
                    "meeting_section_html": meeting_html,
                    "detail_html": meeting_html,
                    "done_count": done_count,
                    "total_count": total_count,
                },
                safe=False,
            )

        if action == "export_excel":
            if quarter_error:
                return HttpResponse(quarter_error, status=400)
            return self.export_dashboard_excel(
                request,
                selected_month=effective_month,
                selected_months=quarter_months or None,
            )

        # ====================== Ø·Ù„Ø¨Ø§Øª AJAX ======================
        if request.headers.get("X-Requested-With") == "XMLHttpRequest":
            print("âš¡ [AJAX Request] Received request")

            if quarter_error:
                return JsonResponse({"error": quarter_error})

            tab_filter_map = {
                "warehouse": lambda: self.warehouse_tab(request),
                "dashboard": lambda: self.dashboard_tab(request),
                "all": lambda: self.filter_all_tabs(
                    request,
                    effective_month,
                    selected_months=quarter_months or None,
                ),
                "return & refusal": lambda: self.filter_rejections_combined(
                    request,
                    effective_month,
                    selected_months=quarter_months or None,
                ),
                "rejections": lambda: self.filter_rejections_combined(
                    request,
                    effective_month,
                    selected_months=quarter_months or None,
                ),
                "inbound": lambda: self.filter_dock_to_stock_combined(
                    request,
                    effective_month,
                    selected_months=quarter_months or None,
                ),
                "outbound": lambda: self.filter_total_lead_time_performance(
                    request,
                    effective_month,
                    selected_months=quarter_months or None,
                ),
                "total lead time performance": lambda: self.filter_total_lead_time_performance(
                    request,
                    effective_month,
                    selected_months=quarter_months or None,
                ),
                "pods update": lambda: self.filter_pods_update(
                    request, effective_month
                ),
                "meeting points": lambda: self.meeting_points_tab(request),
                "project tracker": lambda: self.project_tracker_tab(request),
                "expiry": lambda: self.filter_expiry(
                    request,
                    effective_month,
                    selected_months=quarter_months or None,
                ),
                "Expiry": lambda: self.filter_expiry(
                    request,
                    effective_month,
                    selected_months=quarter_months or None,
                ),
            }

            # Iterate available tab filters
            for key, func in tab_filter_map.items():
                if key in selected_tab:
                    print(f"ğŸ“‚ Executing tab filter: {key}")
                    try:
                        result = func()

                        # Direct HttpResponse/JsonResponse
                        if isinstance(result, HttpResponse):
                            print(
                                "â„¹ï¸ Filter returned HttpResponse/JsonResponse; returning as-is."
                            )
                            return result

                        # Dict/list response â†’ JSON
                        if isinstance(result, (dict, list)):
                            return JsonResponse(result, safe=False)

                        # String response (likely HTML)
                        if isinstance(result, str):
                            return JsonResponse({"detail_html": result}, safe=False)

                        # Fallback conversion
                        return JsonResponse({"detail_html": str(result)}, safe=False)

                    except Exception as e:
                        import traceback

                        print("âŒ Error while executing tab filter:", key)
                        traceback.print_exc()
                        return JsonResponse(
                            {"error": f"Error in '{key}': {str(e)}"},
                            status=200,
                        )

            # Warehouse tab (ÙƒØ±ÙˆØª Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹Ø§Øª Ù…Ù† Ø§Ù„Ø£Ø¯Ù…Ù†)
            if selected_tab == "warehouse":
                print("ğŸ”¹ Loading Warehouse tab")
                wh_result = self.warehouse_tab(request)
                return JsonResponse(wh_result, safe=False)

            # All-in-One (never cached)
            if selected_tab == "all":
                print("ğŸ”¹ Loading All-in-One tab")
                all_result = self.filter_all_tabs(
                    request=request,
                    selected_month=effective_month,
                    selected_months=quarter_months or None,
                )
                return JsonResponse(all_result, safe=False)

            # Remaining tabs
            if selected_tab in ["rejections", "return & refusal"]:
                return JsonResponse(
                    self.filter_rejections_combined(
                        request,
                        effective_month,
                        selected_months=quarter_months or None,
                    ),
                    safe=False,
                )
            # airport / seaport tabs ØªÙ… Ø¥Ù„ØºØ§Ø¤Ù‡Ø§
            elif selected_tab in [
                "outbound",
                "total lead time performance",
                "total lead time preformance",
            ]:
                return JsonResponse(
                    self.filter_total_lead_time_performance(
                        request,
                        effective_month,
                        selected_months=quarter_months or None,
                    ),
                    safe=False,
                )
            elif selected_tab == "total lead time preformance -r":
                return JsonResponse(
                    self.filter_total_lead_time_roche(request, effective_month),
                    safe=False,
                )
            # data logger tab ØªÙ… Ø¥Ù„ØºØ§Ø¤Ù‡
            elif "dock to stock - roche" in selected_tab:
                return JsonResponse(
                    self.filter_dock_to_stock_roche(request, effective_month),
                    safe=False,
                )
            elif (selected_tab or "").lower() == "inbound":
                return JsonResponse(
                    self.filter_dock_to_stock_combined(
                        request,
                        effective_month,
                        selected_months=quarter_months or None,
                    ),
                    safe=False,
                )
            elif selected_tab == "pods update":
                return JsonResponse(
                    self.filter_pods_update(request, effective_month), safe=True
                )
            elif "rejection" in selected_tab:
                return JsonResponse(
                    self.filter_rejection_data(request, effective_month), safe=False
                )
            elif "dock to stock" in selected_tab:
                return JsonResponse(
                    self.filter_dock_to_stock_combined(
                        request,
                        effective_month,
                        selected_months=quarter_months or None,
                    ),
                    safe=False,
                )
            elif "meeting points" in selected_tab:
                return self.meeting_points_tab(request)
            elif selected_tab:
                raw_data = self.render_raw_sheet(request, selected_tab)
                return JsonResponse(raw_data, safe=False)
            else:
                return JsonResponse({"error": "âš ï¸ Please select a tab first."})

        # ====================== Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ø¹Ø§Ø¯ÙŠ ======================
        try:
            xls = pd.ExcelFile(excel_path, engine="openpyxl")
            all_sheets = [s.strip() for s in xls.sheet_names]

            MERGE_SHEETS = ["Urgent orders details", "Outbound details"]
            REJECTION_SHEETS = ["Rejection", "Rejection breakdown"]
            AIRPORT_SHEETS = ["Airport Clearance - Roche", "Airport Clearance - 3PL"]
            SEAPORT_SHEETS = ["Seaport clearance - 3pl", "Seaport clearance - Roche"]
            TOTAL_LEADTIME_SHEETS = [
                "Total lead time preformance",
                "Total lead time preformance -R",
            ]
            DOCK_TO_STOCK_SHEETS = ["Dock to stock", "Dock to stock - Roche"]
            # Ø§Ù„ØªØ§Ø¨Ø§Øª Ø§Ù„Ù„ÙŠ ØªØ­Ø¨ ØªØ§Ø®Ø¯Ù‡Ø§ Ù…Ù† Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯: Ø¹Ø¯Ù‘Ù„ Ù‡Ù†Ø§ (Ø£Ø³Ù…Ø§Ø¡ ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ø¥ÙƒØ³Ù„)
            EXCLUDE_SHEETS_BASE = ["Sheet2"]
            # Ù„Ùˆ Ø­Ø§Ø¨Ø¨ ØªØ­Ø°Ù ØªØ§Ø¨Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©: Ø²ÙˆØ¯ Ø£Ø³Ù…Ø§Ø¦Ù‡Ù… Ù‡Ù†Ø§ (Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ø¥ÙƒØ³Ù„)
            EXCLUDE_SHEETS_EXTRA = getattr(
                self.__class__, "EXCLUDE_TABS", []
            )  # Ø£Ùˆ Ø¹Ø¯Ù‘Ù„ EXCLUDE_TABS ÙÙŠ Ø£ÙˆÙ„ Ø§Ù„ÙƒÙ„Ø§Ø³
            EXCLUDE_SHEETS = list(EXCLUDE_SHEETS_BASE) + list(EXCLUDE_SHEETS_EXTRA)

            include_only = getattr(self.__class__, "INCLUDE_ONLY_TABS", None)
            if include_only:
                # Ø¹Ø±Ø¶ Ø§Ù„ØªØ§Ø¨Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙ‚Ø· (Ø§Ù„Ø§Ø³Ù… ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ø¥ÙƒØ³Ù„)
                include_set = {s.strip() for s in include_only}
                filtered_tabs = [t for t in all_sheets if t in include_set]
            else:
                filtered_tabs = [
                    t
                    for t in all_sheets
                    if t not in MERGE_SHEETS
                    and t not in REJECTION_SHEETS
                    and t not in AIRPORT_SHEETS
                    and t not in SEAPORT_SHEETS
                    and t not in TOTAL_LEADTIME_SHEETS
                    and t not in DOCK_TO_STOCK_SHEETS
                    and t not in EXCLUDE_SHEETS
                ]

            virtual_tabs = [
                self.DASHBOARD_TAB_NAME,
                "Inbound",
                "Outbound",
                "Return & Refusal",
                "PODs update",
                "Expiry",
                "Meeting Points & Action",
            ]
            if include_only:
                include_set_v = {s.strip() for s in include_only}
                filtered_tabs += [v for v in virtual_tabs if v in include_set_v]
            else:
                filtered_tabs += virtual_tabs

            ordered_tabs = [
                self.DASHBOARD_TAB_NAME,
                "Inbound",
                "Outbound",
                "Return & Refusal",
                "PODs update",
                "Expiry",
                "Meeting Points & Action",
            ]

            filtered_tabs = [tab for tab in ordered_tabs if tab in filtered_tabs]
            excel_tabs = [{"original": name, "display": name} for name in filtered_tabs]

        except Exception as e:
            print(f"âš ï¸ [ERROR] ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø´ÙŠØªØ§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù: {e}")
            excel_tabs = []

        # ======================================================
        # ğŸ—“ï¸ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒÙ„ Ø§Ù„Ø´Ù‡ÙˆØ± Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ø§Ù„Ù…Ù…ÙƒÙ†Ø©
        # ======================================================
        all_months = set()
        try:
            for sheet in xls.sheet_names:
                try:
                    df = pd.read_excel(excel_path, sheet_name=sheet, engine="openpyxl")
                    df.columns = df.columns.str.strip().str.title()
                    possible_date_cols = [
                        c
                        for c in df.columns
                        if "date" in c.lower() or "month" in c.lower()
                    ]
                    if not possible_date_cols:
                        continue
                    col = possible_date_cols[0]
                    df[col] = pd.to_datetime(df[col], errors="coerce")
                    df["MonthName"] = df[col].dt.strftime("%b")
                    all_months.update(df["MonthName"].dropna().unique().tolist())
                except Exception as inner_e:
                    continue

            all_months = sorted(
                all_months, key=lambda m: pd.to_datetime(m, format="%b")
            )
            print("ğŸ“… [INFO] Ø§Ù„Ø´Ù‡ÙˆØ± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† ÙƒÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª:", all_months)
        except Exception as e:
            print("âš ï¸ [ERROR] Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ù‡ÙˆØ±:", e)
            all_months = []

        meeting_points = MeetingPoint.objects.all().order_by("is_done", "-created_at")
        done_count = meeting_points.filter(is_done=True).count()
        total_count = meeting_points.count()

        # ÙˆØ¶Ø¹ ØªØ§Ø¨ Warehouse ÙÙ‚Ø·: ØªØ§Ø¨ ÙˆØ§Ø­Ø¯ ÙˆØ¹Ø±Ø¶ Ø§Ù„ÙƒØ±ÙˆØª Ù…Ù† Ø§Ù„Ø£Ø¯Ù…Ù†
        if getattr(self, "USE_WAREHOUSE_TAB_ONLY", False):
            excel_tabs = []
            selected_tab = "warehouse"
            data_is_uploaded = True
            warehouse_overview = context_helpers.get_warehouse_overview_list()
            clerk_interview_rows = context_helpers.get_clerk_interview_list()
            dashboard_theme = context_helpers.get_dashboard_theme_dict()
            phases_sections = context_helpers.get_phases_sections_list()
        else:
            data_is_uploaded = True
            warehouse_overview = []
            clerk_interview_rows = []
            dashboard_theme = context_helpers.get_dashboard_theme_dict()
            phases_sections = []

        all_tab_data = self.filter_all_tabs(
            request=request, selected_month=selected_month or None
        )

        render_context = {
            "data_is_uploaded": data_is_uploaded,
            "months": all_months,
            "excel_tabs": excel_tabs,
            "active_tab": selected_tab or "all",
            "tab_summaries": [],
            "form": ExcelUploadForm(),
            "meeting_points": meeting_points,
            "done_count": done_count,
            "total_count": total_count,
            "all_tab_data": all_tab_data,
            "raw_tab_data": None,
            "warehouse_overview": warehouse_overview,
            "clerk_interview_rows": clerk_interview_rows,
            "dashboard_theme": dashboard_theme,
            "recommendations": context_helpers.get_recommendations_list(),
            "weekly_tracker_rows": context_helpers.get_weekly_project_tracker_list(),
            "progress_status_rows": context_helpers.get_progress_status_list(),
            "potential_challenges_rows": context_helpers.get_potential_challenges_list(),
            "project_tracker_items": context_helpers.get_project_tracker_list(
                project_type=request.GET.get("project_type") or None
            ),
        }
        if (selected_tab or "").lower() == "dashboard":
            try:
                dashboard_ctx = self._get_dashboard_include_context(request)
                render_context.update(dashboard_ctx)
            except Exception as e:
                import traceback
                traceback.print_exc()
                print(f"âš ï¸ [Dashboard include context] {e}")

        return render(request, self.template_name, render_context)

    def post(self, request):
        print("ğŸ“¥ [DEBUG] ØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ post()")  # âœ… Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø¯Ø§Ù„Ø©

        entered_code = request.POST.get("upload_code", "").strip()
        print(f"ğŸ”‘ [DEBUG] Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…Ø¯Ø®Ù„: {entered_code}")

        # âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙˆØ¯
        if entered_code != self.correct_code:
            print("âŒ [DEBUG] Ø§Ù„ÙƒÙˆØ¯ ØºÙŠØ± ØµØ­ÙŠØ­!")
            if request.headers.get("x-requested-with") == "XMLHttpRequest":
                return JsonResponse(
                    {"error": "âŒ Invalid code. Please try again."}, status=403
                )
            messages.error(request, "âŒ Invalid code. Please try again.")
            return redirect(request.path)

        # âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹
        form = ExcelUploadForm(request.POST, request.FILES)
        if not form.is_valid():
            print("âš ï¸ [DEBUG] Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± ØµØ§Ù„Ø­ Ø£Ùˆ Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ù…Ù„Ù.")
            if request.headers.get("x-requested-with") == "XMLHttpRequest":
                return JsonResponse(
                    {"error": "âš ï¸ Please select an Excel file."}, status=400
                )
            return render(
                request, self.template_name, {"form": form, "data_is_uploaded": False}
            )

        # âœ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù (ÙŠØ¯Ø¹Ù… .xlsx Ùˆ .xlsm Ù…Ø«Ù„ all sheet.xlsm)
        excel_file = form.cleaned_data["excel_file"]
        folder_path = os.path.join(settings.MEDIA_ROOT, "excel_uploads")
        os.makedirs(folder_path, exist_ok=True)
        file_name = getattr(excel_file, "name", "") or ""
        is_dashboard_file = _is_dashboard_excel_filename(file_name)

        if is_dashboard_file:
            # âœ… Ù…Ù„Ù Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ (Ø´ÙŠØª ØªØ§Ù†ÙŠ): Aramco_Tamer3PL_KPI_Dashboard.xlsx â€” Ù„Ù„ØªØ§Ø¨ Dashboard ÙÙ‚Ø·
            file_path = os.path.join(folder_path, DASHBOARD_EXCEL_FILENAME)
            print(f"ğŸ“Š [DEBUG] Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯: {file_name} â†’ {file_path}")
        else:
            # âœ… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (all_sheet / latest) â€” Ù„Ø¨Ø§Ù‚ÙŠ Ø§Ù„ØªØ§Ø¨Ø§Øª
            ext = os.path.splitext(file_name)[1] or ".xlsx"
            if ext.lower() not in (".xlsx", ".xlsm"):
                ext = ".xlsx"
            file_path = os.path.join(folder_path, "latest" + ext)

        try:
            if not is_dashboard_file:
                # âœ… Ø­Ø°Ù Ø£ÙŠ Ù…Ù„Ù latest Ù‚Ø¯ÙŠÙ… (xlsx Ø£Ùˆ xlsm) Ù„ØªÙØ§Ø¯ÙŠ Ø¨Ù‚Ø§Ø¡ Ù…Ù„Ù Ø¨Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯ Ø§Ù„Ø¢Ø®Ø±
                for old_name in ("latest.xlsx", "latest.xlsm"):
                    old_path = os.path.join(folder_path, old_name)
                    if os.path.exists(old_path):
                        try:
                            os.chmod(old_path, 0o644)
                            os.remove(old_path)
                            print(f"ğŸ—‘ï¸ [DEBUG] ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ…: {old_path}")
                        except Exception as e:
                            print(f"âš ï¸ [DEBUG] ØªØ­Ø°ÙŠØ± Ø­Ø°Ù {old_name}: {e}")
            if os.path.exists(file_path):
                try:
                    os.chmod(file_path, 0o644)
                    os.remove(file_path)
                    print(f"ğŸ—‘ï¸ [DEBUG] ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ…: {file_path}")
                except PermissionError as pe:
                    print(
                        f"âš ï¸ [DEBUG] ØªØ­Ø°ÙŠØ±: Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ… (PermissionError): {pe}"
                    )
                    temp_path = os.path.join(folder_path, "temp_upload.xlsx")
                    with open(temp_path, "wb+") as destination:
                        for chunk in excel_file.chunks():
                            destination.write(chunk)
                    try:
                        os.replace(temp_path, file_path)
                        print(f"âœ… [DEBUG] ØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ù„Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… os.replace")
                    except Exception as replace_error:
                        print(
                            f"âš ï¸ [DEBUG] ØªØ­Ø°ÙŠØ±: Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ù„Ù: {replace_error}"
                        )
                        file_path = temp_path
                except Exception as delete_error:
                    print(f"âš ï¸ [DEBUG] ØªØ­Ø°ÙŠØ±: Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ…: {delete_error}")

            # âœ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯
            with open(file_path, "wb+") as destination:
                for chunk in excel_file.chunks():
                    destination.write(chunk)

            try:
                os.chmod(file_path, 0o644)
            except Exception as chmod_error:
                print(f"âš ï¸ [DEBUG] ØªØ­Ø°ÙŠØ±: Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØºÙŠÙŠØ± ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…Ù„Ù: {chmod_error}")

            print(f"âœ… [DEBUG] ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ: {file_path}")

            # âœ… Ø­ÙØ¸ Ø§Ù„Ù…Ø³Ø§Ø± ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù (Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø£Ùˆ Ø±Ø¦ÙŠØ³ÙŠ)
            if is_dashboard_file:
                request.session["dashboard_excel_path"] = file_path
                print(f"ğŸ’¾ [DEBUG] ØªÙ… Ø­ÙØ¸ Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©: {file_path}")
            else:
                request.session["uploaded_excel_path"] = file_path
                print(f"ğŸ’¾ [DEBUG] ØªÙ… Ø­ÙØ¸ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©: {file_path}")
            request.session.save()

            # âœ… Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´ Ø¨Ø¹Ø¯ Ø±ÙØ¹ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯
            try:
                cache.clear()
                print(f"ğŸ—‘ï¸ [DEBUG] ØªÙ… Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´")
            except Exception as cache_error:
                print(f"âš ï¸ [DEBUG] ØªØ­Ø°ÙŠØ±: Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´: {cache_error}")

            # âœ… Ø¥Ø±Ø¬Ø§Ø¹ response
            if request.headers.get("x-requested-with") == "XMLHttpRequest":
                return JsonResponse(
                    {"success": True, "message": "âœ… File uploaded successfully!"}
                )
            messages.success(request, "âœ… File uploaded successfully!")
            return redirect(request.path)
        except Exception as e:
            import traceback

            error_trace = traceback.format_exc()
            print(f"âŒ [DEBUG] Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù: {e}")
            print(f"âŒ [DEBUG] Traceback:\n{error_trace}")
            if request.headers.get("x-requested-with") == "XMLHttpRequest":
                return JsonResponse(
                    {"error": f"âŒ Error saving file: {str(e)}"}, status=500
                )
            messages.error(request, f"âŒ Error saving file: {str(e)}")
            return redirect(request.path)

    def export_dashboard_excel(
        self, request, selected_month=None, selected_months=None
    ):
        """
        ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ Ø§Ù„Ù…Ø±ÙÙˆØ¹ (Roche KPI new.xlsx) ÙÙ‚Ø· Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„ØªÙ†Ø³ÙŠÙ‚
        """
        from openpyxl import load_workbook

        # ğŸ“‚ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ "Roche KPI new.xlsx" ÙÙŠ Ù…Ø¬Ù„Ø¯ media
        folder_path = os.path.join(settings.MEDIA_ROOT, "excel_uploads")
        original_excel_path = os.path.join(folder_path, "Roche KPI new.xlsx")

        # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ØŒ Ø¬Ø±Ø¨ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† latest.xlsx ÙƒØ¨Ø¯ÙŠÙ„
        if not os.path.exists(original_excel_path):
            latest_path = os.path.join(folder_path, "latest.xlsx")
            if os.path.exists(latest_path):
                original_excel_path = latest_path
                print(
                    f"ğŸ“„ [EXPORT] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ latest.xlsx Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Roche KPI new.xlsx"
                )
            else:
                # Ø¬Ø±Ø¨ Ù…Ù† Ø§Ù„Ø¬Ù„Ø³Ø©
                saved_path = request.session.get("uploaded_excel_path")
                if saved_path and os.path.exists(saved_path):
                    original_excel_path = saved_path
                    print(f"ğŸ“„ [EXPORT] ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø§Ù„Ø¬Ù„Ø³Ø©: {saved_path}")
                else:
                    print(f"âš ï¸ [EXPORT] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ")
                    return HttpResponse(
                        "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ (Roche KPI new.xlsx)",
                        status=404,
                    )

        try:
            print(f"ğŸ“„ [EXPORT] Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ: {original_excel_path}")

            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… openpyxl Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ÙˆØ§Ù„Ø£Ù„ÙˆØ§Ù†
            workbook = load_workbook(original_excel_path)

            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù ÙÙŠ BytesIO Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
            output = BytesIO()
            workbook.save(output)
            output.seek(0)

            print(f"âœ… [EXPORT] ØªÙ… Ù†Ø³Ø® Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ Ø¨Ù†Ø¬Ø§Ø­ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚")

            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù„Ù„ØªÙ†Ø²ÙŠÙ„
            filename_parts = ["Roche KPI Dashboard Data"]
            if selected_months:
                filename_parts.append("-".join(selected_months))
            elif selected_month:
                filename_parts.append(selected_month)
            safe_filename = " ".join(filename_parts)

            response = HttpResponse(
                output.getvalue(),
                content_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )
            response["Content-Disposition"] = (
                f'attachment; filename="{safe_filename}.xlsx"'
            )
            return response

        except Exception as e:
            print(f"âš ï¸ [EXPORT] Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¹Ù†Ø¯ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ: {e}")
            import traceback

            traceback.print_exc()
            return HttpResponse(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¹Ù†Ø¯ ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ù„Ù: {str(e)}", status=500)

    def render_raw_sheet(self, request, sheet_name):
        """Ø¹Ø±Ø¶ Ø£ÙŠ Ø´ÙŠØª ÙƒØ¬Ø¯ÙˆÙ„ Ø®Ø§Ù… Ø¥Ø°Ø§ Ù…ÙÙŠØ´ ÙÙ„ØªØ± Ø®Ø§Øµ"""
        print(f"ğŸŸ¢ [DEBUG] âœ… Ø¯Ø®Ù„ Ø¹Ù„Ù‰ render_raw_sheet() - Ø§Ù„ØªØ§Ø¨: {sheet_name}")

        # ğŸ“ Ø¬Ù„Ø¨ Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„
        excel_file_path = self.get_uploaded_file_path(request)
        if not excel_file_path or not os.path.exists(excel_file_path):
            print("âš ï¸ [ERROR] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Excel.")
            return {
                "detail_html": "<p class='text-danger'>âš ï¸ Excel file not found.</p>",
                "count": 0,
            }

        try:
            # ğŸ“– Ù‚Ø±Ø§Ø¡Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª
            xls = pd.ExcelFile(excel_file_path, engine="openpyxl")

            # ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø´ÙŠØª Ø¨Ø¯ÙˆÙ† Ø­Ø³Ø§Ø³ÙŠØ© Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù
            matching_sheet = next(
                (
                    s
                    for s in xls.sheet_names
                    if s.lower().strip() == sheet_name.lower().strip()
                ),
                None,
            )

            if not matching_sheet:
                print(
                    f"âš ï¸ [WARNING] Ø§Ù„ØªØ§Ø¨ '{sheet_name}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ù„Ø´ÙŠØªØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©: {xls.sheet_names}"
                )
                return {
                    "detail_html": f"<p class='text-danger'>âŒ Tab '{sheet_name}' does not exist in the file.</p>",
                    "count": 0,
                }

            # ğŸ§¾ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø´ÙŠØª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚
            df = pd.read_excel(
                excel_file_path, sheet_name=matching_sheet, engine="openpyxl"
            )

            # ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            df.columns = df.columns.str.strip().str.title()

            # ğŸ—“ï¸ ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø´Ù‡Ø± Ø¥Ø°Ø§ ØªÙ… Ø§Ø®ØªÙŠØ§Ø±Ù‡
            selected_month = request.GET.get("month")
            if selected_month:
                date_cols = [c for c in df.columns if "Date" in c]
                if date_cols:
                    df[date_cols[0]] = pd.to_datetime(df[date_cols[0]], errors="coerce")
                    df["Month"] = df[date_cols[0]].dt.strftime("%b")
                    df = df[df["Month"] == selected_month]

            # ğŸ§© Ø·Ø¨Ø§Ø¹Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if df.empty:
                print(
                    f"âš ï¸ [WARNING] Ø§Ù„Ø´ÙŠØª '{matching_sheet}' ÙØ§Ø¶ÙŠ Ø£Ùˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ„ØªØ±Ø©!"
                )
            else:
                print(
                    f"âœ… [INFO] Ø§Ù„Ø´ÙŠØª '{matching_sheet}' Ø§ØªÙ‚Ø±Ø£ Ø¨Ù†Ø¬Ø§Ø­ ÙˆÙÙŠÙ‡ {len(df)} ØµÙÙˆÙ."
                )
                print(f"ğŸ“‹ [COLUMNS] Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {list(df.columns)}")

            # ğŸ”¢ ØªØ¬Ù‡ÙŠØ² Ø£ÙˆÙ„ 50 ØµÙ ÙÙ‚Ø· Ù„Ù„Ø¹Ø±Ø¶
            data = df.head(50).to_dict(orient="records")
            for row in data:
                for col, val in row.items():
                    row[col] = self.safe_format_value(val)

            # ğŸ§© ØªÙˆÙ„ÙŠØ¯ HTML Ù…Ù† Ø§Ù„ØªÙ…Ø¨Ù„Øª
            tab_data = {
                "name": matching_sheet,
                "columns": df.columns.tolist(),
                "data": data,
            }
            month_norm = self.apply_month_filter_to_tab(tab_data, selected_month)

            html = render_to_string(
                "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
                {"tab": tab_data, "selected_month": month_norm},
            )

            # ğŸ“¤ Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù„Ù„ÙˆØ§Ø¬Ù‡Ø©
            return {"detail_html": html, "count": len(df), "tab_data": tab_data}

        except Exception as e:
            print(f"âŒ [ERROR] Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø´ÙŠØª '{sheet_name}': {e}")
            return {
                "detail_html": f"<p class='text-danger'>âš ï¸ Error while reading sheet: {e}</p>",
                "count": 0,
            }

    def filter_by_month(self, request, selected_month):
        import pandas as pd
        from django.template.loader import render_to_string

        try:
            excel_file_path = self.get_uploaded_file_path(request)
            xls = pd.ExcelFile(excel_file_path, engine="openpyxl")

            # ğŸ§© ØªØ­Ø¯ÙŠØ¯ Ø§Ø³Ù… Ø§Ù„Ø´ÙŠØª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§
            # Ù†Ø­Ø§ÙˆÙ„ Ù†Ø®ØªØ§Ø± Ø´ÙŠØª ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ "Data logger" Ø£Ùˆ "Dock to stock"
            possible_sheets = [
                s
                for s in xls.sheet_names
                if any(key in s.lower() for key in ["data logger", "dock to stock"])
            ]

            if not possible_sheets:
                print(
                    "âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ø´ÙŠØª ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Data logger Ø£Ùˆ Dock to stock"
                )
                return {
                    "error": "âš ï¸ No sheet containing Data logger or Dock to stock was found."
                }

            sheet_name = possible_sheets[0]  # Ù†Ø§Ø®Ø¯ Ø£ÙˆÙ„ ÙˆØ§Ø­Ø¯ Ù…Ø·Ø§Ø¨Ù‚
            print(f"ğŸ“„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø´ÙŠØª: {sheet_name}")

            df = pd.read_excel(
                excel_file_path, sheet_name=sheet_name, engine="openpyxl"
            )
        except Exception as e:
            return {"error": f"âš ï¸ Unable to read the tab: {e}"}

        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        df.columns = df.columns.str.strip()

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ®
        if "Month" not in df.columns:
            return {"error": "âš ï¸ Column 'Month' is missing."}

        # ØªØ­ÙˆÙŠÙ„/ØªØ·Ø¨ÙŠØ¹ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø´Ù‡Ø± Ù„Ù‚Ø¨ÙˆÙ„ ÙƒÙ„ Ø§Ù„ØµÙŠØº (ØªØ§Ø±ÙŠØ®ØŒ Ø§Ø®ØªØµØ§Ø±ØŒ Ø§Ø³Ù… ÙƒØ§Ù…Ù„ØŒ Ø±Ù‚Ù… 1-12)
        import calendar

        month_raw = df["Month"]
        # Ø­Ø§ÙˆÙ„ ØªØ­ÙˆÙŠÙ„Ù‡ Ù„ØªØ§Ø±ÙŠØ®Ø› Ø§Ù„Ù„ÙŠ ÙŠÙØ´Ù„ Ù‡Ù†Ø±Ø¬Ù‘Ø¹Ù‡ Ù†ØµÙŠØ§Ù‹
        parsed = pd.to_datetime(month_raw, errors="coerce")
        month_abbr_from_dates = parsed.dt.strftime("%b")

        # Ø·Ø¨Ù‘Ø¹ Ø§Ù„Ù†ØµÙˆØµ: Ø£ÙˆÙ„ 3 Ø­Ø±ÙˆÙ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ø´Ù‡Ø± (Jan/February -> Feb)ØŒ ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… 1-12 Ø¥Ù„Ù‰ Ø§Ø®ØªØµØ§Ø±
        def normalize_month_val(v):
            if pd.isna(v):
                return None
            s = str(v).strip()
            # Ø£Ø±Ù‚Ø§Ù…
            if s.isdigit():
                n = int(s)
                if 1 <= n <= 12:
                    return calendar.month_abbr[n]
            # Ø£Ø³Ù…Ø§Ø¡ ÙƒØ§Ù…Ù„Ø© Ø£Ùˆ Ù…Ø®ØªØµØ±Ø©
            # Ø¬Ø±Ù‘Ø¨ Ø§Ø³Ù… ÙƒØ§Ù…Ù„
            for i, mname in enumerate(calendar.month_name):
                if i == 0:
                    continue
                if s.lower() == mname.lower():
                    return calendar.month_abbr[i]
            # Ø¬Ø±Ù‘Ø¨ Ø§Ø®ØªØµØ§Ø± Ø¬Ø§Ù‡Ø² Ø£Ùˆ Ù†Øµ Ø¹Ø§Ù… -> Ø£ÙˆÙ„ 3 Ø£Ø­Ø±Ù Ø¨Ø­Ø§Ù„Ø© Capitalize
            return s[:3].capitalize()

        month_abbr_fallback = month_raw.apply(normalize_month_val)
        # Ø§Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø§Ù„ØªØ§Ø±ÙŠØ® Ø­ÙŠØ« Ù…ØªØ§Ø­ ÙˆØ¥Ù„Ø§ fallback
        df["Month"] = month_abbr_from_dates.where(~parsed.isna(), month_abbr_fallback)

        # ØªÙˆØ­ÙŠØ¯ ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù…Ø®ØªØ§Ø± (Ø£Ù…Ø§Ù† Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©)
        selected_month_norm = (
            str(selected_month).strip().capitalize() if selected_month else None
        )

        # Ø­ÙØ¸ Ø§Ù„Ø´Ù‡Ø± ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø© Ù„ÙŠØ³ØªØ®Ø¯Ù…Ù‡ Ø¨Ø§Ù‚ÙŠ Ø§Ù„ØªØ§Ø¨Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù„Ø§Ø­Ù‚Ø©
        try:
            if selected_month_norm:
                request.session["selected_month"] = selected_month_norm
        except Exception:
            # ÙÙŠ Ø­Ø§Ù„ Ø¹Ø¯Ù… ØªÙˆÙØ± Ø§Ù„Ø¬Ù„Ø³Ø© (Ù…Ø«Ù„Ø§Ù‹ ÙÙŠ Ø·Ù„Ø¨Ø§Øª ØºÙŠØ± Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù…Ø³ØªØ®Ø¯Ù…)ØŒ Ù†ØªØ¬Ø§ÙˆØ² Ø¨Ù‡Ø¯ÙˆØ¡
            pass

        # ÙÙ„ØªØ±Ø© Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù…Ø®ØªØ§Ø± Ø£ÙˆÙ„Ø§Ù‹
        month_df = df[df["Month"] == selected_month_norm]

        if month_df.empty:
            return {
                "error": f"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø© Ù„Ù„Ø´Ù‡Ø± {selected_month_norm}.",
                "month": selected_month_norm,
                "sheet_name": sheet_name,
            }

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ KPI Ø¨Ø´ÙƒÙ„ Ù…Ø±Ù† (Ù…Ù…ÙƒÙ† ÙŠÙƒÙˆÙ† Ø§Ø³Ù…Ù‡ Ù…Ø®ØªÙ„Ù)
        kpi_miss_col = None
        possible_kpi_names = [
            "kpi miss in",
            "kpi miss",
            "kpi",
            "miss",
            "clearance handling kpi",
            "transit kpi",
        ]

        for kpi_name in possible_kpi_names:
            kpi_miss_col = next(
                (col for col in df.columns if str(col).strip().lower() == kpi_name),
                None,
            )
            if kpi_miss_col:
                break

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        total = len(month_df.drop_duplicates())

        # Ù„Ùˆ ÙˆØ¬Ø¯Ù†Ø§ Ø¹Ù…ÙˆØ¯ KPIØŒ Ù†Ø­Ø³Ø¨ Miss
        if kpi_miss_col:
            miss_df = month_df[month_df[kpi_miss_col].astype(str).str.lower() == "miss"]
            miss_count = len(miss_df)
            valid = total - miss_count
        else:
            # Ù„Ùˆ Ù…ÙÙŠØ´ Ø¹Ù…ÙˆØ¯ KPIØŒ Ù†Ø¹Ø±Ø¶ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯ÙˆÙ† ÙÙ„ØªØ±Ø© Miss
            miss_df = pd.DataFrame()  # Ø¬Ø¯ÙˆÙ„ ÙØ§Ø¶ÙŠ
            miss_count = 0
            valid = total
            print(
                f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ KPIØŒ Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø´Ù‡Ø± {selected_month_norm}"
            )

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ HTML (Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø£ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø­Ø§Ù„ÙŠ)
        dedup_html = month_df.to_html(
            classes="table table-bordered table-hover text-center",
            index=False,
            border=0,
        )
        miss_html = miss_df.to_html(
            classes="table table-bordered table-hover text-center text-danger",
            index=False,
            border=0,
        )

        print(
            f"ğŸ“† ÙÙ„ØªØ±Ø© Ø§Ù„Ø´Ù‡Ø± {selected_month}: Ø¥Ø¬Ù…Ø§Ù„ÙŠ={total}, Miss={miss_count}, Valid={valid}"
        )

        hit_pct = int(round((valid / total) * 100)) if total else 0

        # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªÙ…Ø¨Ù„Øª Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠ (Ø¬Ø¯Ø§ÙˆÙ„ + Ø´Ø§Ø±Øª)
        month_df_display = month_df.fillna("").astype(str)
        sub_tables = [
            {
                "title": f"{sheet_name} â€“ {selected_month_norm} (ÙƒÙ„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª)",
                "columns": month_df_display.columns.tolist(),
                "data": month_df_display.to_dict(orient="records"),
            }
        ]

        if miss_count > 0:
            miss_df_display = miss_df.fillna("").astype(str)
            sub_tables.append(
                {
                    "title": f"{sheet_name} â€“ {selected_month_norm} (Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ØªØ£Ø®Ø±Ø©)",
                    "columns": miss_df_display.columns.tolist(),
                    "data": miss_df_display.to_dict(orient="records"),
                }
            )

        summary_table = [
            {"Ø§Ù„Ù…Ø¤Ø´Ø±": "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø´Ø­Ù†Ø§Øª", "Ø§Ù„Ù‚ÙŠÙ…Ø©": int(total)},
            {"Ø§Ù„Ù…Ø¤Ø´Ø±": "Ø´Ø­Ù†Ø§Øª ØµØ­ÙŠØ­Ø©", "Ø§Ù„Ù‚ÙŠÙ…Ø©": int(valid)},
            {"Ø§Ù„Ù…Ø¤Ø´Ø±": "Ø´Ø­Ù†Ø§Øª Miss", "Ø§Ù„Ù‚ÙŠÙ…Ø©": int(miss_count)},
            {"Ø§Ù„Ù…Ø¤Ø´Ø±": "Hit %", "Ø§Ù„Ù‚ÙŠÙ…Ø©": f"{hit_pct}%"},
        ]
        sub_tables.append(
            {
                "title": f"{sheet_name} â€“ {selected_month_norm} (Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ø¯Ø§Ø¡)",
                "columns": ["Ø§Ù„Ù…Ø¤Ø´Ø±", "Ø§Ù„Ù‚ÙŠÙ…Ø©"],
                "data": summary_table,
            }
        )

        chart_title = f"{sheet_name} â€“ {selected_month_norm} Performance"
        chart_data = [
            {
                "title": chart_title,
                "type": "column",
                "name": "Valid Shipments",
                "color": "#4caf50",
                "showInLegend": True,
                "dataPoints": [{"label": selected_month_norm, "y": int(valid)}],
                "related_table": sub_tables[0]["title"],
            },
            {
                "title": chart_title,
                "type": "column",
                "name": "Miss Shipments",
                "color": "#f44336",
                "showInLegend": True,
                "dataPoints": [{"label": selected_month_norm, "y": int(miss_count)}],
                "related_table": sub_tables[0]["title"],
            },
            {
                "title": chart_title,
                "type": "line",
                "name": "Hit %",
                "color": "#1976d2",
                "showInLegend": True,
                "dataPoints": [{"label": selected_month_norm, "y": hit_pct}],
                "related_table": sub_tables[-1]["title"],
            },
        ]

        tab_data = {
            "name": f"{sheet_name} ({selected_month_norm})",
            "sub_tables": sub_tables,
            "chart_data": chart_data,
            "chart_title": chart_title,
        }
        month_norm_filtered = self.apply_month_filter_to_tab(
            tab_data, selected_month_norm
        )

        combined_html = render_to_string(
            "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
            {"tab": tab_data, "selected_month": month_norm_filtered},
        )

        return {
            "month": selected_month_norm,
            "selected_month": selected_month_norm,
            "sheet_name": sheet_name,
            "total_shipments": total,
            "miss_count": miss_count,
            "valid_shipments": valid,
            "hit_pct": hit_pct,
            "dedup_html": dedup_html,
            "miss_html": miss_html,
            "html": combined_html,
            "detail_html": combined_html,
            "chart_data": chart_data,
            "chart_title": chart_title,
            "tab_data": tab_data,
        }

    def _resolve_quarter_months(self, selected_quarter):
        if not selected_quarter:
            return []

        import re

        quarter_pattern = re.compile(r"^Q([1-4])(?:[-\s]?(\d{4}))?$", re.IGNORECASE)
        match = quarter_pattern.match(str(selected_quarter).strip())
        if not match:
            raise ValueError(f"âš ï¸ ÙƒÙˆØ±ØªØ± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {selected_quarter}")

        quarter_number = int(match.group(1))
        quarter_months_map = {
            1: ["Jan", "Feb", "Mar"],
            2: ["Apr", "May", "Jun"],
            3: ["Jul", "Aug", "Sep"],
            4: ["Oct", "Nov", "Dec"],
        }

        months = quarter_months_map.get(quarter_number, [])
        if not months:
            raise ValueError(f"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø´Ù‡ÙˆØ± Ù…Ø¹Ø±Ù‘ÙØ© Ù„Ù„ÙƒÙˆØ§Ø±ØªØ± {selected_quarter}.")
        return months

    def filter_by_quarter(self, request, selected_quarter):
        from django.template.loader import render_to_string
        import re

        if not selected_quarter:
            return {"error": "âš ï¸ Please select a valid quarter."}

        quarter_pattern = re.compile(r"^Q([1-4])(?:[-\s]?(\d{4}))?$", re.IGNORECASE)
        match = quarter_pattern.match(str(selected_quarter).strip())
        if not match:
            return {"error": f"âš ï¸ Unknown quarter: {selected_quarter}"}

        quarter_number = int(match.group(1))
        quarter_months_map = {
            1: ["Jan", "Feb", "Mar"],
            2: ["Apr", "May", "Jun"],
            3: ["Jul", "Aug", "Sep"],
            4: ["Oct", "Nov", "Dec"],
        }

        display_month_list = quarter_months_map.get(quarter_number, [])
        if not display_month_list:
            return {
                "error": f"âš ï¸ No months were defined for quarter {selected_quarter}."
            }

        try:
            total_lead_time_result = self.filter_total_lead_time_performance(
                request, selected_months=display_month_list
            )
        except Exception as exc:
            import traceback

            traceback.print_exc()
            total_lead_time_result = {
                "detail_html": f"<p class='text-danger text-center p-4'>âš ï¸ Error while loading Total Lead Time Performance: {exc}</p>"
            }

        section_html = (
            total_lead_time_result.get("detail_html")
            or total_lead_time_result.get("html")
            or "<p class='text-warning text-center p-4'>âš ï¸ No data available for this quarter.</p>"
        )

        section_wrapper = f"""
        <section class="quarter-section mb-5">
            <div class="d-flex justify-content-between align-items-center mb-3">
                <h4 class="mb-0 text-primary">Total Lead Time Performance â€“ Quarter {selected_quarter}</h4>
                <span class="badge bg-light text-dark px-3 py-2">{', '.join(display_month_list)}</span>
            </div>
            {section_html}
        </section>
        """

        header_html = f"""
        <div class="quarter-header text-center mb-4">
            <h3 class="fw-bold text-primary mb-1">Quarter {selected_quarter}</h3>
            <p class="text-muted mb-0">Months in scope: {', '.join(display_month_list)}</p>
        </div>
        """

        combined_html = (
            f"<div class='quarter-wrapper'>{header_html}{section_wrapper}</div>"
        )

        return {
            "quarter": selected_quarter,
            "months": ", ".join(display_month_list),
            "detail_html": combined_html,
            "html": combined_html,
            "chart_data": total_lead_time_result.get("chart_data", []),
            "chart_title": total_lead_time_result.get("chart_title"),
            "hit_pct": total_lead_time_result.get("hit_pct"),
        }

    def filter_all_tabs(self, request=None, selected_month=None, selected_months=None):
        cache.clear()
        try:
            month_for_filters = selected_month if not selected_months else None
            # âœ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ø­Ø§Ù„ÙŠ
            status_filter = "all"
            if request is not None and hasattr(request, "GET"):
                status_filter = request.GET.get("status", "all")

            # âœ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø± Ù…Ù„Ù Excel
            excel_path = self.get_uploaded_file_path(request)
            if not excel_path or not os.path.exists(excel_path):
                html = render_to_string(
                    "components/ui-kits/tab-bootstrap/components/dashboard-overview.html",
                    {"message": "âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Excel."},
                )
                return {"detail_html": html}

            # âœ… Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù€ overview_tab (Ù…Ù†Ù‡Ø§ Ù†Ø¨Ø¯Ø£ Ø§Ù„Ù†Ø³Ø¨)
            overview_data = self.overview_tab(
                request=request,
                selected_month=month_for_filters,
                selected_months=selected_months,
                from_all_in_one=True,
            )

            if not overview_data or "tab_cards" not in overview_data:
                html = render_to_string(
                    "components/ui-kits/tab-bootstrap/components/dashboard-overview.html",
                    {"message": "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø© Ù…Ù† overview_tab."},
                )
                return {"detail_html": html}

            # âœ… Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ§Ø¨Ø§Øª Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©
            excluded_tabs = [
                "return & refusal",
                "airport clearance",
                "seaport clearance",
                "data logger measurement",
            ]

            clean_tabs = []
            for tab in overview_data.get("tab_cards", []):
                name = tab.get("name", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
                name_lower = name.strip().lower()

                # âœ… Ø­Ø°Ù Ø§Ù„ØªØ§Ø¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
                if name_lower in excluded_tabs:
                    continue

                # âœ… Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©
                try:
                    hit = float(tab.get("hit_pct", 0))
                except Exception:
                    hit = 0
                hit = int(round(max(0, min(hit, 100))))

                # âœ… Ø§Ù„ØªØ§Ø±Ø¬Øª
                try:
                    target = float(tab.get("target_pct", 100))
                except Exception:
                    target = 100

                # âœ… Ù†Ø³ØªØ®Ø¯Ù… Ø£ÙŠ chart_data Ùˆ chart_type Ø±Ø§Ø¬Ø¹ÙŠÙ† Ù…Ù† Ø§Ù„Ù€ overview ÙƒÙ…Ø§ Ù‡ÙŠ
                chart_data = tab.get("chart_data", []) or []
                chart_type = tab.get("chart_type", "bar")

                clean_tabs.append(
                    {
                        "name": name,
                        "hit_pct": hit,
                        "target_pct": int(target),
                        "count": tab.get("count", 0),
                        "chart_type": chart_type,
                        "chart_data": chart_data,
                    }
                )

            # âœ… PODs Update - Ø¥Ø¶Ø§ÙØ© Ù…Ø¹ Ø§Ù„Ø´Ø§Ø±ØªØ§Øª
            pods_data = self.filter_pods_update(request, month_for_filters)
            if pods_data and pods_data.get("hit_pct") is not None:
                try:
                    hit_pods = float(pods_data.get("hit_pct", 0))
                except:
                    hit_pods = 0
                hit_pods = int(round(max(0, min(hit_pods, 100))))

                existing_names = [t["name"].strip().lower() for t in clean_tabs]
                if "pods update" not in existing_names:
                    # âœ… Ø¬Ù„Ø¨ Ø§Ù„Ø´Ø§Ø±ØªØ§Øª Ù…Ù† pods_data
                    pods_chart_data = pods_data.get("chart_data", [])
                    pods_chart_type = "column"
                    if pods_chart_data and len(pods_chart_data) > 0:
                        pods_chart_type = pods_chart_data[0].get("type", "column")

                    clean_tabs.append(
                        {
                            "name": "PODs update",
                            "hit_pct": hit_pods,
                            "target_pct": 100,
                            "count": pods_data.get("count", 0),
                            "chart_type": pods_chart_type,
                            "chart_data": pods_chart_data,
                        }
                    )

            # âœ… ØªØ±ØªÙŠØ¨ Ø§Ù„ØªØ§Ø¨Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© (Ø¨Ø¯ÙˆÙ† Ø§Ù„ØªØ§Ø¨Ø§Øª Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©)
            desired_order = [
                "Inbound",
                "Outbound",
                "PODs update",
            ]
            clean_tabs.sort(
                key=lambda x: (
                    desired_order.index(x["name"])
                    if x["name"] in desired_order
                    else len(desired_order)
                )
            )

            # âœ… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙŠØªÙ†Ø¬ - Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· (Ù…Ø«Ù„ meeting_points_tab)
            meeting_points = MeetingPoint.objects.all().order_by(
                "is_done", "-created_at"
            )

            if status_filter == "done":
                meeting_points = meeting_points.filter(is_done=True)
            elif status_filter == "pending":
                meeting_points = meeting_points.filter(is_done=False)

            meeting_data = [
                {
                    "id": p.id,
                    "description": p.description,
                    "assigned_to": getattr(p, "assigned_to", "") or "",
                    "status": "Done" if p.is_done else "Pending",
                    "created_at": p.created_at,
                    "target_date": p.target_date,
                }
                for p in meeting_points
            ]

            tabs_for_display = clean_tabs

            warehouse_overview = context_helpers.get_warehouse_overview_list()
            clerk_interview_rows = context_helpers.get_clerk_interview_list()
            dashboard_theme = context_helpers.get_dashboard_theme_dict()
            phases_sections = context_helpers.get_phases_sections_list()
            html = render_to_string(
                "components/ui-kits/tab-bootstrap/components/dashboard-overview.html",
                {
                    "tabs": tabs_for_display,
                    "tabs_json": json.dumps(tabs_for_display),
                    "meeting_data": meeting_data,
                    "status_filter": status_filter,
                    "warehouse_overview": warehouse_overview,
                    "clerk_interview_rows": clerk_interview_rows,
                    "dashboard_theme": dashboard_theme,
                    "phases_sections": phases_sections,
                },
                request=request,
            )

            return {"detail_html": html}

        except Exception as e:
            traceback.print_exc()
            return {
                "detail_html": f"<div class='alert alert-danger'>âš ï¸ Error: {e}</div>"
            }

    def get_meeting_points_section_html(self, request, status_filter="all"):
        """
        âœ… Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø¥Ø±Ø¬Ø§Ø¹ HTML Ù‚Ø³Ù… Meeting Points ÙÙ‚Ø·
        """
        try:
            meeting_points = MeetingPoint.objects.all().order_by(
                "is_done", "-created_at"
            )

            if status_filter == "done":
                meeting_points = meeting_points.filter(is_done=True)
            elif status_filter == "pending":
                meeting_points = meeting_points.filter(is_done=False)

            meeting_data = [
                {
                    "id": p.id,
                    "description": p.description,
                    "assigned_to": getattr(p, "assigned_to", "") or "",
                    "status": "Done" if p.is_done else "Pending",
                    "created_at": p.created_at,
                    "target_date": p.target_date,
                }
                for p in meeting_points
            ]

            # âœ… Ø¥Ø±Ø¬Ø§Ø¹ HTML Ù‚Ø³Ù… Meeting Points ÙÙ‚Ø·
            html = render_to_string(
                "components/ui-kits/tab-bootstrap/components/meeting_points_section.html",
                {
                    "meeting_data": meeting_data,
                    "status_filter": status_filter,
                },
                request=request,
            )
            return html
        except Exception as e:
            import traceback

            traceback.print_exc()
            return f"<div class='alert alert-danger'>âš ï¸ Error: {e}</div>"

    def filter_total_lead_time_detail(self, request, selected_month=None):
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø§Ù„Ø¬Ù„Ø³Ø©
            excel_path = request.session.get("uploaded_excel_path")
            if not excel_path or not os.path.exists(excel_path):
                return {"error": "âš ï¸ Excel file was not found in the session."}

            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø´ÙŠØª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
            df = pd.read_excel(
                excel_path, sheet_name="Total lead time preformance", engine="openpyxl"
            )
            df.columns = df.columns.str.strip().str.lower()

            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            required_cols = [
                "month",
                "outbound delivery",
                "kpi",
                "reason group",
                "miss reason",
            ]
            for col in required_cols:
                if col not in df.columns:
                    return {"error": f"âš ï¸ Column '{col}' does not exist in the sheet."}

            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ Ø§Ù„Ø´Ù‡Ø±
            df["month"] = (
                pd.to_datetime(df["month"], errors="coerce")
                .dt.strftime("%b")
                .str.capitalize()
            )

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ù‡ÙˆØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙØ¹Ù„ÙŠÙ‹Ø§ ÙÙŠ Ø§Ù„Ù…Ù„Ù (Ø¨ØªØ±ØªÙŠØ¨ Ø²Ù…Ù†ÙŠ)
            existing_months = df["month"].dropna().unique().tolist()
            existing_months = sorted(
                existing_months, key=lambda x: pd.to_datetime(x, format="%b").month
            )

            if not existing_months:
                return {"error": "âš ï¸ No valid months were found in the file."}

            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø­Ø³Ø¨ Ø±Ù‚Ù… Ø§Ù„Ø´Ø­Ù†Ø©
            df = df.drop_duplicates(subset=["outbound delivery"])

            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
            df["reason group"] = df["reason group"].astype(str).str.strip().str.lower()
            df["kpi"] = df["kpi"].astype(str).str.strip().str.lower()

            # Ø¨ÙŠØ§Ù†Ø§Øª Miss Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù€ 3PL ÙÙ‚Ø·
            df_miss_3pl = df[
                (df["kpi"] == "miss") & (df["reason group"] == "3pl")
            ].copy()

            # ğŸ”¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¨Ø¨ ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ©)
            df_miss_3pl["miss reason"] = (
                df_miss_3pl["miss reason"]
                .astype(str)
                .str.strip()
                .str.replace(r"\s+", " ", regex=True)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
            )

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø®ØªÙ„Ø§Ù Ø§Ù„Ø­Ø±ÙˆÙ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ (case-insensitive grouping)
            df_miss_3pl["_miss_reason_key"] = df_miss_3pl["miss reason"].str.lower()

            # Ø¨ÙŠØ§Ù†Ø§Øª On Time Delivery (Hit)
            df_hit = df[df["kpi"] != "miss"].copy()

            # ØªØ¬Ù…ÙŠØ¹ Miss Ø­Ø³Ø¨ Ø§Ù„Ø³Ø¨Ø¨ ÙˆØ§Ù„Ø´Ù‡Ø± (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ù…ÙˆØ­Ø¯ Ù„Ù„Ø­Ø±ÙˆÙ)
            miss_grouped = (
                df_miss_3pl.groupby(["_miss_reason_key", "month"], as_index=False)
                .agg(
                    {
                        "miss reason": "first",
                        "month": "first",
                        "_miss_reason_key": "count",
                    }
                )
                .rename(columns={"_miss_reason_key": "count"})
            )

            # Pivot Ø§Ù„Ø¬Ø¯ÙˆÙ„
            miss_pivot = miss_grouped.pivot_table(
                index="miss reason", columns="month", values="count", fill_value=0
            )

            # ØªØ£ÙƒØ¯ Ø£Ù† ÙƒÙ„ Ø§Ù„Ø´Ù‡ÙˆØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„
            for m in existing_months:
                if m not in miss_pivot.columns:
                    miss_pivot[m] = 0
            miss_pivot = miss_pivot[existing_months]

            # Ø­Ø³Ø§Ø¨ On Time Delivery Ù„ÙƒÙ„ Ø´Ù‡Ø±
            hit_counts = (
                df_hit.groupby("month").size().reindex(existing_months, fill_value=0)
            )

            # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            final_df = miss_pivot.copy()
            final_df.loc["On Time Delivery"] = hit_counts
            final_df = final_df.fillna(0)

            # ØªØ±ØªÙŠØ¨ Ø§Ù„ØµÙÙˆÙ Ø¨Ø­ÙŠØ« On Time ÙÙŠ Ø§Ù„Ø£Ø¹Ù„Ù‰
            final_df = final_df.reindex(
                ["On Time Delivery"]
                + [r for r in final_df.index if r != "On Time Delivery"]
            )

            # Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
            final_df["Total"] = final_df.sum(axis=1)

            # ØµÙ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            final_df.loc["TOTAL"] = final_df.sum(numeric_only=True)

            # ğŸŸ¦ Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ HTML
            html_table = """
            <table class='table table-bordered text-center align-middle mb-0'>
                <thead class='table-warning'>
                    <tr><th colspan='{colspan}'>Reason From 3PL Side</th></tr>
                </thead>
                <thead class='table-primary'>
                    <tr>
                        <th>KPI</th>
                        {month_headers}
                        <th>2025</th>
                    </tr>
                </thead>
                <tbody>
                    {table_rows}
                </tbody>
            </table>
            """

            # Ø±Ø¤ÙˆØ³ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            month_headers = "".join([f"<th>{m}</th>" for m in existing_months])

            # Ø§Ù„ØµÙÙˆÙ
            rows_html = ""
            for reason, row in final_df.iterrows():
                rows_html += f"<tr><td>{reason}</td>"
                for m in existing_months:
                    rows_html += f"<td>{int(row[m])}</td>"
                rows_html += f"<td class='fw-bold'>{int(row['Total'])}</td></tr>"

            # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ Ø§Ù„Ù‚Ø§Ù„Ø¨
            html_table = html_table.format(
                colspan=len(existing_months) + 2,
                month_headers=month_headers,
                table_rows=rows_html,
            )

            # ÙˆØ¶Ø¹ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¯Ø§Ø®Ù„ ÙˆØ§Ø¬Ù‡Ø© Ù…Ø±ØªØ¨Ø©
            html_output = f"""
            <div class='container-fluid'>
                <h5 class='text-center text-primary mb-3'>KPI Summary - 3PL Performance</h5>
                <div class='card shadow'>
                    <div class='card-body'>
                        {html_table}
                    </div>
                </div>
            </div>
            """

            return {"detail_html": html_output, "months": existing_months}

        except Exception as e:
            import traceback

            print("âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:", str(e))
            print(traceback.format_exc())
            return {"error": f"âš ï¸ Error while analyzing data: {e}"}

    def filter_rejection_data(self, request, month=None):
        print("ğŸŸ£ [DEBUG] filter_rejection_data CALLED âœ… month:", month)

        excel_path = request.session.get("uploaded_excel_path")

        if not excel_path or not os.path.exists(excel_path):
            return {"error": "âš ï¸ Excel file not found."}

        try:
            df = pd.read_excel(excel_path, sheet_name="Rejection", engine="openpyxl")
            print("ğŸŸ¢ [DEBUG] Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:", df.columns.tolist())
            print(df.head(3))
        except Exception as e:
            return {"error": f"âš ï¸ Unable to read the 'Rejection' sheet: {e}"}

        df.columns = df.columns.str.strip().str.title()
        required = ["Month", "Total Number Of Orders", "Booking Orders"]
        if not all(col in df.columns for col in required):
            return {
                "error": "âš ï¸ Required columns (Month, Total Number Of Orders, Booking Orders) are missing."
            }

        if month:
            df = df[df["Month"].astype(str).str.contains(month, case=False, na=False)]

        if df.empty:
            return {"error": "âš ï¸ No data available."}

        # âœ… Ø®Ø¯ÙŠ Ø§Ù„Ù‚ÙŠÙ… Ø²ÙŠ Ù…Ø§ Ù‡ÙŠ Ù…Ù† Ø§Ù„Ø¥ÙƒØ³Ù„ (Ù…Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Booking Orders)
        summary = df[["Month", "Booking Orders"]].copy()

        # ğŸ§  ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ… â€” Ø´ÙŠÙ„ Ø¹Ù„Ø§Ù…Ø© % Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯Ø© ÙˆØ­ÙˆÙ‘Ù„ÙŠÙ‡Ø§ Ù„Ø£Ø±Ù‚Ø§Ù…
        summary["Booking Orders"] = (
            summary["Booking Orders"]
            .astype(str)
            .str.replace("%", "", regex=False)
            .astype(float)
        )

        # ğŸ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø´Ø§Ø±Øª Ù…Ø¨Ø§Ø´Ø±Ø©
        chart_data = [
            {"month": row["Month"], "percentage": row["Booking Orders"]}
            for _, row in summary.iterrows()
        ]

        html = df.to_html(
            index=False,
            classes="table table-bordered table-striped text-center align-middle",
            border=0,
        )

        print("ğŸ“Š DEBUG - chart_data:", chart_data)  # <-- Ø´ÙˆÙÙŠÙ‡Ø§ ÙÙŠ Ø§Ù„ØªÙŠØ±Ù…Ù†Ø§Ù„
        return {"detail_html": html, "chart_data": chart_data}

    def filter_dock_to_stock_roche(self, request, selected_month=None):
        print("ğŸŸ¢ [DEBUG] âœ… Ø¯Ø®Ù„ Ø¹Ù„Ù‰ filter_dock_to_stock_roche()")

        excel_path = request.session.get("uploaded_excel_path")
        if not excel_path or not os.path.exists(excel_path):
            return {"error": "âš ï¸ Excel file not found."}

        try:
            import pandas as pd
            from django.template.loader import render_to_string

            sheet_name = "Dock to stock - Roche"
            df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl")
            df.columns = df.columns.astype(str).str.strip()

            if df.empty:
                return {"error": "âš ï¸ Sheet 'Dock to stock - Roche' is empty."}

            # Ø£ÙˆÙ„ Ø¹Ù…ÙˆØ¯ Ù‡Ùˆ Ø§Ù„Ø´Ù‡Ø±
            month_col = df.columns[0]
            # Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù‡ÙŠ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ (KPIs)
            kpi_cols = df.columns[1:]

            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø­ÙŠØ« ØªÙƒÙˆÙ† Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ ØµÙÙˆÙ ÙˆØ§Ù„Ø´Ù‡ÙˆØ± Ø£Ø¹Ù…Ø¯Ø©
            melted_df = df.melt(id_vars=[month_col], var_name="KPI", value_name="Value")

            # Pivot ÙØ¹Ù„ÙŠ (KPI ÙƒØµÙÙˆÙ ÙˆØ§Ù„Ø´Ù‡ÙˆØ± ÙƒØ£Ø¹Ù…Ø¯Ø©)
            pivot_df = melted_df.pivot_table(
                index="KPI", columns=month_col, values="Value", aggfunc="sum"
            ).reset_index()
            pivot_df = pivot_df.rename_axis(None, axis=1)

            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø­Ø³Ø¨ ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø´Ù‡ÙˆØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø´ÙŠØª Ø§Ù„Ø£ØµÙ„ÙŠ
            month_order = list(df[month_col].unique())
            ordered_cols = ["KPI"] + month_order
            pivot_df = pivot_df.reindex(columns=ordered_cols)

            # âœ… Ø­Ø°Ù Ø£ÙŠ Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù…Ù‡ "Total" (Ø§Ù„Ù„ÙŠ Ø¨ÙŠØªÙˆÙ„Ø¯ Ù…Ù† Ø§Ù„Ø´ÙŠØª Ø£Ùˆ Ù…Ù† Ø§Ù„Ø®Ø·Ø£)
            if "Total" in pivot_df.columns:
                pivot_df = pivot_df.drop(columns=["Total"])

            # âœ… Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ "2025" ÙÙ‚Ø· Ø¨Ø¹Ø¯ Ø§Ù„Ø´Ù‡ÙˆØ±
            pivot_df["2025"] = pivot_df.iloc[:, 1:].sum(axis=1)

            # âœ… Ø¥Ø¶Ø§ÙØ© ØµÙ Total (Ø§Ù„Ù„ÙŠ Ø¨ÙŠÙƒÙˆÙ† ØªØ­Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„)
            total_row = {"KPI": "Total"}
            for col in pivot_df.columns[1:]:  # ØªØ¬Ø§Ù‡Ù„ Ø¹Ù…ÙˆØ¯ KPI
                total_row[col] = pivot_df[col].sum()
            pivot_df = pd.concat(
                [pivot_df, pd.DataFrame([total_row])], ignore_index=True
            )

            print("âœ… [DEBUG] Ø¬Ø¯ÙˆÙ„ KPI Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„:")
            print(pivot_df.to_string(index=False))

            # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¹Ø±Ø¶
            columns = list(pivot_df.columns)
            table_data = pivot_df.fillna("").to_dict(orient="records")

            tab = {
                "name": "Dock to Stock - Roche",
                "columns": columns,
                "data": table_data,
            }

            month_norm = self.apply_month_filter_to_tab(tab, selected_month)

            html = render_to_string(
                "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
                {
                    "tab": tab,
                    "table_title": "Dock to Stock - Roche (KPI Summary)",
                    "selected_month": month_norm,
                },
            )

            return {
                "detail_html": html,
                "chart_title": "Dock to Stock - Roche",
            }

        except Exception as e:
            print(f"âŒ [ERROR] {e}")
            return {"error": f"âš ï¸ Error while reading data: {e}"}

    def filter_dock_to_stock_3pl(
        self, request, selected_month=None, selected_months=None
    ):
        try:
            print("ğŸŸ¢ [DEBUG] âœ… Ø¯Ø®Ù„ Ø¹Ù„Ù‰ filter_dock_to_stock_3pl()")
            file_path = self.get_uploaded_file_path(request)
            print(f"ğŸ“ [DEBUG] Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {file_path}")

            if not file_path or not os.path.exists(file_path):
                return {"error": "âš ï¸ File not found."}

            # ğŸ§© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø´ÙŠØª
            df = pd.read_excel(file_path, sheet_name="Dock to stock", engine="openpyxl")
            print(f"ğŸ“„ [DEBUG] Ø£ÙˆÙ„ 10 ØµÙÙˆÙ Ù…Ù† Ø§Ù„Ø´ÙŠØª Dock to stock:\n{df.head(10)}")

            # âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            if "Delv #" not in df.columns or "Month" not in df.columns:
                return {
                    "error": "âš ï¸ Columns 'Delv #' or 'Month' are missing in the sheet."
                }

            # ğŸ§® Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ù‡Ø± Ù…Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Month
            df["Month"] = pd.to_datetime(df["Month"], errors="coerce").dt.strftime("%b")

            selected_months_norm = []
            if selected_months:
                if isinstance(selected_months, str):
                    selected_months = [selected_months]
                seen = set()
                for m in selected_months:
                    norm = self.normalize_month_label(m)
                    if norm and norm not in seen:
                        seen.add(norm)
                        selected_months_norm.append(norm)

            selected_month_norm = (
                self.normalize_month_label(selected_month)
                if selected_month and not selected_months_norm
                else None
            )
            if selected_months_norm:
                df = df[
                    df["Month"]
                    .str.lower()
                    .isin([m.lower() for m in selected_months_norm])
                ]
                if df.empty:
                    return {
                        "detail_html": "<p class='text-warning text-center'>âš ï¸ No data available for the selected quarter months.</p>",
                        "chart_data": [],
                    }
            elif selected_month_norm:
                df = df[df["Month"].str.lower() == selected_month_norm.lower()]
                if df.empty:
                    return {
                        "detail_html": "<p class='text-warning text-center'>âš ï¸ No data available for this month.</p>",
                        "chart_data": [],
                    }

            # ğŸ§± Ø­Ø°Ù Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù„ÙŠ Ù…Ø§ÙÙŠÙ‡Ø§Ø´ Ø´Ù‡Ø±
            df = df.dropna(subset=["Month"])

            # âœ… Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø© (hit) Ù„ÙƒÙ„ Ø´Ù‡Ø± Ù…Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Delv #
            hits_per_month = (
                df.drop_duplicates(subset=["Delv #"])
                .groupby("Month")["Delv #"]
                .count()
                .reset_index(name="Hits")
            )

            print("ğŸ“Š [DEBUG] Ù†ØªØ§Ø¦Ø¬ Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø© Ù„ÙƒÙ„ Ø´Ù‡Ø±:")
            print(hits_per_month)

            # âœ… Ø­Ø³Ø§Ø¨ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø´Ø­Ù†Ø§Øª (Total) Ù„ÙƒÙ„ Ø´Ù‡Ø± Ù‚Ø¨Ù„ Ø­Ø°Ù Ø§Ù„Ù…ÙƒØ±Ø±
            total_per_month = (
                df.groupby("Month")["Delv #"]
                .count()
                .reset_index(name="Total_Shipments")
            )

            # âœ… Ø¯Ù…Ø¬ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù€ hits Ù…Ø¹ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
            merged = pd.merge(hits_per_month, total_per_month, on="Month", how="left")

            # âœ… Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ§Ø±Ø¬Øª Ù„ÙƒÙ„ Ø´Ù‡Ø±
            merged["Target_%"] = (
                merged["Hits"] / merged["Total_Shipments"] * 100
            ).round(2)

            print("ğŸ“ˆ [DEBUG] Ø¨Ø¹Ø¯ Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ§Ø±Ø¬Øª:")
            print(merged)

            # âœ… ØªØ¬Ù‡ÙŠØ² Ø¬Ø¯ÙˆÙ„ KPI Ø¨ØµÙŠØºØ© Ù†Ù‡Ø§Ø¦ÙŠØ©
            kpi_name = "On Time Receiving"
            df_kpi = pd.DataFrame({"KPI": [kpi_name]})

            for _, row in merged.iterrows():
                month = row["Month"]
                hits = int(row["Hits"])
                df_kpi[month] = hits

            # âœ… Ø¥Ø¶Ø§ÙØ© ØµÙ Ø¬Ø¯ÙŠØ¯ Total
            total_row = {"KPI": "Total"}
            for col in df_kpi.columns[1:]:  # ØªØ¬Ø§Ù‡Ù„ Ø¹Ù…ÙˆØ¯ KPI
                total_row[col] = df_kpi[col].sum()
            df_kpi = pd.concat([df_kpi, pd.DataFrame([total_row])], ignore_index=True)

            # âœ… Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯ "2025" ÙŠÙ…Ø«Ù„ Ù…Ø¬Ù…ÙˆØ¹ ÙƒÙ„ Ø§Ù„Ø´Ù‡ÙˆØ±
            df_kpi["2025"] = df_kpi.iloc[:, 1:].sum(axis=1)

            # âœ… Ø¥Ø¶Ø§ÙØ© ØµÙ Ø¬Ø¯ÙŠØ¯ Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ§Ø±Ø¬Øª
            target_row = {"KPI": "Target (%)"}
            for _, row in merged.iterrows():
                month = row["Month"]
                target_row[month] = row["Target_%"]
            target_row["2025"] = round(merged["Target_%"].mean(), 2)
            df_kpi = pd.concat([df_kpi, pd.DataFrame([target_row])], ignore_index=True)

            print("âœ… [DEBUG] Ø¬Ø¯ÙˆÙ„ KPI Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ø¹Ø¯ Ø§Ù„Ø¥Ø¶Ø§ÙØ§Øª:")
            print(df_kpi.to_string(index=False))

            if selected_months_norm:
                desired_cols = ["KPI"] + [
                    m for m in selected_months_norm if m in df_kpi.columns
                ]
                if "2025" in df_kpi.columns:
                    desired_cols.append("2025")
                df_kpi = df_kpi[[col for col in desired_cols if col in df_kpi.columns]]
            elif selected_month_norm:
                keep_cols = ["KPI", selected_month_norm]
                if "2025" in df_kpi.columns:
                    keep_cols.append("2025")
                df_kpi = df_kpi[[col for col in keep_cols if col in df_kpi.columns]]

            # ğŸ§¾ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¥Ù„Ù‰ HTML
            html_table = df_kpi.to_html(
                classes="table table-bordered text-center table-striped", index=False
            )

            # ğŸ”¹ Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹ Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
            return {
                "detail_html": html_table,
                "chart_data": df_kpi.to_dict(orient="records"),
            }

        except Exception as e:
            print(f"âŒ [EXCEPTION] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ø§Ù„Ø©: {e}")
            return {"error": str(e)}

    def filter_total_lead_time_detail(self, request, selected_month=None):
        excel_path = request.session.get("uploaded_excel_path")
        if not excel_path or not os.path.exists(excel_path):
            return {
                "detail_html": "<p class='text-danger'>âš ï¸ Excel file not found.</p>",
                "count": 0,
            }

        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø´ÙŠØª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
            xls = pd.ExcelFile(excel_path, engine="openpyxl")
            sheet_name = next(
                (
                    s
                    for s in xls.sheet_names
                    if "total lead time preformance" in s.lower()
                ),
                None,
            )
            if not sheet_name:
                return {
                    "detail_html": "<p class='text-danger'>âŒ Tab 'Total lead time preformance' does not exist in the file.</p>",
                    "count": 0,
                }

            df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl")
            df.columns = df.columns.str.strip().str.lower()

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            required_cols = [
                "month",
                "outbound delivery",
                "kpi",
                "reason group",
                "miss reason",
            ]
            if not all(col in df.columns for col in required_cols):
                html = render_to_string(
                    "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
                    {
                        "tabs": [
                            {
                                "name": sheet_name,
                                "columns": df.columns.tolist(),
                                "data": df.head(50).to_dict(orient="records"),
                            }
                        ]
                    },
                )
                return {"detail_html": html, "count": len(df)}

            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ Ø´Ù‡Ø±
            df["month"] = (
                pd.to_datetime(df["month"], errors="coerce")
                .dt.strftime("%b")
                .str.capitalize()
            )

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ù‡ÙˆØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙØ¹Ù„ÙŠÙ‹Ø§
            existing_months = sorted(
                df["month"].dropna().unique().tolist(),
                key=lambda x: pd.to_datetime(x, format="%b").month,
            )
            if not existing_months:
                return {
                    "detail_html": "<p class='text-danger'>âš ï¸ No valid months were found in the file.</p>",
                    "count": 0,
                }

            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
            df["reason group"] = df["reason group"].astype(str).str.strip().str.lower()
            df["kpi"] = df["kpi"].astype(str).str.strip().str.lower()
            df["miss reason"] = (
                df["miss reason"]
                .astype(str)
                .str.strip()
                .str.replace(r"\s+", " ", regex=True)
            )

            # Ø¨ÙŠØ§Ù†Ø§Øª Miss Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù€ 3PL ÙÙ‚Ø·
            df_miss_3pl = df[
                (df["kpi"] == "miss") & (df["reason group"] == "3pl")
            ].copy()
            df_miss_3pl["_reason_key"] = df_miss_3pl["miss reason"].str.lower()

            # Ø¨ÙŠØ§Ù†Ø§Øª Hit (On Time Delivery)
            df_hit = df[df["kpi"] != "miss"].copy()

            # ØªØ¬Ù…ÙŠØ¹ Miss Ø­Ø³Ø¨ Ø§Ù„Ø³Ø¨Ø¨ ÙˆØ§Ù„Ø´Ù‡Ø±
            miss_grouped = df_miss_3pl.groupby(
                ["_reason_key", "month"], as_index=False
            ).agg({"miss reason": "first"})
            miss_grouped["count"] = (
                df_miss_3pl.groupby(["_reason_key", "month"]).size().values
            )

            miss_pivot = miss_grouped.pivot_table(
                index="miss reason", columns="month", values="count", fill_value=0
            )

            # Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø´Ù‡ÙˆØ± Ø§Ù„Ù†Ø§Ù‚ØµØ©
            for m in existing_months:
                if m not in miss_pivot.columns:
                    miss_pivot[m] = 0
            miss_pivot = miss_pivot[existing_months]

            # Ø­Ø³Ø§Ø¨ On Time Delivery
            hit_counts = (
                df_hit.groupby("month").size().reindex(existing_months, fill_value=0)
            )

            # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            final_df = miss_pivot.copy()
            final_df.loc["On Time Delivery"] = hit_counts
            final_df = final_df.fillna(0)

            # ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø§Ù„Ù‚ÙŠÙ… Ù„Ø£Ø¹Ø¯Ø§Ø¯ ØµØ­ÙŠØ­Ø©
            final_df = final_df.astype(int)

            # Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ (2025 Ø¨Ø¯Ù„ TOTAL)
            final_df["2025"] = final_df.sum(axis=1)

            # ØµÙ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            total_row = final_df.sum(numeric_only=True)
            total_row.name = "TOTAL"
            final_df = pd.concat([final_df, pd.DataFrame([total_row])])

            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            final_df.reset_index(inplace=True)
            # final_df.rename(columns={"miss reason": "KPI"}, inplace=True)
            final_df.rename(columns={"index": "KPI"}, inplace=True)

            # âœ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªÙ…Ø¨Ù„Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
            tab_data = {
                "name": "KPI Summary - 3PL Performance",
                "sub_tables": [
                    {
                        "title": "Reason From 3PL Side",
                        "columns": ["KPI"] + existing_months + ["2025"],
                        "data": final_df.to_dict(orient="records"),
                    }
                ],
            }

            month_norm = self.apply_month_filter_to_tab(tab_data, selected_month)
            html = render_to_string(
                "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
                {"tab": tab_data, "selected_month": month_norm},
            )

            return {"detail_html": html, "count": len(df), "tab_data": tab_data}

        except Exception as e:
            import traceback

            print(traceback.format_exc())
            return {
                "detail_html": f"<p class='text-danger'>âš ï¸ Error while reading data: {e}</p>",
                "count": 0,
            }

    def filter_total_lead_time_roche(self, request, selected_month=None):
        """
        ğŸ”¹ Ù‚Ø±Ø§Ø¡Ø© Ø´ÙŠØª "Total lead time preformance -R" Ù…Ù† Ø§Ù„ØªÙ…Ø¨Ù„Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹
        ğŸ”¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„ØªØ£Ø®ÙŠØ± ÙˆØªØ±ØªÙŠØ¨Ù‡Ø§ Ø­Ø³Ø¨ Ø§Ù„Ø´Ù‡ÙˆØ±
        ğŸ”¹ Ø¹Ø±Ø¶Ù‡Ø§ Ø¨ØªØµÙ…ÙŠÙ… Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…ÙˆØ­Ø¯
        """
        print("ğŸŸ¢ [DEBUG] âœ… Ø¯Ø®Ù„ Ø¹Ù„Ù‰ filter_total_lead_time_roche()")

        excel_path = request.session.get("uploaded_excel_path")
        if not excel_path or not os.path.exists(excel_path):
            return {"error": "âš ï¸ Excel file not found."}

        try:
            # ÙØªØ­ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„
            xls = pd.ExcelFile(excel_path, engine="openpyxl")

            # ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø´ÙŠØª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
            sheet_name = next(
                (s for s in xls.sheet_names if "preformance -r" in s.lower()), None
            )
            if not sheet_name:
                return {
                    "error": "âš ï¸ No sheet containing 'Total lead time preformance -R' was found."
                }

            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø´ÙŠØª
            df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl")
            df.columns = df.columns.str.strip()

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            if "Month" not in df.columns:
                return {"error": "âš ï¸ Column named 'Month' was not found in the sheet."}

            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø´Ù‡ÙˆØ± Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø²Ù…Ù†ÙŠ
            month_order = [
                "Jan",
                "Feb",
                "Mar",
                "Apr",
                "May",
                "Jun",
                "Jul",
                "Aug",
                "Sep",
                "Oct",
                "Nov",
                "Dec",
            ]
            df["Month"] = pd.Categorical(
                df["Month"], categories=month_order, ordered=True
            )
            df = df.sort_values("Month")

            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø´ÙƒÙ„ Ø·ÙˆÙŠÙ„ (Melt)
            df_melted = df.melt(id_vars=["Month"], var_name="KPI", value_name="Count")

            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø³Ø¨Ø¨ ÙˆØ§Ù„Ø´Ù‡Ø±
            pivot_df = (
                df_melted.groupby(["KPI", "Month"])["Count"]
                .sum()
                .unstack(fill_value=0)
                .reindex(columns=month_order, fill_value=0)
            )

            # Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ù†ÙˆÙŠ
            pivot_df["2025"] = pivot_df.sum(axis=1)

            # ØµÙ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„ÙŠ
            total_row = pivot_df.sum(numeric_only=True)
            total_row.name = "TOTAL"
            pivot_df = pd.concat([pivot_df, pd.DataFrame([total_row])])

            # âœ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙˆÙ„ Ø¥Ù„Ù‰ KPI
            pivot_df.reset_index(inplace=True)
            pivot_df.rename(columns={"index": "KPI"}, inplace=True)

            # Ø­Ø°Ù Ø§Ù„Ø´Ù‡ÙˆØ± Ø§Ù„ÙØ§Ø±ØºØ© ØªÙ…Ø§Ù…Ù‹Ø§ (Ø¨Ø¯ÙˆÙ† Ø¨ÙŠØ§Ù†Ø§Øª)
            pivot_df = pivot_df.loc[:, (pivot_df != 0).any(axis=0)]

            # âœ… ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù„ØªÙ…Ø¨Ù„Øª Ø§Ù„Ù€ HTML
            tab = {
                "name": "Total Lead Time Performance - Roche Side",
                "columns": list(pivot_df.columns),
                "data": pivot_df.to_dict(orient="records"),
            }

            month_norm = self.apply_month_filter_to_tab(tab, selected_month)
            html = render_to_string(
                "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
                {
                    "tab": tab,
                    "table_title": "Roche Lead Time 2025",
                    "selected_month": month_norm,
                },
            )

            return {
                "detail_html": html,
                "message": "âœ… ØªÙ… Ø¹Ø±Ø¶ Ø¨ÙŠØ§Ù†Ø§Øª Roche Lead Time Ø¨Ù†Ø¬Ø§Ø­.",
            }

        except Exception as e:
            import traceback

            print(traceback.format_exc())
            return {"error": f"âš ï¸ Error while reading Roche Lead Time data: {e}"}

    def filter_outbound(self, request, selected_month=None):
        """
        ğŸ”¹ Ø¹Ø±Ø¶ ØªØ§Ø¨ Outbound Ø¨Ø®Ø·ÙˆØ§Øª Ø£ÙÙ‚ÙŠØ© Ù…Ù† ØªÙ…Ø¨Ù„Øª Ø®Ø§Ø±Ø¬ÙŠ
        """
        try:
            # âœ… Ø§Ù„Ø®Ø·ÙˆØ§Øª Ù…Ø¹ Ø£Ù„ÙˆØ§Ù† ÙˆØ®Ù„ÙÙŠØ§Øª Ù…Ø®ØªÙ„ÙØ©
            raw_steps = [
                {
                    "title": "GI Issue<br>Pick & Pack",
                    "icon": "bi-receipt",
                    "bg": "#9fc0e4",
                    "text_color": "#fff",
                    "border": "4px solid #9fc0e4",
                    "sub_color": "#eee",
                },
                {
                    "title": "Prepare Docs<br>Invoice, PO and Market place",
                    "icon": "bi-box-seam",
                    "bg": "#e8f1fb",
                    "text_color": "#007fa3",
                    "border": "4px solid #9fc0e4",
                    "sub_color": "#000",
                },
                {
                    "title": "Dispatch Time<br>from Docs Ready till left from WH",
                    "icon": "bi-arrow-left-right",
                    "bg": "#9fc0e4",
                    "text_color": "#fff",
                    "border": "4px solid #9fc0e4",
                    "sub_color": "#eee",
                },
                {
                    "title": "Delivery<br>Deliver to Customer",
                    "icon": "bi-file-earmark-text",
                    "bg": "#e8f1fb",
                    "text_color": "#007fa3",
                    "border": "4px solid #9fc0e4",
                    "sub_color": "#000",
                },
            ]

            steps = []
            for step in raw_steps:
                # Ù†Ù‚Ø³Ù… Ø§Ù„Ù†Øµ Ø¹Ù„Ù‰ <br>
                parts = step["title"].split("<br>")
                styled_title = ""
                for i, part in enumerate(parts):
                    # Ù„Ùˆ Ø¯Ø§ Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø£Ø®ÙŠØ± â†’ Ù†Ø³ØªØ®Ø¯Ù… sub_color
                    color = (
                        step["sub_color"] if i == len(parts) - 1 else step["text_color"]
                    )
                    styled_title += f"<span class='step-line d-block' style='color:{color};'>{part.strip()}</span>"

                steps.append(
                    {
                        "title": styled_title,
                        "icon": step["icon"],
                        "bg": step["bg"],
                        "text_color": step["text_color"],
                        "border": step["border"],
                    }
                )

            # âœ… ØªÙ…Ø±ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„ØªÙ…Ø¨Ù„Øª
            html = render_to_string(
                "forms-table/table/bootstrap-table/basic-table/components/workflow.html",
                {
                    "table_title": "Outbound workflow",
                    "table_text": "Process Stages",
                    "table_span": "Way Of Calculation",
                    "table_text_bottom": "The KPI was calculated based full lead time Order creation to deliver the order to the customer Based on SLA for each city",
                    "process_steps_text": "=NETWORKDAYS(Order Date, Delivery Date,7)-1",
                    "steps": steps,
                    "workflow_type": "outbound",
                },
            )

            return {
                "detail_html": html,
                "message": "âœ… Outbound steps displayed successfully.",
            }

        except Exception as e:
            import traceback

            print(traceback.format_exc())
            return {"error": f"âš ï¸ Error while rendering the Outbound tab: {e}"}

    def filter_outbound_shipments(
        self, request, selected_month=None, selected_months=None
    ):
        """
        ğŸ”¹ ÙŠÙ‚Ø±Ø£ Ù…Ù† Ø´ÙŠØª Outbound1: Order Nbr, Customer Name, Create Timestamp, Customer City,
           Order Type, Status, Ship Date.
        ğŸ”¹ ÙŠÙ‚Ø±Ø£ Ù…Ù† Ø´ÙŠØª Outbound2: Packed Timestamp (Ø§Ù„Ø±Ø¨Ø· Ø¹Ù„Ù‰ Order Nbr).
        ğŸ”¹ Hit/Miss: Ù…Ù† Packed Timestamp Ø¥Ù„Ù‰ Ship Date â€” Ù„Ùˆ â‰¤24 Ø³Ø§Ø¹Ø© = Hit ÙˆØ¥Ù„Ø§ Miss.
        ğŸ”¹ ÙŠØ¹ÙŠØ¯ Ù†ÙØ³ Ù‡ÙŠÙƒÙ„ Inbound (stats, sub_tables, chart_data) Ù„Ø¹Ø±Ø¶Ù‡ Ø¨Ù†ÙØ³ Ø§Ù„ØªÙ…Ø¨Ù„Øª.
        """
        try:
            import os

            excel_path = self.get_uploaded_file_path(request) or self.get_excel_path()
            if not excel_path or not os.path.exists(excel_path):
                return {
                    "detail_html": "<p class='text-danger'>âš ï¸ Excel file not found.</p>",
                    "sub_tables": [],
                    "chart_data": [],
                    "stats": {},
                }

            xls = pd.ExcelFile(excel_path, engine="openpyxl")

            # Ø·Ø¨Ø§Ø¹Ø© Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´ÙŠØªØ§Øª ÙÙŠ Ø§Ù„Ù…Ù„Ù Ø¹Ø´Ø§Ù† Ù†Ø¹Ø±Ù Ù…ÙŠÙ† Ù…ÙˆØ¬ÙˆØ¯
            print("\n[Outbound] Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´ÙŠØªØ§Øª ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„:", xls.sheet_names)

            # Ø¥ÙŠØ¬Ø§Ø¯ Ø´ÙŠØª Outbound1 Ùˆ Outbound2 (Ø£ÙŠ ØªØ³Ù…ÙŠØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ outbound + 1 Ø£Ùˆ 2)
            outbound1_name = None
            outbound2_name = None
            for i, name in enumerate(xls.sheet_names):
                low = name.lower().strip()
                if "outbound" in low and (
                    "1" in low or "one" in low or low == "outbound1"
                ):
                    outbound1_name = name
                if "outbound" in low and (
                    "2" in low or "two" in low or low == "outbound2"
                ):
                    outbound2_name = name
            if not outbound1_name:
                outbound1_name = next(
                    (
                        s
                        for s in xls.sheet_names
                        if "outbound" in s.lower() and "2" not in s.lower()
                    ),
                    None,
                )
            if not outbound2_name:
                outbound2_name = next(
                    (
                        s
                        for s in xls.sheet_names
                        if "outbound" in s.lower() and "1" not in s.lower()
                    ),
                    None,
                )
            # Ù„Ùˆ Ù„Ø³Ù‡ Ù…ÙÙŠØ´ Outbound2: Ù†Ø¬Ø±Ø¨ Ø£ÙŠ Ø´ÙŠØª ÙÙŠÙ‡ Ø¹Ù…ÙˆØ¯ Packed Timestamp (Ø£Ùˆ Packed) + Order Nbr
            if not outbound2_name and outbound1_name:
                for sheet in xls.sheet_names:
                    if sheet == outbound1_name:
                        continue
                    try:
                        probe = pd.read_excel(
                            excel_path, sheet_name=sheet, engine="openpyxl", nrows=2
                        )
                        probe.columns = probe.columns.astype(str).str.strip()
                        has_order = any(
                            "order" in c.lower() and "nbr" in c.lower()
                            for c in probe.columns
                        ) or any("order nbr" in c.lower() for c in probe.columns)
                        has_packed = any("packed" in c.lower() for c in probe.columns)
                        if has_order and has_packed:
                            outbound2_name = sheet
                            print(
                                f"[Outbound] ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø´ÙŠØª '{sheet}' ÙƒÙ€ Outbound2 (ÙÙŠÙ‡ Order Nbr + Packed)"
                            )
                            break
                    except Exception:
                        continue
            if not outbound2_name and outbound1_name:
                print(
                    "[Outbound] âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø´ÙŠØª Outbound2. ØªØ£ÙƒØ¯ÙŠ Ø£Ù† Ø§Ø³Ù… Ø§Ù„Ø´ÙŠØª ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'outbound' Ùˆ '2' Ø£Ùˆ Ø£Ù† ÙÙŠÙ‡ Ø¹Ù…ÙˆØ¯ Packed Timestamp Ùˆ Order Nbr."
                )

            if not outbound1_name:
                return {
                    "detail_html": "<p class='text-warning'>âš ï¸ Sheet 'Outbound1' (or similar) not found.</p>",
                    "sub_tables": [],
                    "chart_data": [],
                    "stats": {},
                }

            df1 = pd.read_excel(
                excel_path, sheet_name=outbound1_name, engine="openpyxl"
            )
            df1.columns = df1.columns.astype(str).str.strip()

            def find_col(df, candidates):
                for c in df.columns:
                    if str(c).strip().lower() in [x.lower() for x in candidates]:
                        return c
                for cand in candidates:
                    for c in df.columns:
                        if cand.lower() in str(c).lower():
                            return c
                return None

            # Outbound1 columns
            order_nbr_col = find_col(
                df1, ["Order Nbr", "Order Nbr.", "Order Number", "Order No", "Order #"]
            )
            customer_col = find_col(df1, ["Customer Name", "Customer"])
            create_ts_col = find_col(
                df1, ["Create Timestamp", "Create Date", "Order Date", "Created"]
            )
            city_col = find_col(df1, ["Customer City", "City"])
            order_type_col = find_col(df1, ["Order Type", "Type"])
            status_col = find_col(df1, ["Status"])
            ship_date_col = find_col(
                df1, ["Ship Date", "Shipment Date", "Shipped Date"]
            )

            required_ob1 = [
                order_nbr_col,
                customer_col,
                create_ts_col,
                status_col,
                ship_date_col,
            ]
            if not all(required_ob1):
                return {
                    "detail_html": "<p class='text-danger'>âš ï¸ Outbound1: missing required columns (Order Nbr, Customer Name, Create Timestamp, Status, Ship Date).</p>",
                    "sub_tables": [],
                    "chart_data": [],
                    "stats": {},
                }

            rename_ob1 = {
                order_nbr_col: "Order Nbr",
                customer_col: "Customer Name",
                create_ts_col: "Create Timestamp",
                status_col: "Status",
                ship_date_col: "Ship Date",
            }
            if city_col and city_col in df1.columns:
                rename_ob1[city_col] = "Customer City"
            if order_type_col and order_type_col in df1.columns:
                rename_ob1[order_type_col] = "Order Type"
            df1 = df1.rename(columns=rename_ob1)
            if "Customer City" not in df1.columns:
                df1["Customer City"] = ""
            if "Order Type" not in df1.columns:
                df1["Order Type"] = ""

            for dt_col in ["Create Timestamp", "Ship Date"]:
                if dt_col in df1.columns:
                    df1[dt_col] = pd.to_datetime(df1[dt_col], errors="coerce")

            df1["Order Nbr"] = df1["Order Nbr"].astype(str).str.strip()
            df1["Status"] = df1["Status"].astype(str).str.strip()

            # Ù…ÙØªØ§Ø­ Ø±Ø¨Ø· Ù…ÙˆØ­Ù‘Ø¯ (ÙŠØ­Ù„ Ø§Ø®ØªÙ„Ø§Ù Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ù…Ø«Ù„ 001 vs 1)
            def _order_key(ser):
                def _norm(v):
                    s = str(v).strip()
                    try:
                        return str(int(float(s)))
                    except (ValueError, TypeError):
                        return s

                return ser.astype(str).str.strip().apply(_norm)

            # Outbound2: Packed Timestamp + key to join (Order Nbr)
            packed_series = None
            if outbound2_name:
                df2 = pd.read_excel(
                    excel_path, sheet_name=outbound2_name, engine="openpyxl"
                )
                df2.columns = df2.columns.astype(str).str.strip()
                order_nbr_col2 = find_col(
                    df2,
                    ["Order Nbr", "Order Nbr.", "Order Number", "Order No", "Order #"],
                )
                packed_col = find_col(
                    df2, ["Packed Timestamp", "Packed Date", "Packed", "Packed Time"]
                )
                if order_nbr_col2 and packed_col:
                    df2 = df2[[order_nbr_col2, packed_col]].copy()
                    df2.columns = ["Order Nbr", "Packed Timestamp"]
                    df2["Order Nbr"] = df2["Order Nbr"].astype(str).str.strip()
                    df2["Packed Timestamp"] = pd.to_datetime(
                        df2["Packed Timestamp"], errors="coerce"
                    )
                    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± ÙÙŠ Order Nbr Ø¹Ø´Ø§Ù† Ø§Ù„Ù€ map ÙŠØ´ØªØºÙ„ (Ù†Ø­ØªÙØ¸ Ø¨Ø£ÙˆÙ„ ØµÙ Ù„ÙƒÙ„ Order Nbr)
                    df2_unique = df2.drop_duplicates(subset=["Order Nbr"], keep="first")
                    packed_series = df2_unique.set_index("Order Nbr")[
                        "Packed Timestamp"
                    ]
                    df1["Packed Timestamp"] = df1["Order Nbr"].map(packed_series)
                    # Ø·Ø¨Ø§Ø¹Ø© Ø¹ÙŠÙ†Ø© Ù…Ù† Outbound2 Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø¯Ø§ØªØ§
                    print("\n[Outbound2] Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø´ÙŠØª â€” Order Nbr Ùˆ Packed Timestamp:")
                    for idx, r in df2.head(8).iterrows():
                        print(
                            f"  Order Nbr: {r['Order Nbr']!r}  |  Packed: {r['Packed Timestamp']}"
                        )
                    print(f"  Ø¹Ø¯Ø¯ ØµÙÙˆÙ Outbound2: {len(df2)}\n")
                    # Ù„Ùˆ Ù…Ø¹Ø¸Ù… Ø§Ù„Ù‚ÙŠÙ… ÙØ§Ø¶ÙŠØ©ØŒ Ù†Ø¬Ø±Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ù…ÙˆØ­Ù‘Ø¯ (Ù…Ø«Ù„Ø§Ù‹ 1 Ùˆ 001 ÙŠØªØ·Ø§Ø¨Ù‚Ø§Ù†)
                    if df1["Packed Timestamp"].notna().sum() < len(df1) // 2:
                        df2["_ok"] = _order_key(df2["Order Nbr"])
                        packed_by_ok = df2.drop_duplicates(
                            subset=["_ok"], keep="first"
                        ).set_index("_ok")["Packed Timestamp"]
                        df1["_ok"] = _order_key(df1["Order Nbr"])
                        df1["Packed Timestamp"] = df1["Packed Timestamp"].fillna(
                            df1["_ok"].map(packed_by_ok)
                        )
                        df1.drop(columns=["_ok"], inplace=True, errors="ignore")
                else:
                    df1["Packed Timestamp"] = pd.NaT
            else:
                df1["Packed Timestamp"] = pd.NaT

            if "Packed Timestamp" not in df1.columns:
                df1["Packed Timestamp"] = pd.NaT

            # Ø·Ø¨Ø§Ø¹Ø© ÙÙŠ Ø§Ù„ØªØ±Ù…ÙŠÙ†Ø§Ù„: Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø±Ø¨Ø· Ù…Ø¹ Outbound2
            packed_filled = df1["Packed Timestamp"].notna().sum()
            print("\n" + "=" * 70)
            print("Outbound â€” Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø±Ø¨Ø· (Packed Timestamp Ù…Ù† Outbound2)")
            print("=" * 70)
            print(f"  Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙÙˆÙ (Outbound1): {len(df1)}")
            print(f"  ØµÙÙˆÙ ÙÙŠÙ‡Ø§ Packed Timestamp ØºÙŠØ± ÙØ§Ø¶ÙŠ: {packed_filled}")
            print(f"  ØµÙÙˆÙ ÙØ§Ø¶ÙŠØ© (Ù…ÙÙŠØ´ Ø±Ø¨Ø·): {len(df1) - packed_filled}")
            if outbound2_name:
                print(f"  Ø´ÙŠØª Outbound2 Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {outbound2_name}")
            else:
                print("  âš ï¸ Ù…ÙÙŠØ´ Ø´ÙŠØª Outbound2 ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡")
            print("  Ø¹ÙŠÙ†Ø© Ù…Ù† df1 (Order Nbr | Packed Timestamp | Ship Date):")
            for i, row in df1.head(10).iterrows():
                pt = row.get("Packed Timestamp")
                pt_str = str(pt)[:19] if pd.notna(pt) and pt is not pd.NaT else "(ÙØ§Ø¶ÙŠ)"
                sd = row.get("Ship Date")
                sd_str = str(sd)[:19] if pd.notna(sd) and sd is not pd.NaT else "(ÙØ§Ø¶ÙŠ)"
                print(
                    f"    Order Nbr: {row.get('Order Nbr')!r}  |  Packed: {pt_str}  |  Ship: {sd_str}"
                )
            print("=" * 70 + "\n")

            # Ù„Ùˆ Ù„Ø³Ù‡ ÙØ§Ø¶ÙŠ: Ù†Ø¬Ø±Ø¨ Ù†Ø£Ø®Ø° Packed Ù…Ù† Outbound1 Ù„Ùˆ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠÙ‡
            if df1["Packed Timestamp"].isna().all():
                packed_in_ob1 = find_col(
                    df1, ["Packed Timestamp", "Packed Date", "Packed", "Packed Time"]
                )
                if packed_in_ob1 and packed_in_ob1 in df1.columns:
                    df1["Packed Timestamp"] = pd.to_datetime(
                        df1[packed_in_ob1], errors="coerce"
                    )

            # ========== Ø¹Ù„Ø§Ù‚Ø© Outbound1 Ùˆ Outbound2 â€” Ø­Ø³Ø§Ø¨ Hit/Miss ==========
            # Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: Ship Date (Ù…Ù† Outbound1) Ù…Ø¹ Packed Timestamp (Ù…Ù† Outbound2).
            # Ø§Ù„ÙØ±Ù‚ = ÙƒÙ… ÙŠÙˆÙ…/Ø³Ø§Ø¹Ø© Ù…Ù† Ø§Ù„ØªØ¹Ø¨Ø¦Ø© (Packed) Ù„Ø­Ø¯ Ø§Ù„Ø´Ø­Ù† (Ship).
            #   â€¢ Ù„Ùˆ Ø§Ù„ÙØ±Ù‚ â‰¤ ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯ (Ø£Ùˆ â‰¤ 24 Ø³Ø§Ø¹Ø©) â†’ Hit
            #   â€¢ Ù„Ùˆ Ø§Ù„ÙØ±Ù‚ > ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯ (Ø£Ùˆ > 24 Ø³Ø§Ø¹Ø©) â†’ Miss
            #   â€¢ Ù„Ùˆ Packed Timestamp Ù†Ø§Ù‚Øµ (Ù…ÙÙŠØ´ Ø±Ø¨Ø·) â†’ Pending
            # ==========
            # Ø§Ù„ÙØ±Ù‚ Ø¨Ø§Ù„Ø³Ø§Ø¹Ø§Øª: Ship Date - Packed Timestamp
            df1["Cycle Hours"] = (
                (df1["Ship Date"] - df1["Packed Timestamp"])
                .dt.total_seconds()
                .div(3600)
            )
            df1["Cycle Hours"] = df1["Cycle Hours"].round(2)
            # Ø§Ù„ÙØ±Ù‚ Ø¨Ø§Ù„Ø£ÙŠØ§Ù… (Ù„Ù„Ø¹Ø±Ø¶ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„)
            df1["Cycle Days"] = (df1["Cycle Hours"] / 24).round(2)
            # Hit = ÙØ±Ù‚ â‰¤ 24 Ø³Ø§Ø¹Ø© (ÙŠØ¹Ù†ÙŠ â‰¤ ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯)ØŒ Miss = Ø£ÙƒØªØ± Ù…Ù† 24 Ø³Ø§Ø¹Ø©
            df1["is_hit"] = df1["Cycle Hours"].le(24) & df1["Cycle Hours"].notna()
            df1["HIT or MISS"] = np.where(df1["is_hit"], "Hit", "Miss")
            df1.loc[df1["Cycle Hours"].isna(), "HIT or MISS"] = "Pending"

            # Ø§Ù„Ø´Ù‡Ø± Ù…Ù† Ship Date Ø£Ùˆ Create Timestamp
            month_source = df1["Ship Date"].copy()
            month_source = month_source.fillna(df1["Create Timestamp"])
            df1["Month"] = month_source.dt.strftime("%b")

            # ÙÙ„ØªØ± Ø§Ù„Ø´Ù‡Ø±
            selected_months_norm = []
            if selected_months:
                if isinstance(selected_months, str):
                    selected_months = [selected_months]
                for m in selected_months:
                    norm = self.normalize_month_label(m)
                    if norm and norm not in selected_months_norm:
                        selected_months_norm.append(norm)
            selected_month_norm = (
                self.normalize_month_label(selected_month)
                if selected_month and not selected_months_norm
                else None
            )
            if selected_months_norm:
                df1 = df1[
                    df1["Month"]
                    .fillna("")
                    .str.lower()
                    .isin([m.lower() for m in selected_months_norm])
                ]
            elif selected_month_norm:
                df1 = df1[
                    df1["Month"].fillna("").str.lower() == selected_month_norm.lower()
                ]

            if df1.empty:
                return {
                    "detail_html": "<p class='text-warning'>âš ï¸ No outbound records for the selected period.</p>",
                    "sub_tables": [],
                    "chart_data": [],
                    "stats": {},
                }

            df_summary = df1.dropna(subset=["Month"]).copy()
            if df_summary.empty:
                return {
                    "detail_html": "<p class='text-warning'>âš ï¸ No valid month values in outbound data.</p>",
                    "sub_tables": [],
                    "chart_data": [],
                    "stats": {},
                }

            def month_order_value(label):
                if not label:
                    return 999
                label = str(label).strip()[:3].title()
                for idx in range(1, 13):
                    if month_abbr[idx] == label:
                        return idx
                return 999

            total_per_month = (
                df_summary.groupby("Month")["Order Nbr"]
                .nunique()
                .reset_index(name="Total_Shipments")
            )
            hits_df = (
                df_summary[df_summary["is_hit"]]
                .groupby("Month")["Order Nbr"]
                .nunique()
                .reset_index(name="Hits")
            )
            summary_df = total_per_month.merge(hits_df, on="Month", how="left")
            summary_df["Hits"] = summary_df["Hits"].fillna(0).astype(int)
            summary_df["Misses"] = summary_df["Total_Shipments"] - summary_df["Hits"]
            summary_df["Hit %"] = (
                summary_df["Hits"]
                / summary_df["Total_Shipments"].replace(0, np.nan)
                * 100
            )
            summary_df["Hit %"] = summary_df["Hit %"].fillna(0).round(2)
            summary_df = summary_df.sort_values(
                by="Month", key=lambda col: col.map(month_order_value)
            )

            months_with_miss = summary_df[summary_df["Misses"] > 0]["Month"].tolist()
            months_with_hit_only_ob = summary_df[summary_df["Misses"] == 0][
                "Month"
            ].tolist()
            ordered_months = months_with_miss + months_with_hit_only_ob

            kpi_rows = []
            for _, row in summary_df.iterrows():
                m = row["Month"]
                kpi_rows.append(
                    {
                        "Month": m,
                        "Total Shipments": int(row["Total_Shipments"]),
                        "Hit (â‰¤24h)": int(row["Hits"]),
                        "Miss (>24h)": int(row["Misses"]),
                        "Hit %": float(row["Hit %"]),
                    }
                )

            pivot_cols = ["KPI"] + ordered_months
            if len(ordered_months) >= 2:
                pivot_cols.append("2025")

            hit_pct_row = {"KPI": "Hit %"}
            total_row = {"KPI": "Total Shipments"}
            hit_row = {"KPI": "Hit (â‰¤24h)"}
            miss_row = {"KPI": "Miss (>24h)"}
            for m in ordered_months:
                r = next((x for x in kpi_rows if x["Month"] == m), None)
                if r:
                    total_val = int(r["Total Shipments"])
                    hit_val = int(r["Hit (â‰¤24h)"])
                    miss_val = int(r["Miss (>24h)"])
                    total_row[m] = total_val
                    hit_row[m] = hit_val
                    miss_row[m] = miss_val
                    hit_pct_row[m] = (
                        int(round(hit_val / total_val * 100)) if total_val > 0 else 0
                    )
            if "2025" in pivot_cols:
                total_2025 = sum(r["Total Shipments"] for r in kpi_rows)
                hit_2025 = sum(r["Hit (â‰¤24h)"] for r in kpi_rows)
                hit_pct_row["2025"] = (
                    int(round(hit_2025 / total_2025 * 100)) if total_2025 > 0 else 0
                )
                total_row["2025"] = int(sum(r["Total Shipments"] for r in kpi_rows))
                hit_row["2025"] = int(sum(r["Hit (â‰¤24h)"] for r in kpi_rows))
                miss_row["2025"] = int(sum(r["Miss (>24h)"] for r in kpi_rows))

            # Total Shipments Ø¢Ø®Ø± ØµÙ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„
            summary_data_pivot = [hit_pct_row, hit_row, miss_row, total_row]
            summary_columns = pivot_cols
            summary_data = summary_data_pivot

            overall_total = int(df1.shape[0])
            overall_hits = int(df1["is_hit"].sum())
            overall_miss = overall_total - overall_hits
            overall_hit_pct = (
                round((overall_hits / overall_total) * 100, 2) if overall_total else 0
            )

            chart_data = []
            hit_pct_for_chart = next(
                (r for r in summary_data if r.get("KPI") == "Hit %"), None
            )
            if hit_pct_for_chart:
                data_points = [
                    {"label": m, "y": float(hit_pct_for_chart.get(m, 0))}
                    for m in ordered_months
                    if hit_pct_for_chart.get(m) is not None
                ]
                if "2025" in hit_pct_for_chart:
                    data_points.append(
                        {"label": "2025", "y": float(hit_pct_for_chart["2025"])}
                    )
                chart_data.append(
                    {
                        "type": "column",
                        "name": "Outbound Hit %",
                        "color": "#74c0fc",
                        "related_table": "sub-table-outbound-hit-summary",
                        "dataPoints": data_points,
                    }
                )

            months_with_miss_label = (
                " â€” Months with Miss: " + ", ".join(months_with_miss)
                if months_with_miss
                else " â€” All months Hit"
            )
            summary_table = {
                "id": "sub-table-outbound-hit-summary",
                "title": "Outbound KPI â‰¤ 24h" + months_with_miss_label,
                "columns": summary_columns,
                "data": summary_data,
                "chart_data": chart_data,
                "months_with_miss": months_with_miss,
                "months_with_hit_only": months_with_hit_only_ob,
            }

            # Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„: Order Nbr Ø£ÙˆÙ„Ø§Ù‹ Ø«Ù… Customer Name ÙˆØ¨Ø§Ù‚ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            detail_columns = [
                "Order Nbr",
                "Customer Name",
                "Create Timestamp",
                "Customer City",
                "Order Type",
                "Status",
                "Packed Timestamp",
                "Ship Date",
                "Days",
                "Month",
                "HIT or MISS",
            ]

            detail_df = df1.copy()
            detail_df["_sort_ts"] = detail_df["Ship Date"]

            def _fmt_date(x):
                if pd.isna(x) or x is pd.NaT:
                    return ""
                try:
                    return pd.Timestamp(x).strftime("%Y-%m-%d %H:%M")
                except Exception:
                    return ""

            for col in ["Create Timestamp", "Ship Date", "Packed Timestamp"]:
                if col in detail_df.columns:
                    detail_df[col] = detail_df[col].apply(_fmt_date)
                else:
                    detail_df[col] = ""

            detail_df["Days"] = detail_df["Cycle Days"].apply(
                lambda x: "" if pd.isna(x) else str(int(np.ceil(float(x))))
            )

            for col in detail_columns:
                if col not in detail_df.columns:
                    detail_df[col] = ""

            drop_cols = [
                c
                for c in [
                    "_sort_ts",
                    "Cycle Hours",
                    "Cycle Days",
                    "is_hit",
                ]
                if c in detail_df.columns
            ]
            detail_rows_raw = (
                detail_df.sort_values("_sort_ts", ascending=False)
                .drop(columns=drop_cols)
                .head(500)[detail_columns]
                .to_dict(orient="records")
            )

            def _to_blank(val):
                if val is None:
                    return ""
                if isinstance(val, float) and (pd.isna(val) or (val != val)):
                    return ""
                s = str(val).strip()
                if s.lower() in ("nan", "nat", "none", "<nat>"):
                    return ""
                return s

            detail_rows = [
                {k: _to_blank(v) for k, v in row.items()} for row in detail_rows_raw
            ]

            # Ø·Ø¨Ø§Ø¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙˆÙ„ Outbound Shipments Detail ÙÙŠ Ø§Ù„ØªØ±Ù…ÙŠÙ†Ø§Ù„ (Ù…Ø¹ Packed Timestamp)
            print("\n" + "=" * 90)
            print(
                "Outbound Shipments Detail â€” Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø±Ø³Ù„Ø© Ù„Ù„Ù‚Ø§Ù„Ø¨ (Ø£ÙˆÙ„ 15 ØµÙ)"
            )
            print("=" * 90)
            print("  Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:", detail_columns)
            print("-" * 90)
            for i, row in enumerate(detail_rows[:15], 1):
                packed_val = row.get("Packed Timestamp", "")
                ship_val = row.get("Ship Date", "")
                cust = row.get("Customer Name", "")[:25]
                print(
                    f"  {i:2d} | Customer: {cust:25s} | Packed Timestamp: {str(packed_val):20s} | Ship Date: {str(ship_val):20s} | HIT or MISS: {row.get('HIT or MISS', '')}"
                )
            print("-" * 90)
            print(f"  Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙÙˆÙ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„: {len(detail_rows)}")
            print("=" * 90 + "\n")

            detail_df_for_options = detail_df.sort_values(
                "_sort_ts", ascending=False
            ).drop(columns=[c for c in drop_cols if c in detail_df.columns])
            facility_options = sorted(
                detail_df_for_options["Customer Name"]
                .fillna("")
                .astype(str)
                .str.strip()
                .replace("", None)
                .dropna()
                .unique()
                .tolist()
            )
            status_options = sorted(
                detail_df_for_options["Status"]
                .fillna("")
                .astype(str)
                .str.strip()
                .replace("", None)
                .dropna()
                .unique()
                .tolist()
            )
            month_options = sorted(
                detail_df_for_options["Month"]
                .fillna("")
                .astype(str)
                .str.strip()
                .replace("", None)
                .dropna()
                .unique()
                .tolist()
            )
            city_options = sorted(
                detail_df_for_options["Customer City"]
                .fillna("")
                .astype(str)
                .str.strip()
                .replace("", None)
                .dropna()
                .unique()
                .tolist()
            )
            hit_miss_options = ["Hit", "Miss", "Pending"]

            detail_table = {
                "id": "sub-table-outbound-detail",
                "title": "Outbound Shipments Detail",
                "columns": detail_columns,
                "data": detail_rows,
                "chart_data": [],
                "full_width": True,
                "filter_options": {
                    "facility_codes": facility_options,
                    "statuses": status_options,
                    "months": month_options,
                    "customer_cities": city_options,
                    "hit_miss": hit_miss_options,
                },
            }

            return {
                "detail_html": "",
                "sub_tables": [summary_table, detail_table],
                "chart_data": chart_data,
                "stats": {
                    "total": overall_total,
                    "hit": overall_hits,
                    "miss": overall_miss,
                    "hit_pct": overall_hit_pct,
                },
            }

        except Exception as e:
            import traceback

            print(traceback.format_exc())
            return {
                "detail_html": f"<p class='text-danger'>âš ï¸ Error processing outbound shipments: {e}</p>",
                "sub_tables": [],
                "chart_data": [],
                "stats": {},
            }

    def filter_inbound(self, request, selected_month=None, selected_months=None):
        """
        ğŸ”¹ ÙŠØ­Ø³Ø¨ KPI Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù€ Inbound (â‰¤24 Ø³Ø§Ø¹Ø© Ø¨ÙŠÙ† Create Timestamp Ùˆ Last LPN Rcv TS).
        ğŸ”¹ ÙŠØ¹ÙŠØ¯ Ø¬Ø¯ÙˆÙ„ Ù…Ù„Ø®Øµ Ø´Ù‡Ø±ÙŠ + Ø¬Ø¯ÙˆÙ„ ØªÙØµÙŠÙ„ÙŠ Ù„Ù„Ø´Ø­Ù†Ø§Øª.
        """
        try:
            import os

            excel_path = self.get_uploaded_file_path(request) or self.get_excel_path()
            if not excel_path or not os.path.exists(excel_path):
                return {
                    "detail_html": "<p class='text-danger'>âš ï¸ Excel file not found.</p>",
                    "sub_tables": [],
                    "chart_data": [],
                }

            xls = pd.ExcelFile(excel_path, engine="openpyxl")
            sheet_name = next(
                (s for s in xls.sheet_names if "inbound" in s.lower()), None
            )
            if not sheet_name:
                return {
                    "detail_html": "<p class='text-warning'>âš ï¸ Sheet containing 'Inbound' was not found.</p>",
                    "sub_tables": [],
                    "chart_data": [],
                }

            df = pd.read_excel(excel_path, sheet_name=sheet_name, engine="openpyxl")
            if df.empty:
                return {
                    "detail_html": "<p class='text-warning'>âš ï¸ Inbound sheet is empty.</p>",
                    "sub_tables": [],
                    "chart_data": [],
                }

            df.columns = df.columns.astype(str).str.strip()

            def normalize_name(val):
                return re.sub(r"[^a-z0-9]", "", str(val).strip().lower())

            def find_column(possible_names):
                normalized_map = {normalize_name(col): col for col in df.columns}
                for name in possible_names:
                    norm = normalize_name(name)
                    if norm in normalized_map:
                        return normalized_map[norm]
                for col in df.columns:
                    col_norm = normalize_name(col)
                    if any(normalize_name(name) in col_norm for name in possible_names):
                        return col
                return None

            column_aliases = {
                "facility": [
                    "facility code",
                    "facility",
                    "facilitycode",
                ],
                "shipment": [
                    "shipment nbr",
                    "shipment number",
                    "shipment no",
                    "shipment#",
                    "shipment id",
                ],
                "status": ["status", "shipment status"],
                "create_ts": ["create timestamp", "created timestamp", "creation time"],
                "arrival": ["arrival date", "arrival timestamp"],
                "offload": ["offloading date", "offload date", "offload timestamp"],
                "last_lpn": [
                    "last lpn rcv ts",
                    "last lpn receive ts",
                    "last lpn rcv timestamp",
                    "last lpn rcv",
                ],
                "reason": [
                    "reason",
                    "miss reason",
                    "delay reason",
                    "remarks",
                    "comments",
                    "cause",
                    "reason code",
                ],
            }

            column_map = {
                key: find_column(names) for key, names in column_aliases.items()
            }

            required_keys = ["shipment", "status", "create_ts", "last_lpn"]
            missing_required = [key for key in required_keys if not column_map.get(key)]
            if missing_required:
                missing_labels = ", ".join(missing_required)
                return {
                    "detail_html": f"<p class='text-danger'>âš ï¸ Missing required columns for inbound analysis: {missing_labels}</p>",
                    "sub_tables": [],
                    "chart_data": [],
                }

            rename_map = {}
            if column_map.get("facility"):
                rename_map[column_map["facility"]] = "Facility Code"
            if column_map["shipment"]:
                rename_map[column_map["shipment"]] = "Shipment Nbr"
            if column_map["status"]:
                rename_map[column_map["status"]] = "Status"
            if column_map["create_ts"]:
                rename_map[column_map["create_ts"]] = "Create Timestamp"
            if column_map["arrival"]:
                rename_map[column_map["arrival"]] = "Arrival Date"
            if column_map["offload"]:
                rename_map[column_map["offload"]] = "Offloading Date"
            if column_map["last_lpn"]:
                rename_map[column_map["last_lpn"]] = "Last LPN Rcv TS"
            if column_map.get("reason"):
                rename_map[column_map["reason"]] = "Reason"

            df = df.rename(columns=rename_map)
            if "Reason" not in df.columns:
                df["Reason"] = ""
            if "Facility Code" not in df.columns:
                df["Facility Code"] = ""

            for col in [
                "Create Timestamp",
                "Arrival Date",
                "Offloading Date",
                "Last LPN Rcv TS",
            ]:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col], errors="coerce")
                else:
                    df[col] = pd.NaT

            df["Shipment Nbr"] = df["Shipment Nbr"].astype(str).str.strip()
            df["Status"] = df["Status"].astype(str).str.strip()
            if "Facility Code" in df.columns:
                df["Facility Code"] = df["Facility Code"].astype(str).str.strip()

            df["Cycle Hours"] = (
                (df["Last LPN Rcv TS"] - df["Create Timestamp"])
                .dt.total_seconds()
                .div(3600)
            )
            df["Cycle Hours"] = df["Cycle Hours"].round(2)
            df["Cycle Days"] = (df["Cycle Hours"] / 24).round(2)

            df["is_hit"] = df["Cycle Hours"].le(24)
            df["is_hit"] = df["is_hit"] & df["Cycle Hours"].notna()

            df["HIT or MISS"] = np.where(df["is_hit"], "Hit", "Miss")
            df.loc[df["Cycle Hours"].isna(), "HIT or MISS"] = "Pending"

            month_source = df["Create Timestamp"].copy()
            month_source = month_source.fillna(df["Arrival Date"])
            month_source = month_source.fillna(df["Offloading Date"])
            df["Month"] = month_source.dt.strftime("%b")

            selected_months_norm = []
            if selected_months:
                if isinstance(selected_months, str):
                    selected_months = [selected_months]
                seen = set()
                for m in selected_months:
                    norm = self.normalize_month_label(m)
                    if norm and norm not in seen:
                        seen.add(norm)
                        selected_months_norm.append(norm)

            selected_month_norm = (
                self.normalize_month_label(selected_month)
                if selected_month and not selected_months_norm
                else None
            )

            if selected_months_norm:
                df = df[
                    df["Month"]
                    .fillna("")
                    .str.lower()
                    .isin([m.lower() for m in selected_months_norm])
                ]
            elif selected_month_norm:
                df = df[
                    df["Month"].fillna("").str.lower() == selected_month_norm.lower()
                ]

            if df.empty:
                return {
                    "detail_html": "<p class='text-warning'>âš ï¸ No inbound records for the selected period.</p>",
                    "sub_tables": [],
                    "chart_data": [],
                }

            df_summary = df.dropna(subset=["Month"]).copy()
            if df_summary.empty:
                return {
                    "detail_html": "<p class='text-warning'>âš ï¸ Inbound data has no valid month values.</p>",
                    "sub_tables": [],
                    "chart_data": [],
                }

            def month_order_value(label):
                if not label:
                    return 999
                label = label.strip()[:3].title()
                for idx in range(1, 13):
                    if month_abbr[idx] == label:
                        return idx
                return 999

            total_per_month = (
                df_summary.groupby("Month")["Shipment Nbr"]
                .nunique()
                .reset_index(name="Total_Shipments")
            )
            hits_df = (
                df_summary[df_summary["is_hit"]]
                .groupby("Month")["Shipment Nbr"]
                .nunique()
                .reset_index(name="Hits")
            )
            summary_df = total_per_month.merge(hits_df, on="Month", how="left")
            summary_df["Hits"] = summary_df["Hits"].fillna(0).astype(int)
            summary_df["Misses"] = summary_df["Total_Shipments"] - summary_df["Hits"]
            summary_df["Hit %"] = (
                summary_df["Hits"]
                / summary_df["Total_Shipments"].replace(0, np.nan)
                * 100
            )
            summary_df["Hit %"] = summary_df["Hit %"].fillna(0).round(2)
            summary_df = summary_df.sort_values(
                by="Month", key=lambda col: col.map(month_order_value)
            )

            months_with_miss = summary_df[summary_df["Misses"] > 0]["Month"].tolist()
            months_with_hit_only = summary_df[summary_df["Misses"] == 0][
                "Month"
            ].tolist()
            ordered_months = months_with_miss + months_with_hit_only

            df_miss = df_summary[~df_summary["is_hit"]].copy()
            df_miss["Reason"] = (
                df_miss.get("Reason", pd.Series([""] * len(df_miss)))
                .astype(str)
                .str.strip()
            )
            # Ù„Ø§ Ù†Ø¹ÙŠÙ‘Ù† "(No reason)" â€” Ø³Ù†Ø³ØªØ¨Ø¹Ø¯ ØµÙÙˆÙ Ø§Ù„Ù€ Reason Ø§Ù„ÙØ§Ø±ØºØ© Ù…Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù„Ø§Ø­Ù‚Ø§Ù‹

            reason_pivot = None
            if not df_miss.empty and "Reason" in df_miss.columns:
                reason_counts = (
                    df_miss.groupby(["Reason", "Month"])["Shipment Nbr"]
                    .nunique()
                    .reset_index(name="cnt")
                )
                if not reason_counts.empty:
                    reason_pivot = reason_counts.pivot_table(
                        index="Reason", columns="Month", values="cnt", fill_value=0
                    ).reset_index()
                    # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ "(No reason)" Ø£Ùˆ ØµÙÙˆÙ Reason ÙØ§Ø±ØºØ© Ù…Ù† Ø§Ù„Ø¹Ø±Ø¶
                    reason_pivot = reason_pivot[
                        reason_pivot["Reason"].astype(str).str.strip().isin(["", "nan", "NaN", "(No reason)"]) == False
                    ].copy()
                    for m in ordered_months:
                        if m not in reason_pivot.columns:
                            reason_pivot[m] = 0
                    if not reason_pivot.empty:
                        reason_pivot = reason_pivot.reindex(
                            columns=["Reason"]
                            + [c for c in ordered_months if c in reason_pivot.columns]
                        )
                    else:
                        reason_pivot = None

            kpi_rows = []
            for _, row in summary_df.iterrows():
                m = row["Month"]
                kpi_rows.append(
                    {
                        "Month": m,
                        "Total Shipments": int(row["Total_Shipments"]),
                        "Hit (â‰¤24h)": int(row["Hits"]),
                        "Miss (>24h)": int(row["Misses"]),
                        "Hit %": float(row["Hit %"]),
                        "_has_miss": row["Misses"] > 0,
                    }
                )

            pivot_cols = ["KPI"] + ordered_months
            if len(ordered_months) >= 2:
                pivot_cols.append("2025")

            hit_pct_row = {"KPI": "Hit %"}
            total_row = {"KPI": "Total Shipments"}
            hit_row = {"KPI": "Hit (â‰¤24h)"}
            miss_row = {"KPI": "Miss (>24h)"}
            for m in ordered_months:
                r = next((x for x in kpi_rows if x["Month"] == m), None)
                if r:
                    total_val = int(r["Total Shipments"])
                    hit_val = int(r["Hit (â‰¤24h)"])
                    miss_val = int(r["Miss (>24h)"])
                    total_row[m] = total_val
                    hit_row[m] = hit_val
                    miss_row[m] = miss_val
                    hit_pct_row[m] = (
                        int(round(hit_val / total_val * 100)) if total_val > 0 else 0
                    )
            if "2025" in pivot_cols:
                total_2025 = sum(r["Total Shipments"] for r in kpi_rows)
                hit_2025 = sum(r["Hit (â‰¤24h)"] for r in kpi_rows)
                hit_pct_row["2025"] = (
                    int(round(hit_2025 / total_2025 * 100)) if total_2025 > 0 else 0
                )
                total_row["2025"] = int(sum(r["Total Shipments"] for r in kpi_rows))
                hit_row["2025"] = int(sum(r["Hit (â‰¤24h)"] for r in kpi_rows))
                miss_row["2025"] = int(sum(r["Miss (>24h)"] for r in kpi_rows))

            # ØªØ±ØªÙŠØ¨ Ø§Ù„ØµÙÙˆÙ: Hit % Ø«Ù… Hit (â‰¤24h) Ø«Ù… Miss (>24h) Ø«Ù… Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ù€ Miss Ø«Ù… Total Shipments Ø¢Ø®Ø±Ø§Ù‹
            summary_data_pivot = [hit_pct_row, hit_row, miss_row]

            if reason_pivot is not None and not reason_pivot.empty:
                for _, r in reason_pivot.iterrows():
                    reason_row = {"KPI": str(r["Reason"])}
                    for c in ordered_months:
                        if c in r.index:
                            reason_row[c] = int(r[c]) if pd.notna(r[c]) else 0
                    if "2025" in pivot_cols:
                        reason_row["2025"] = int(
                            sum(
                                int(r[c]) if c in r.index and pd.notna(r[c]) else 0
                                for c in ordered_months
                            )
                        )
                    summary_data_pivot.append(reason_row)
            summary_data_pivot.append(total_row)

            def _to_display_int(val):
                if val is None or (
                    isinstance(val, float) and (np.isnan(val) or np.isinf(val))
                ):
                    return 0
                if isinstance(val, (int, np.integer)):
                    return int(val)
                try:
                    return int(round(float(val)))
                except (ValueError, TypeError):
                    return 0

            for row in summary_data_pivot:
                for k in list(row.keys()):
                    if k != "KPI" and isinstance(
                        row[k], (int, float, np.integer, np.floating)
                    ):
                        row[k] = _to_display_int(row[k])

            summary_columns = pivot_cols
            summary_data = summary_data_pivot

            overall_total = int(df.shape[0])
            overall_hits = int(df["is_hit"].sum())
            overall_miss = overall_total - overall_hits
            overall_hit_pct = (
                round((overall_hits / overall_total) * 100, 2) if overall_total else 0
            )

            chart_data = []
            hit_pct_for_chart = next(
                (r for r in summary_data if r.get("KPI") == "Hit %"), None
            )
            if hit_pct_for_chart:
                data_points = []
                for m in ordered_months:
                    v = hit_pct_for_chart.get(m)
                    if v is not None and isinstance(v, (int, float)):
                        data_points.append({"label": m, "y": float(v)})
                if "2025" in hit_pct_for_chart:
                    data_points.append(
                        {"label": "2025", "y": float(hit_pct_for_chart["2025"])}
                    )
                chart_data.append(
                    {
                        "type": "column",
                        "name": "Inbound Hit %",
                        "color": "#74c0fc",
                        "related_table": "sub-table-inbound-hit-summary",
                        "dataPoints": data_points,
                    }
                )

            detail_columns = [
                "Facility Code",
                "Shipment Nbr",
                "Status",
                "Create Timestamp",
                "Arrival Date",
                "Offloading Date",
                "Last LPN Rcv TS",
                "Days",
                "Month",
                "HIT or MISS",
            ]

            detail_df = df.copy()
            detail_df["_sort_ts"] = detail_df["Create Timestamp"]

            def _fmt_date(x):
                if pd.isna(x) or x is pd.NaT:
                    return ""
                try:
                    return pd.Timestamp(x).strftime("%Y-%m-%d %H:%M")
                except Exception:
                    return ""

            for col in [
                "Create Timestamp",
                "Arrival Date",
                "Offloading Date",
                "Last LPN Rcv TS",
            ]:
                if col in detail_df.columns:
                    detail_df[col] = detail_df[col].apply(_fmt_date)
                else:
                    detail_df[col] = ""

            detail_df["Days"] = detail_df["Cycle Days"].apply(
                lambda x: "" if pd.isna(x) else str(int(np.ceil(float(x))))
            )

            if "Facility Code" not in detail_df.columns:
                detail_df["Facility Code"] = ""
            if "HIT or MISS" not in detail_df.columns:
                detail_df["HIT or MISS"] = ""

            for col in detail_columns:
                if col not in detail_df.columns:
                    detail_df[col] = ""

            drop_cols = [
                c
                for c in ["_sort_ts", "Cycle Hours", "Cycle Days", "is_hit"]
                if c in detail_df.columns
            ]
            detail_rows_raw = (
                detail_df.sort_values("_sort_ts", ascending=False)
                .drop(columns=drop_cols)
                .head(500)[detail_columns]
                .to_dict(orient="records")
            )

            def _to_blank(val):
                if val is None:
                    return ""
                if isinstance(val, float) and (pd.isna(val) or (val != val)):
                    return ""
                s = str(val).strip()
                if s.lower() in ("nan", "nat", "none", "<nat>"):
                    return ""
                return s

            detail_rows = [
                {k: _to_blank(v) for k, v in row.items()} for row in detail_rows_raw
            ]

            # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ÙÙ„Ø§ØªØ± Ù„Ø¬Ø¯ÙˆÙ„ Inbound Shipments Detail (Ù…Ù† ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ head(500))
            detail_df_for_options = detail_df.sort_values(
                "_sort_ts", ascending=False
            ).drop(columns=[c for c in drop_cols if c in detail_df.columns])
            facility_options = sorted(
                detail_df_for_options["Facility Code"]
                .fillna("")
                .astype(str)
                .str.strip()
                .replace("", None)
                .dropna()
                .unique()
                .tolist()
            )
            status_options = sorted(
                detail_df_for_options["Status"]
                .fillna("")
                .astype(str)
                .str.strip()
                .replace("", None)
                .dropna()
                .unique()
                .tolist()
            )
            month_options = sorted(
                detail_df_for_options["Month"]
                .fillna("")
                .astype(str)
                .str.strip()
                .replace("", None)
                .dropna()
                .unique()
                .tolist()
            )
            hit_miss_options = ["Hit", "Miss", "Pending"]

            months_with_miss_label = (
                " â€” Months with Miss: " + ", ".join(months_with_miss)
                if months_with_miss
                else " â€” All months Hit"
            )
            summary_table = {
                "id": "sub-table-inbound-hit-summary",
                "title": "Inbound KPI â‰¤ 24h" + months_with_miss_label,
                "columns": summary_columns,
                "data": summary_data,
                "chart_data": chart_data,
                "months_with_miss": months_with_miss,
                "months_with_hit_only": months_with_hit_only,
            }

            # Ø·Ø¨Ø§Ø¹Ø© Ø¬Ø¯ÙˆÙ„ KPI (Inbound KPI â‰¤ 24h) ÙÙŠ Ø§Ù„ØªØ±Ù…ÙŠÙ†Ø§Ù„
            print("\n" + "=" * 80)
            print("Inbound KPI â‰¤ 24h â€” summary_table data")
            print("=" * 80)
            print("Columns:", summary_columns)
            print("-" * 80)
            for row in summary_data:
                kpi_name = row.get("KPI", "")
                rest = {k: v for k, v in row.items() if k != "KPI"}
                print(f"  KPI: {kpi_name}")
                for col, val in rest.items():
                    print(f"    {col}: {val}")
                print("-" * 80)
            print("=" * 80 + "\n")

            detail_table = {
                "id": "sub-table-inbound-detail",
                "title": "Inbound Shipments Detail",
                "columns": detail_columns,
                "data": detail_rows,
                "chart_data": [],
                "full_width": True,
                "filter_options": {
                    "facility_codes": facility_options,
                    "statuses": status_options,
                    "months": month_options,
                    "hit_miss": hit_miss_options,
                },
            }

            # Ø·Ø¨Ø§Ø¹Ø© Ø¬Ø¯ÙˆÙ„ Inbound Shipments Detail ÙÙŠ Ø§Ù„ØªØ±Ù…ÙŠÙ†Ø§Ù„
            print("\n" + "=" * 100)
            print(
                "Inbound Shipments Detail â€” Create Timestamp | Arrival Date | Offloading Date | Status | HIT or MISS"
            )
            print("=" * 100)
            for i, row in enumerate(detail_rows[:50], 1):  # Ø£ÙˆÙ„ 50 ØµÙ
                create_ts = str(row.get("Create Timestamp", ""))[:16]
                arrival = str(row.get("Arrival Date", ""))[:16]
                offload = str(row.get("Offloading Date", ""))[:16]
                status = str(row.get("Status", ""))[:18]
                hit_miss = str(row.get("HIT or MISS", ""))
                print(
                    f"  {i:3d} | Create: {create_ts:16s} | Arrival: {arrival:16s} | Offload: {offload:16s} | Status: {status:18s} | {hit_miss}"
                )
            if len(detail_rows) > 50:
                print(f"  ... Ùˆ {len(detail_rows) - 50} ØµÙ Ø¥Ø¶Ø§ÙÙŠ")
            print("=" * 100 + "\n")

            return {
                "detail_html": "",
                "sub_tables": [summary_table, detail_table],
                "chart_data": chart_data,
                "stats": {
                    "total": overall_total,
                    "hit": overall_hits,
                    "miss": overall_miss,
                    "hit_pct": overall_hit_pct,
                },
            }

        except Exception as e:
            import traceback

            print(traceback.format_exc())
            return {
                "detail_html": f"<p class='text-danger'>âš ï¸ Error while processing inbound data: {e}</p>",
                "sub_tables": [],
                "chart_data": [],
            }

    # Merge sheets from Excel
    def filter_pods_update(self, request, selected_month=None, selected_months=None):
        """
        ØªØ§Ø¨ PODs: Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† Ø´ÙŠØª PODs.
        - ÙÙ„ØªØ±Ø© Ø¨Ù€ W.HNAMEØŒ Created onØŒ PGI Date.
        - Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ÙŠØ§Ù… Ø¨ÙŠÙ† Created on Ùˆ PGI Date (Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ ÙŠÙˆÙ… Ø§Ù„Ø¬Ù…Ø¹Ø©).
        - Hit = Ø§Ø³ØªÙ„Ø§Ù… Ø®Ù„Ø§Ù„ 7 Ø£ÙŠØ§Ù… Ø£Ùˆ Ø£Ù‚Ù„ØŒ Miss = Ø£ÙƒØ«Ø± Ù…Ù† 7 Ø£ÙŠØ§Ù….
        - Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ù„ÙˆÙŠ: KPI + ØµÙÙˆÙ Ø§Ù„Ù…Ø¯Ù† Ù„ÙƒÙ„ Ø´Ù‡Ø±.
        - Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø³ÙÙ„ÙŠ: Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ù…Ø¹ ÙÙ„ØªØ± W.HNAMEØŒ Ø§Ù„Ø´Ù‡ÙˆØ±ØŒ Hit/MissØ› Ø§Ù„Ø¨Ø§Ø¯Ø¬Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¯Ù† Ùˆ Hit/Miss.
        """
        import pandas as pd
        from django.template.loader import render_to_string
        import os
        from datetime import datetime, timedelta

        try:
            excel_path = self.get_excel_path()
            if not excel_path or not os.path.exists(excel_path):
                return {"error": "âš ï¸ Excel file not found."}

            xls = pd.ExcelFile(excel_path, engine="openpyxl")
            sheet_name = next(
                (
                    s
                    for s in xls.sheet_names
                    if "pod" in s.lower() and "update" not in s.lower()
                ),
                None,
            )
            if not sheet_name:
                return {"error": "âš ï¸ Sheet 'PODs' was not found."}

            df = pd.read_excel(
                excel_path,
                sheet_name=sheet_name,
                engine="openpyxl",
                dtype=str,
                header=0,
            ).fillna("")
            df.columns = df.columns.astype(str).str.strip()

            def _norm(val):
                return re.sub(r"[^a-z0-9]", "", str(val).strip().lower())

            def _find_col(dframe, names):
                nmap = {_norm(c): c for c in dframe.columns}
                for name in names:
                    n = _norm(name)
                    if n in nmap:
                        return nmap[n]
                for col in dframe.columns:
                    if any(_norm(n) in _norm(col) for n in names):
                        return col
                return None

            col_created = _find_col(df, ["created on", "createdon", "created"])
            col_pgi = _find_col(df, ["pgi date", "pgidate", "pgi"])
            col_whname = _find_col(
                df, ["w.hname", "whname", "warehouse name", "warehouse"]
            )
            col_shpng = _find_col(df, ["shpng pnt", "shpngpnt", "shipping point"])
            col_plant = _find_col(df, ["plant"])
            col_whno = _find_col(df, ["wh no", "whno", "warehouse no"])
            col_delivery = _find_col(df, ["delivery"])
            col_inv = _find_col(df, ["inv", "invoice"])
            col_shipto = _find_col(df, ["ship-to party", "shiptoparty", "ship to"])
            col_shipto_name = _find_col(
                df, ["name of the ship-to party", "ship-to party name"]
            )
            col_qty = _find_col(df, ["qty", "quantity"])
            col_unit = _find_col(df, ["unit"])
            col_city = _find_col(df, ["city"])

            if not col_created or not col_pgi or not col_whname:
                return {
                    "error": "âš ï¸ Required columns (Created on, PGI Date, W.HNAME) not found."
                }

            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
            df["_created_dt"] = pd.to_datetime(df[col_created], errors="coerce")
            df["_pgi_dt"] = pd.to_datetime(df[col_pgi], errors="coerce")

            # Ø­Ø³Ø§Ø¨ Days (Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ ÙŠÙˆÙ… Ø§Ù„Ø¬Ù…Ø¹Ø©) - Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Created on Ùˆ PGI Date
            def business_days_between(start, end):
                if pd.isna(start) or pd.isna(end):
                    return None
                if start > end:
                    return None
                days = 0
                current = start.date()
                end_date = end.date()
                # Ù†Ø­Ø³Ø¨ Ø§Ù„Ø£ÙŠØ§Ù… Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø¬Ù…Ø¹Ø© (Ù…Ù† Created on Ø¥Ù„Ù‰ PGI Date)
                while current < end_date:  # < ÙˆÙ„ÙŠØ³ <= Ù„Ø£Ù†Ù†Ø§ Ù„Ø§ Ù†Ø­Ø³Ø¨ Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ø£Ø®ÙŠØ±
                    if current.weekday() != 4:  # 4 = Friday
                        days += 1
                    current += timedelta(days=1)
                return days

            df["Days"] = df.apply(
                lambda row: business_days_between(row["_created_dt"], row["_pgi_dt"]),
                axis=1,
            )
            # Hit = Ø§Ø³ØªÙ„Ø§Ù… Ø®Ù„Ø§Ù„ 7 Ø£ÙŠØ§Ù… Ø£Ùˆ Ø£Ù‚Ù„ (Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø¬Ù…Ø¹Ø©)ØŒ Miss = Ø£ÙƒØ«Ø± Ù…Ù† 7 Ø£ÙŠØ§Ù…
            df["Hit or Miss"] = df["Days"].apply(
                lambda d: (
                    "Hit"
                    if d is not None and d <= 7
                    else ("Miss" if d is not None else "Pending")
                )
            )
            df["Days"] = df["Days"].apply(
                lambda d: str(int(d)) if d is not None else ""
            )

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ù‡Ø± Ù…Ù† Created on (Ù†Ø­ØªÙØ¸ Ø¨Ù€ _created_dt Ùˆ _pgi_dt Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„)
            df["Month"] = df["_created_dt"].dt.strftime("%b").fillna("")

            # ÙÙ„ØªØ±Ø© Ø§Ù„Ø´Ù‡Ø±
            selected_months_norm = []
            if selected_months:
                if isinstance(selected_months, str):
                    selected_months = [selected_months]
                seen = set()
                for m in selected_months:
                    norm = self.normalize_month_label(m)
                    if norm and norm.lower() not in seen:
                        seen.add(norm.lower())
                        selected_months_norm.append(norm)

            if selected_months_norm:
                df = df[
                    df["Month"]
                    .str.lower()
                    .isin([m.lower() for m in selected_months_norm])
                ]
            elif selected_month:
                month_norm = self.normalize_month_label(selected_month)
                if month_norm:
                    df = df[df["Month"].str.lower() == month_norm.lower()]

            if df.empty:
                return {
                    "detail_html": "<p class='text-warning text-center p-4'>âš ï¸ No data available for selected period.</p>",
                    "count": 0,
                    "hit_pct": 0,
                }

            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø© (Ù„ÙƒØ±ÙˆØª KPI): Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„ÙƒÙ„ = Hit + Miss ÙÙ‚Ø·
            hit_count = len(df[df["Hit or Miss"] == "Hit"])
            miss_count = len(df[df["Hit or Miss"] == "Miss"])
            total_shipments = hit_count + miss_count
            hit_pct = (
                round((hit_count / total_shipments * 100), 2)
                if total_shipments > 0
                else 0
            )
            miss_pct = (
                round((miss_count / total_shipments * 100), 2)
                if total_shipments > 0
                else 0
            )

            # ØªØ¬Ù…ÙŠØ¹ ÙƒÙ„ Ø§Ù„Ù…Ø¯Ù† Ù…Ø¹ Ø¨Ø¹Ø¶ (Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ø­Ø¯ ÙˆØ´Ø§Ø±Øª ÙˆØ§Ø­Ø¯)
            month_order = [
                "Jan",
                "Feb",
                "Mar",
                "Apr",
                "May",
                "Jun",
                "Jul",
                "Aug",
                "Sep",
                "Oct",
                "Nov",
                "Dec",
            ]
            months_raw = df["Month"].dropna().unique().tolist()
            months = sorted(
                months_raw,
                key=lambda m: month_order.index(m) if m in month_order else 999,
            )

            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø¯Ù†
            cities = sorted(
                df[col_whname]
                .astype(str)
                .str.strip()
                .replace("", pd.NA)
                .dropna()
                .unique()
                .tolist()
            )

            if not months:
                return {
                    "detail_html": "<p class='text-warning text-center p-4'>âš ï¸ No months found in data.</p>",
                    "count": 0,
                    "hit_pct": 0,
                }

            # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© ÙˆØ§Ù„Ø´Ù‡Ø±: Hit (Closed), Miss (Pending), Total
            # Ù„ÙƒÙ„ Ù…Ø¯ÙŠÙ†Ø©: Closed, Pending, Total
            city_data = {}
            for city in cities:
                df_city = df[df[col_whname].astype(str).str.strip() == city].copy()
                if df_city.empty:
                    continue

                closed_by_month_city = []
                pending_by_month_city = []
                total_by_month_city = []

                for month in months:
                    df_month_city = df_city[df_city["Month"] == month]
                    hit_month = len(
                        df_month_city[df_month_city["Hit or Miss"] == "Hit"]
                    )
                    miss_month = len(
                        df_month_city[df_month_city["Hit or Miss"] == "Miss"]
                    )
                    closed_by_month_city.append(hit_month)
                    pending_by_month_city.append(miss_month)
                    total_by_month_city.append(hit_month + miss_month)

                # YTD Ù„ÙƒÙ„ Ù…Ø¯ÙŠÙ†Ø©
                closed_ytd_city = sum(closed_by_month_city)
                pending_ytd_city = sum(pending_by_month_city)
                total_ytd_city = sum(total_by_month_city)

                city_data[city] = {
                    "closed": closed_by_month_city + [closed_ytd_city],
                    "pending": pending_by_month_city + [pending_ytd_city],
                    "total": total_by_month_city + [total_ytd_city],
                }

            # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø´Ù‡Ø±: Hit (Closed), Miss (Pending), Total (ÙƒÙ„ Ø§Ù„Ù…Ø¯Ù† Ù…Ø¬Ù…Ø¹Ø©)
            closed_by_month = []
            pending_by_month = []
            total_by_month = []

            for month in months:
                df_month = df[df["Month"] == month]
                hit_month = len(df_month[df_month["Hit or Miss"] == "Hit"])
                miss_month = len(df_month[df_month["Hit or Miss"] == "Miss"])
                closed_by_month.append(hit_month)
                pending_by_month.append(miss_month)
                total_by_month.append(hit_month + miss_month)

            # Ø¥Ø¶Ø§ÙØ© YTD
            closed_ytd = sum(closed_by_month)
            pending_ytd = sum(pending_by_month)
            total_ytd = sum(total_by_month)

            months_display = months + ["YTD"]
            closed_by_month.append(closed_ytd)
            pending_by_month.append(pending_ytd)
            total_by_month.append(total_ytd)

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø³Ø¨ Ø§Ù„Ù…Ø¦ÙˆÙŠØ©
            closed_pct = [
                round((c / t * 100), 2) if t > 0 else 0
                for c, t in zip(closed_by_month, total_by_month)
            ]

            # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙˆÙ„: KPIØŒ Ø«Ù… Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¯Ù† Ø¬Ø§Ù†Ø¨ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø´Ù‡ÙˆØ±ØŒ Ø«Ù… Ø§Ù„Ø´Ù‡ÙˆØ± + YTD
            # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: KPI, City1, City2, ..., Jan, Feb, ..., YTD
            columns = ["KPI"] + cities + months_display
            table_rows = []

            # ØµÙ Closed (Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ): Ù„ÙƒÙ„ Ù…Ø¯ÙŠÙ†Ø© Ù†Ø¹Ø±Ø¶ YTDØŒ Ø«Ù… Ù„ÙƒÙ„ Ø´Ù‡Ø± Ù†Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
            closed_row = {"KPI": "Closed"}
            for city in cities:
                closed_row[city] = int(city_data.get(city, {}).get("closed", [0])[-1])
            for i, month in enumerate(months_display):
                closed_row[month] = int(closed_by_month[i])
            table_rows.append(closed_row)

            # ØµÙ Pending (Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ)
            pending_row = {"KPI": "Pending"}
            for city in cities:
                pending_row[city] = int(city_data.get(city, {}).get("pending", [0])[-1])
            for i, month in enumerate(months_display):
                pending_row[month] = int(pending_by_month[i])
            table_rows.append(pending_row)

            # ØµÙ Total (Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ)
            total_row = {"KPI": "Total"}
            for city in cities:
                total_row[city] = int(city_data.get(city, {}).get("total", [0])[-1])
            for i, month in enumerate(months_display):
                total_row[month] = int(total_by_month[i])
            table_rows.append(total_row)

            # Ø´Ø§Ø±Øª ÙˆØ§Ø­Ø¯ (ÙƒÙ„ Ø§Ù„Ù…Ø¯Ù† Ù…Ø¬Ù…Ø¹Ø©)
            chart_data = [
                {
                    "type": "column",
                    "name": "Closed %",
                    "color": "#9fc0e4",
                    "showInLegend": True,
                    "indexLabel": "{y}%",
                    "related_table": "PODs YTD",
                    "dataPoints": [
                        {"label": m, "y": closed_pct[i]}
                        for i, m in enumerate(months_display)
                    ],
                },
                {
                    "type": "line",
                    "name": "Target 100%",
                    "color": "red",
                    "showInLegend": True,
                    "related_table": "PODs YTD",
                    "dataPoints": [{"label": m, "y": 100} for m in months_display],
                },
            ]

            sub_tables = [
                {
                    "id": "sub-table-pods-ytd",
                    "title": "PODs YTD",
                    "columns": columns,
                    "data": table_rows,
                    "chart_data": chart_data,
                }
            ]

            # âœ… Ø¨Ù†Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ (Ù…Ø«Ù„ Outbound Ùˆ Inbound)
            detail_columns = [
                col_shpng if col_shpng else "Shpng Pnt",
                col_whname if col_whname else "W.HNAME",
                col_plant if col_plant else "PLANT",
                col_whno if col_whno else "WH No",
                col_created if col_created else "Created on",
                col_pgi if col_pgi else "PGI Date",
                col_delivery if col_delivery else "Delivery",
                col_inv if col_inv else "INV",
                col_shipto if col_shipto else "Ship-to party",
                col_shipto_name if col_shipto_name else "Name of the ship-to party",
                col_qty if col_qty else "QTY",
                col_unit if col_unit else "Unit",
                col_city if col_city else "City",
                "Days",
                "Hit or Miss",
                "Month",
            ]

            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø¥Ø²Ø§Ù„Ø© None)
            detail_columns = [c for c in detail_columns if c]

            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ
            detail_df = df.copy()

            # Ø­ÙØ¸ Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ±ØªÙŠØ¨ Ù‚Ø¨Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„
            if "_created_dt" in detail_df.columns:
                detail_df["_sort_ts"] = detail_df["_created_dt"]

            def _fmt_date(x):
                if pd.isna(x) or x is pd.NaT:
                    return ""
                try:
                    return pd.Timestamp(x).strftime("%Y-%m-%d %H:%M")
                except Exception:
                    return ""

            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ Ù†Øµ
            if col_created in detail_df.columns and "_created_dt" in detail_df.columns:
                detail_df[col_created] = detail_df["_created_dt"].apply(_fmt_date)
            if col_pgi in detail_df.columns and "_pgi_dt" in detail_df.columns:
                detail_df[col_pgi] = detail_df["_pgi_dt"].apply(_fmt_date)

            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            if "_sort_ts" in detail_df.columns:
                detail_df = detail_df.sort_values("_sort_ts", ascending=False)

            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            drop_cols = ["_created_dt", "_pgi_dt", "_sort_ts"]
            detail_df = detail_df.drop(
                columns=[c for c in drop_cols if c in detail_df.columns],
                errors="ignore",
            )

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            detail_rows_raw = detail_df.head(500)[detail_columns].to_dict(
                orient="records"
            )

            def _to_blank(val):
                if val is None:
                    return ""
                if isinstance(val, float) and (pd.isna(val) or (val != val)):
                    return ""
                s = str(val).strip()
                if s.lower() in ("nan", "nat", "none", "<nat>"):
                    return ""
                return s

            detail_rows = [
                {k: _to_blank(v) for k, v in row.items()} for row in detail_rows_raw
            ]

            # Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙÙ„Ø§ØªØ±
            detail_df_for_options = detail_df.copy()
            whname_options = (
                sorted(
                    detail_df_for_options[col_whname]
                    .fillna("")
                    .astype(str)
                    .str.strip()
                    .replace("", None)
                    .dropna()
                    .unique()
                    .tolist()
                )
                if col_whname in detail_df_for_options.columns
                else []
            )

            city_options = (
                sorted(
                    detail_df_for_options[col_city]
                    .fillna("")
                    .astype(str)
                    .str.strip()
                    .replace("", None)
                    .dropna()
                    .unique()
                    .tolist()
                )
                if col_city in detail_df_for_options.columns
                else []
            )

            status_options = (
                sorted(
                    detail_df_for_options["Hit or Miss"]
                    .fillna("")
                    .astype(str)
                    .str.strip()
                    .replace("", None)
                    .dropna()
                    .unique()
                    .tolist()
                )
                if "Hit or Miss" in detail_df_for_options.columns
                else []
            )

            month_options = (
                sorted(
                    detail_df_for_options["Month"]
                    .fillna("")
                    .astype(str)
                    .str.strip()
                    .replace("", None)
                    .dropna()
                    .unique()
                    .tolist()
                )
                if "Month" in detail_df_for_options.columns
                else []
            )

            # Ø¥Ø¶Ø§ÙØ© Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„
            detail_table = {
                "id": "sub-table-pods-detail",
                "title": "PODs Shipments Detail",
                "columns": detail_columns,
                "data": detail_rows,
                "chart_data": [],
                "full_width": True,
                "filter_options": {
                    "whnames": whname_options,
                    "statuses": status_options,
                    "months": month_options,
                },
            }

            sub_tables.append(detail_table)

            # ÙƒØ±ÙˆØª KPI
            stats = {
                "total_shipments": total_shipments,
                "hit_pct": hit_pct,
                "miss_pct": miss_pct,
                "target": 100,
            }

            tab_data = {
                "name": "PODs Update",
                "sub_tables": sub_tables,
                "chart_data": chart_data,
                "chart_title": "PODs Closed % Performance",
                "hit_pct": hit_pct,
                "target_pct": 100,
                "stats": stats,
            }

            month_norm_tab = self.apply_month_filter_to_tab(
                tab_data, selected_month, selected_months_norm or None
            )
            html = render_to_string(
                "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
                {"tab": tab_data, "selected_month": month_norm_tab},
            )

            return {
                "detail_html": html,
                "chart_data": chart_data,
                "chart_title": "PODs Closed % Performance",
                "hit_pct": hit_pct,
                "target_pct": 100,
                "count": total_shipments,
                "tab_data": tab_data,
            }

        except Exception as e:
            import traceback

            print(traceback.format_exc())
            return {"error": f"âš ï¸ Error processing PODs: {e}"}

    def filter_rejections_combined(
        self, request, selected_month=None, selected_months=None
    ):
        """
        ØªØ§Ø¨ Return & Refusal: Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Return ÙÙ‚Ø· Ù…Ù† Ø´ÙŠØª Inbound (Shipment Type = RMA).
        Ø¨Ø¯ÙˆÙ† Rejection / Rejection breakdown / Ø´Ø§Ø±Øª â€” Ø¬Ø¯ÙˆÙ„ ÙÙ‚Ø· Ø¨Ø¹Ø±Ø¶ Ø§Ù„ØµÙØ­Ø©.
        """
        import pandas as pd
        import os
        from django.template.loader import render_to_string

        try:
            excel_path = self.get_excel_path()
            if not excel_path or not os.path.exists(excel_path):
                return {
                    "detail_html": "<p class='text-danger'>âš ï¸ Excel file not found.</p>",
                    "chart_data": [],
                    "count": 0,
                }

            xls = pd.ExcelFile(excel_path, engine="openpyxl")
            sheet_names = [s.strip() for s in xls.sheet_names]
            sub_tables = []
            chart_data = []

            selected_months_norm = []
            if selected_months:
                if isinstance(selected_months, str):
                    selected_months = [selected_months]
                seen = set()
                for m in selected_months:
                    norm = self.normalize_month_label(m)
                    if norm and norm not in seen:
                        seen.add(norm)
                        selected_months_norm.append(norm)

            # âœ… Ø¬Ø¯ÙˆÙ„ Return ÙÙ‚Ø· Ù…Ù† Ø´ÙŠØª Inbound: ÙÙ„ØªØ± Shipment Type = RMA
            return_columns_display = [
                "Shipment Nbr",
                "Shipment Type",
                "Status",
                "Create Timestamp",
                "Arrival Date",
                "Offloading Date",
                "Last LPN Rcv TS",
            ]

            def _normalize_col(val):
                return re.sub(r"[^a-z0-9]", "", str(val).strip().lower())

            def _find_col(df, possible_names):
                norm_map = {_normalize_col(c): c for c in df.columns}
                for name in possible_names:
                    n = _normalize_col(name)
                    if n in norm_map:
                        return norm_map[n]
                for col in df.columns:
                    if any(
                        _normalize_col(name) in _normalize_col(col)
                        for name in possible_names
                    ):
                        return col
                return None

            inbound_sheet = next(
                (s for s in sheet_names if "inbound" in s.lower()), None
            )
            if inbound_sheet:
                try:
                    df_in = pd.read_excel(
                        excel_path,
                        sheet_name=inbound_sheet,
                        engine="openpyxl",
                        dtype=str,
                        header=0,
                    ).fillna("")
                    df_in.columns = df_in.columns.astype(str).str.strip()

                    col_ship_nbr = _find_col(
                        df_in, ["shipment nbr", "shipment number", "shipment no"]
                    )
                    col_ship_type = _find_col(
                        df_in, ["shipment type", "shipmenttype", "type"]
                    )
                    col_status = _find_col(df_in, ["status", "shipment status"])
                    col_create = _find_col(
                        df_in, ["create timestamp", "created timestamp"]
                    )
                    col_arrival = _find_col(
                        df_in, ["arrival date", "arrival timestamp"]
                    )
                    col_offload = _find_col(df_in, ["offloading date", "offload date"])
                    col_last_lpn = _find_col(
                        df_in, ["last lpn rcv ts", "last lpn receive ts"]
                    )

                    if col_ship_type is not None:
                        df_in = df_in[
                            df_in[col_ship_type].astype(str).str.strip().str.upper()
                            == "RMA"
                        ]
                    else:
                        df_in = df_in.iloc[0:0]

                    if not df_in.empty and all(
                        [
                            col_ship_nbr,
                            col_status,
                            col_create,
                            col_arrival,
                            col_offload,
                            col_last_lpn,
                        ]
                    ):
                        rename = {
                            col_ship_nbr: "Shipment Nbr",
                            col_status: "Status",
                            col_create: "Create Timestamp",
                            col_arrival: "Arrival Date",
                            col_offload: "Offloading Date",
                            col_last_lpn: "Last LPN Rcv TS",
                        }
                        if col_ship_type is not None:
                            rename[col_ship_type] = "Shipment Type"
                        df_in = df_in.rename(columns=rename)

                        for c in return_columns_display:
                            if c not in df_in.columns:
                                df_in[c] = ""

                        df_in = df_in[return_columns_display]
                        if selected_month or selected_months_norm:
                            month_col = _find_col(df_in, ["month", "create timestamp"])
                            if month_col and month_col in df_in.columns:
                                if selected_months_norm:
                                    active = {
                                        self.normalize_month_label(m)
                                        for m in selected_months_norm
                                    }
                                else:
                                    active = {
                                        self.normalize_month_label(selected_month)
                                    }
                                if "Create Timestamp" in df_in.columns:
                                    try:
                                        ts = pd.to_datetime(
                                            df_in["Create Timestamp"],
                                            errors="coerce",
                                        )
                                        df_in["_month"] = ts.dt.strftime("%b")
                                        df_in = df_in[
                                            df_in["_month"]
                                            .fillna("")
                                            .str.lower()
                                            .isin([m.lower() for m in active])
                                        ]
                                        df_in = df_in.drop(
                                            columns=["_month"], errors="ignore"
                                        )
                                    except Exception:
                                        pass

                        # Ø­Ø³Ø§Ø¨ Hit/Miss Ù„Ù„Ù€ Return (â‰¤24h Ø¨ÙŠÙ† Create Timestamp Ùˆ Last LPN Rcv TS)
                        return_kpi = None
                        try:
                            ts_create = pd.to_datetime(
                                df_in["Create Timestamp"], errors="coerce"
                            )
                            ts_last = pd.to_datetime(
                                df_in["Last LPN Rcv TS"], errors="coerce"
                            )
                            hours = (ts_last - ts_create).dt.total_seconds() / 3600.0
                            df_in["_is_hit"] = (hours <= 24) & (hours.notna())
                            total_ret = len(df_in)
                            successful_ret = int(df_in["_is_hit"].sum())
                            failed_ret = total_ret - successful_ret
                            hit_pct_ret = (
                                round(100.0 * successful_ret / total_ret, 2)
                                if total_ret else 0
                            )
                            return_kpi = {
                                "total_shipments": total_ret,
                                "successful": successful_ret,
                                "failed": failed_ret,
                                "target": 99,
                                "hit_pct": hit_pct_ret,
                            }
                            df_in = df_in.drop(columns=["_is_hit"], errors="ignore")
                        except Exception:
                            total_ret = len(df_in)
                            return_kpi = {
                                "total_shipments": total_ret,
                                "successful": total_ret,
                                "failed": 0,
                                "target": 99,
                                "hit_pct": 100.0 if total_ret else 0,
                            }

                        sub_tables.append(
                            {
                                "title": "Return",
                                "columns": return_columns_display,
                                "data": df_in.to_dict(orient="records"),
                                "return_kpi": return_kpi,
                            }
                        )
                    else:
                        sub_tables.append(
                            {
                                "title": "Return",
                                "columns": return_columns_display,
                                "data": [],
                                "error": (
                                    "Inbound sheet missing required columns or no RMA rows."
                                    if col_ship_type is not None
                                    else "Column 'Shipment Type' not found in Inbound."
                                ),
                            }
                        )
                except Exception as e_in:
                    import traceback

                    print(traceback.format_exc())
                    sub_tables.append(
                        {
                            "title": "Return",
                            "columns": return_columns_display,
                            "data": [],
                            "error": str(e_in),
                        }
                    )
            else:
                sub_tables.append(
                    {
                        "title": "Return",
                        "columns": return_columns_display,
                        "data": [],
                        "error": "Sheet containing 'Inbound' was not found.",
                    }
                )

            # âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ„ØªØ±Ø©
            total_count = sum(len(st["data"]) for st in sub_tables)
            if (selected_month or selected_months_norm) and total_count == 0:
                if selected_months_norm:
                    msg = ", ".join(selected_months_norm)
                else:
                    msg = str(selected_month).strip().capitalize()
                return {
                    "detail_html": f"<p class='text-warning text-center p-4'>âš ï¸ No data available for {msg} in Return & Refusal.</p>",
                    "chart_data": [],
                    "count": 0,
                }

            # ğŸ§© Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ HTML â€” Ù†Ù…Ø±Ù‘Ø± return_kpi Ù…Ù† Ø£ÙˆÙ„ sub_table Ù„Ù„ÙƒØ±ÙˆØª ÙÙˆÙ‚ Ø§Ù„Ø¬Ø¯ÙˆÙ„
            return_kpi_for_tab = None
            if sub_tables:
                return_kpi_for_tab = sub_tables[0].get("return_kpi")
            tab_data = {
                "name": "Return & Refusal",
                "sub_tables": sub_tables,
                "chart_data": chart_data,
                "chart_title": "Return & Refusal Overview",
                "return_kpi": return_kpi_for_tab,
            }
            month_norm_tab = self.apply_month_filter_to_tab(
                tab_data,
                selected_month if not selected_months_norm else None,
                selected_months_norm or None,
            )
            html = render_to_string(
                "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
                {"tab": tab_data, "selected_month": month_norm_tab},
            )

            # ğŸ§® Ø­Ø³Ø§Ø¨ hit% Ù…Ù† Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ % of Rejection (Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ©)
            hit_values = []
            for st in sub_tables:
                if "rejection" in st["title"].lower():
                    for row in st["data"]:
                        val = row.get("% of Rejection", "")
                        try:
                            num = to_percentage_number(val)
                            if num is not None:
                                hit_values.append(num)
                        except:
                            pass

            hit_pct = round(sum(hit_values) / len(hit_values), 2) if hit_values else 0

            result = {
                "detail_html": html,
                "chart_data": chart_data,
                "chart_title": "Return & Refusal Overview",
                "count": total_count,
                "hit_pct": hit_pct,
                "tab_data": tab_data,
            }

            return result

        except Exception as e:
            import traceback

            print(traceback.format_exc())
            return {
                "detail_html": f"<p class='text-danger'>âš ï¸ Error while processing Return & Refusal data: {e}</p>",
                "chart_data": [],
                "count": 0,
            }

    def filter_expiry(self, request, selected_month=None, selected_months=None):
        """
        ØªØ§Ø¨ Expiry: Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† Ø´ÙŠØª Expiry.
        - ÙÙ„ØªØ± Status: Located, Allocated, Partly Allocated ÙÙ‚Ø·.
        - Ø£Ø¹Ù…Ø¯Ø©: Facility, Company, LPN Nbr, Status, Item Code, Item Description, Current Qty, batch_nbr, Expiry Date.
        - ØªØ­Ø°ÙŠØ±: Ø§Ù„Ù„ÙŠ ÙŠÙ†ØªÙ‡ÙŠ Ø®Ù„Ø§Ù„ 3 Ø´Ù‡ÙˆØ± = Ù‚Ø±ÙŠØ¨ØŒ Ø®Ù„Ø§Ù„ 6 Ø´Ù‡ÙˆØ± = warningØŒ ÙŠØ¹Ø±Ø¶ ØªØ­Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙÙŠ Bootstrap 5 alert.
        """
        import pandas as pd
        import os
        from datetime import datetime, timedelta
        from django.template.loader import render_to_string

        try:
            excel_path = self.get_excel_path()
            if not excel_path or not os.path.exists(excel_path):
                return {
                    "detail_html": "<p class='text-danger'>âš ï¸ Excel file not found.</p>",
                    "chart_data": [],
                    "count": 0,
                }

            xls = pd.ExcelFile(excel_path, engine="openpyxl")
            sheet_names = [s.strip() for s in xls.sheet_names]
            expiry_sheet = next((s for s in sheet_names if "expiry" in s.lower()), None)
            if not expiry_sheet:
                return {
                    "detail_html": "<p class='text-warning'>âš ï¸ Sheet containing 'Expiry' was not found.</p>",
                    "chart_data": [],
                    "count": 0,
                }

            df = pd.read_excel(
                excel_path,
                sheet_name=expiry_sheet,
                engine="openpyxl",
                dtype=str,
                header=0,
            ).fillna("")
            df.columns = df.columns.astype(str).str.strip()

            def _norm(val):
                return re.sub(r"[^a-z0-9]", "", str(val).strip().lower())

            def _find_col(dframe, names):
                nmap = {_norm(c): c for c in dframe.columns}
                for name in names:
                    n = _norm(name)
                    if n in nmap:
                        return nmap[n]
                for col in dframe.columns:
                    if any(_norm(n) in _norm(col) for n in names):
                        return col
                return None

            col_facility = _find_col(df, ["facility", "facility code"])
            col_company = _find_col(df, ["company"])
            col_lpn = _find_col(df, ["lpn nbr", "lpn", "lpn nbr"])
            col_status = _find_col(df, ["status"])
            col_item_code = _find_col(df, ["item code", "itemcode"])
            col_item_desc = _find_col(df, ["item description", "item desc"])
            col_qty = _find_col(df, ["current qty", "currentqty", "qty"])
            col_batch = _find_col(df, ["batch_nbr", "batch nbr", "batch"])
            col_expiry = _find_col(df, ["expiry date", "expirydate", "expiry"])

            if not col_status:
                return {
                    "detail_html": "<p class='text-danger'>âš ï¸ Column 'Status' not found in Expiry sheet.</p>",
                    "chart_data": [],
                    "count": 0,
                }

            # ÙÙ„ØªØ± Status: Located, Allocated, Partly Allocated
            status_vals = {"located", "allocated", "partly allocated"}
            df = df[
                df[col_status].astype(str).str.strip().str.lower().isin(status_vals)
            ]

            display_columns = [
                "Facility",
                "Company",
                "LPN Nbr",
                "Status",
                "Item Code",
                "Item Description",
                "Current Qty",
                "batch_nbr",
                "Expiry Date",
            ]
            rename_map = {}
            if col_facility:
                rename_map[col_facility] = "Facility"
            if col_company:
                rename_map[col_company] = "Company"
            if col_lpn:
                rename_map[col_lpn] = "LPN Nbr"
            if col_status:
                rename_map[col_status] = "Status"
            if col_item_code:
                rename_map[col_item_code] = "Item Code"
            if col_item_desc:
                rename_map[col_item_desc] = "Item Description"
            if col_qty:
                rename_map[col_qty] = "Current Qty"
            if col_batch:
                rename_map[col_batch] = "batch_nbr"
            if col_expiry:
                rename_map[col_expiry] = "Expiry Date"

            df = df.rename(columns=rename_map)
            for c in display_columns:
                if c not in df.columns:
                    df[c] = ""

            df = df[display_columns]

            # ØªØ­ÙˆÙŠÙ„ Expiry Date ÙˆØªØ­Ø¯ÙŠØ¯ Ù†Ø·Ø§Ù‚Ø§Øª: 1â€“3ØŒ 3â€“6ØŒ 6â€“9 Ø´Ù‡ÙˆØ±
            today = pd.Timestamp(datetime.now().date())
            three_months = today + pd.DateOffset(months=3)
            six_months = today + pd.DateOffset(months=6)
            nine_months = today + pd.DateOffset(months=9)

            expiry_ser = pd.to_datetime(df["Expiry Date"], errors="coerce")
            df["_expiry_dt"] = expiry_ser
            df["Expiry Date"] = expiry_ser.dt.strftime("%Y-%m-%d").fillna("")

            within_1_3 = (
                (df["_expiry_dt"].notna())
                & (df["_expiry_dt"] >= today)
                & (df["_expiry_dt"] <= three_months)
            )
            within_3_6 = (
                (df["_expiry_dt"].notna())
                & (df["_expiry_dt"] > three_months)
                & (df["_expiry_dt"] <= six_months)
            )
            within_6_9 = (
                (df["_expiry_dt"].notna())
                & (df["_expiry_dt"] > six_months)
                & (df["_expiry_dt"] <= nine_months)
            )
            df = df.drop(columns=["_expiry_dt"], errors="ignore")

            table_data = df[display_columns].to_dict(orient="records")

            # Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ù„ÙƒÙ„ Ù†Ø·Ø§Ù‚
            expiry_counts = {
                "within_1_3": int(within_1_3.sum()),
                "within_3_6": int(within_3_6.sum()),
                "within_6_9": int(within_6_9.sum()),
            }

            # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ÙÙ„Ø§ØªØ±: Facility, Company, Status, Expiry Date
            facility_codes = (
                sorted(
                    df["Facility"]
                    .astype(str)
                    .str.strip()
                    .replace("", pd.NA)
                    .dropna()
                    .unique()
                    .tolist()
                )
                if "Facility" in df.columns
                else []
            )
            companies = (
                sorted(
                    df["Company"]
                    .astype(str)
                    .str.strip()
                    .replace("", pd.NA)
                    .dropna()
                    .unique()
                    .tolist()
                )
                if "Company" in df.columns
                else []
            )
            statuses = (
                sorted(
                    df["Status"]
                    .astype(str)
                    .str.strip()
                    .replace("", pd.NA)
                    .dropna()
                    .unique()
                    .tolist()
                )
                if "Status" in df.columns
                else []
            )
            expiry_dates = (
                sorted(
                    df["Expiry Date"]
                    .astype(str)
                    .str.strip()
                    .replace("", pd.NA)
                    .dropna()
                    .unique()
                    .tolist()
                )
                if "Expiry Date" in df.columns
                else []
            )

            filter_options = {
                "facility_codes": facility_codes,
                "companies": companies,
                "statuses": statuses,
                "expiry_dates": expiry_dates,
            }

            sub_tables = [
                {
                    "id": "sub-table-expiry-detail",
                    "title": "Expiry",
                    "columns": display_columns,
                    "data": table_data,
                    "filter_options": filter_options,
                }
            ]
            tab_data = {
                "name": "Expiry",
                "sub_tables": sub_tables,
                "chart_data": [],
                "expiry_counts": expiry_counts,
            }
            month_norm = self.apply_month_filter_to_tab(tab_data, selected_month, None)
            html = render_to_string(
                "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
                {"tab": tab_data, "selected_month": month_norm},
            )
            return {
                "detail_html": html,
                "chart_data": [],
                "count": len(table_data),
                "tab_data": tab_data,
            }
        except Exception as e:
            import traceback

            print(traceback.format_exc())
            return {
                "detail_html": f"<p class='text-danger'>âš ï¸ Error processing Expiry: {e}</p>",
                "chart_data": [],
                "count": 0,
            }

    def filter_total_lead_time_performance(
        self, request, selected_month=None, selected_months=None
    ):
        cache.clear()
        """
        ğŸ”¹ Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Miss Breakdown (3PL Ùˆ Roche ÙƒÙ„ ÙˆØ§Ø­Ø¯ Ù…Ù†ÙØµÙ„)
        ğŸ”¹ Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø§Ø±Øª Ø§Ù„Ø®Ø§Øµ Ø¨Ù€ 3PL On-Time Delivery
        ğŸ”¹ Ø¹Ø±Ø¶ Ø®Ø·ÙˆØ§Øª Outbound ÙÙŠ Ø§Ù„Ø£Ø³ÙÙ„
        """
        try:
            excel_path = self.get_uploaded_file_path(request)
            if not excel_path or not os.path.exists(excel_path):
                return {
                    "detail_html": "<p class='text-danger text-center'>âš ï¸ Excel file not found for display.</p>",
                    "chart_data": [],
                    "count": 0,
                }

            xls = pd.ExcelFile(excel_path, engine="openpyxl")
            sub_tables = []
            chart_data = []
            selected_month_norm = None
            selected_months_norm = []
            actual_target = 0  # ÙŠÙØ­Ø¯Ù‘ÙØ« Ù…Ù† Ø§Ù„Ø´ÙŠØª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø¥Ù† ÙˆÙØ¬Ø¯

            if selected_month:
                raw_month = str(selected_month).strip()
                parsed = pd.to_datetime(raw_month, errors="coerce")
                if pd.isna(parsed):
                    selected_month_norm = raw_month[:3].capitalize()
                else:
                    selected_month_norm = parsed.strftime("%b")

            if selected_months:
                if isinstance(selected_months, str):
                    selected_months = [selected_months]
                for m in selected_months:
                    norm = self.normalize_month_label(m)
                    if norm:
                        selected_months_norm.append(norm)
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªØ±ØªÙŠØ¨
                seen = set()
                selected_months_norm = [
                    m for m in selected_months_norm if not (m in seen or seen.add(m))
                ]

            # ----------------------------
            # ğŸŸ¦ Ø¬Ø¯ÙˆÙ„ 3PL SIDE
            # ----------------------------
            sheet_3pl = next(
                (
                    s
                    for s in xls.sheet_names
                    if "total lead time preformance" in s.lower()
                    and "-r" not in s.lower()
                ),
                None,
            )

            final_df_3pl = None

            if sheet_3pl:
                df = pd.read_excel(excel_path, sheet_name=sheet_3pl, engine="openpyxl")
                df.columns = df.columns.str.strip().str.lower()

                required_cols = [
                    "month",
                    "outbound delivery",
                    "kpi",
                    "reason group",
                    "miss reason",
                ]
                if all(col in df.columns for col in required_cols):
                    df["year"] = pd.to_datetime(df["month"], errors="coerce").dt.year
                    df = df[df["year"] == 2025]

                    if "month" in df.columns:
                        # Ù†Ø­Ø§ÙˆÙ„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ Ø¹Ù…ÙˆØ¯ Month Ø¥Ù„Ù‰ ØªØ§Ø±ÙŠØ®ØŒ Ø«Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù…Ø®ØªØµØ±
                        df["month"] = pd.to_datetime(
                            df["month"], errors="coerce"
                        ).dt.strftime("%b")
                    else:
                        # fallback Ù„Ùˆ Ù…ÙÙŠØ´ Ø¹Ù…ÙˆØ¯ Month
                        df["month"] = pd.to_datetime(
                            df["ob distribution date"], errors="coerce"
                        ).dt.strftime("%b")

                    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø´Ù‡ÙˆØ±
                    month_order = [
                        "Jan",
                        "Feb",
                        "Mar",
                        "Apr",
                        "May",
                        "Jun",
                        "Jul",
                        "Aug",
                        "Sep",
                        "Oct",
                        "Nov",
                        "Dec",
                    ]

                    df["month"] = pd.Categorical(
                        df["month"], categories=month_order, ordered=True
                    )
                    missing_months = []
                    if selected_month_norm:
                        df = df[df["month"] == selected_month_norm]
                        if df.empty:
                            return {
                                "detail_html": f"<p class='text-warning text-center p-4'>âš ï¸ No data available for month {selected_month_norm} in Total Lead Time Performance.</p>",
                                "chart_data": [],
                                "count": 0,
                                "hit_pct": 0,
                            }
                        existing_months = [selected_month_norm]
                    elif selected_months_norm:
                        df = df[df["month"].isin(selected_months_norm)]
                        available_months = [
                            m
                            for m in selected_months_norm
                            if m in df["month"].dropna().unique()
                        ]
                        missing_months = [
                            m for m in selected_months_norm if m not in available_months
                        ]
                        if df.empty:
                            return {
                                "detail_html": "<p class='text-warning text-center p-4'>âš ï¸ No data available for the selected quarter months in Total Lead Time Performance.</p>",
                                "chart_data": [],
                                "count": 0,
                                "hit_pct": 0,
                            }
                        existing_months = selected_months_norm
                    else:
                        existing_months = [
                            m for m in month_order if m in df["month"].dropna().unique()
                        ]

                    df["reason group"] = (
                        df["reason group"].astype(str).str.strip().str.lower()
                    )
                    df["kpi"] = df["kpi"].astype(str).str.strip().str.lower()
                    df["miss reason"] = (
                        df["miss reason"].astype(str).str.strip().str.lower()
                    )

                    df_hit = df[df["kpi"].str.lower() == "hit"].copy()
                    hit_counts = (
                        df_hit.groupby("month")["outbound delivery"]
                        .nunique()
                        .reindex(existing_months, fill_value=0)
                    )

                    df_3pl_miss = df[
                        (df["kpi"].str.lower() == "miss")
                        & (df["reason group"] == "3pl")
                    ].copy()

                    miss_grouped = (
                        df_3pl_miss.groupby(["miss reason", "month"])[
                            "outbound delivery"
                        ]
                        .nunique()
                        .reset_index(name="count")
                        .pivot_table(
                            index="miss reason",
                            columns="month",
                            values="count",
                            fill_value=0,
                        )
                    )

                    for m in existing_months:
                        if m not in miss_grouped.columns:
                            miss_grouped[m] = 0
                    miss_grouped = miss_grouped[existing_months]

                    final_df_3pl = miss_grouped.copy()
                    final_df_3pl.loc["on time delivery"] = hit_counts
                    final_df_3pl = final_df_3pl.fillna(0).astype(int)
                    final_df_3pl["2025"] = final_df_3pl.sum(axis=1)

                    total_row = final_df_3pl.sum(numeric_only=True)
                    total_row.name = "total"
                    final_df_3pl = pd.concat([final_df_3pl, pd.DataFrame([total_row])])

                    final_df_3pl.reset_index(inplace=True)
                    final_df_3pl.rename(columns={"index": "KPI"}, inplace=True)
                    final_df_3pl["KPI"] = final_df_3pl["KPI"].str.title()

                    desired_order = [
                        "On Time Delivery",
                        "Late Arrive To The Customer",
                        "Customer Close On Arrive",
                        "Remote Area",
                    ]
                    final_df_3pl["order_key"] = final_df_3pl["KPI"].apply(
                        lambda x: (
                            desired_order.index(x)
                            if x in desired_order
                            else len(desired_order) + 1
                        )
                    )
                    final_df_3pl = final_df_3pl.sort_values(
                        by=["order_key", "KPI"]
                    ).drop(columns=["order_key"])
                    # final_df_3pl.insert(1, "Reason Group", "3PL")
                    #
                    # # âœ… Ø­Ø°Ù Ø¹Ù…ÙˆØ¯ Reason Group Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
                    # if "Reason Group" in final_df_3pl.columns:
                    #     final_df_3pl = final_df_3pl.drop(columns=["Reason Group"])

                    # âœ… Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ§Ø±Ø¬Øª Ø§Ù„ÙØ¹Ù„ÙŠ Ù„ÙƒÙ„ Ø´Ù‡Ø± (On Time Ã· Total Ã— 100)
                    percent_hit = []
                    existing_months = [
                        m
                        for m in final_df_3pl.columns
                        if m not in ["KPI", "Reason Group", "2025", "Total"]
                    ]

                    on_time_row = final_df_3pl.loc[
                        final_df_3pl["KPI"].str.lower() == "on time delivery"
                    ].iloc[0]
                    total_row = final_df_3pl.loc[
                        final_df_3pl["KPI"].str.lower() == "total"
                    ].iloc[0]

                    for m in existing_months:
                        on_time_val = float(on_time_row.get(m, 0))
                        total_val = float(total_row.get(m, 0))

                        # âœ… Ù„Ùˆ Ø§Ù„Ø´Ù‡Ø± ÙÙŠÙ‡ ØµÙØ± ÙØ¹Ù„Ø§Ù‹ØŒ Ø®Ù„ÙŠÙ‡ 0 ÙÙŠ Ø§Ù„Ø´Ø§Ø±Øª ÙƒÙ…Ø§Ù†
                        if total_val == 0 or on_time_val == 0:
                            percent = 0
                        else:
                            percent = int(round((on_time_val / total_val) * 100))

                        percent_hit.append(percent)

                    try:
                        total_year_val = total_row["2025"]
                        on_time_year_val = on_time_row["2025"]
                        actual_target = (
                            int(round((on_time_year_val / total_year_val) * 100))
                            if total_year_val > 0
                            else 0
                        )
                    except Exception:
                        actual_target = 100

                    # âœ… Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø´Ù‡ÙˆØ± Ø§Ù„Ù„ÙŠ ÙÙŠÙ‡Ø§ Ù‚ÙŠÙ… ØºÙŠØ± ØµÙØ±ÙŠØ© (ÙÙ‚Ø· Ù„Ù„Ø´Ø§Ø±Øª)
                    nonzero_months = [
                        m for i, m in enumerate(existing_months) if percent_hit[i] > 0
                    ]
                    nonzero_percents = [
                        percent_hit[i]
                        for i, m in enumerate(existing_months)
                        if percent_hit[i] > 0
                    ]
                    if not nonzero_months:
                        nonzero_months = existing_months
                        nonzero_percents = [
                            percent_hit[i] for i in range(len(existing_months))
                        ]

                    chart_data.append(
                        {
                            "type": "column",
                            "name": "On-Time Delivery (%)",
                            "color": "#9fc0e4",
                            "showInLegend": True,
                            "related_table": "Miss Breakdown â€“ 3PL Side",  # âœ… Ø±Ø¨Ø· Ø§Ù„Ø´Ø§Ø±Øª Ø¨Ø§Ù„Ø¬Ø¯ÙˆÙ„
                            "dataPoints": [
                                {"label": m, "y": nonzero_percents[i]}
                                for i, m in enumerate(nonzero_months)
                            ],
                        }
                    )
                    chart_data.append(
                        {
                            "type": "line",
                            "name": f"Target ({actual_target}%)",
                            "color": "red",
                            "showInLegend": True,
                            "related_table": "Miss Breakdown â€“ 3PL Side",  # âœ… Ø±Ø¨Ø· Ø§Ù„Ø´Ø§Ø±Øª Ø¨Ø§Ù„Ø¬Ø¯ÙˆÙ„
                            "dataPoints": [
                                {"label": m, "y": actual_target} for m in nonzero_months
                            ],
                        }
                    )

                    sub_tables.append(
                        {
                            "title": "Miss Breakdown â€“ 3PL Side",
                            "columns": list(final_df_3pl.columns),
                            "data": final_df_3pl.to_dict(orient="records"),
                        }
                    )
                    # Ù„Ù… Ù†Ø¹Ø¯ Ù†Ø¶ÙŠÙ Ø¬Ø¯ÙˆÙ„ Missing Months Ù‡Ù†Ø§ØŒ ÙŠØªÙ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡ Ù„Ø§Ø­Ù‚Ù‹Ø§ Ø¹Ø¨Ø± apply_month_filter_to_tab

            # ----------------------------
            # ğŸŸ¥ Ø¬Ø¯ÙˆÙ„ ROCHE SIDE
            # ----------------------------
            sheet_roche = next(
                (s for s in xls.sheet_names if "preformance -r" in s.lower()), None
            )
            if sheet_roche:
                df = pd.read_excel(
                    excel_path, sheet_name=sheet_roche, engine="openpyxl"
                )
                df.columns = df.columns.str.strip()
                if "Month" in df.columns:
                    month_order = [
                        "Jan",
                        "Feb",
                        "Mar",
                        "Apr",
                        "May",
                        "Jun",
                        "Jul",
                        "Aug",
                        "Sep",
                        "Oct",
                        "Nov",
                        "Dec",
                    ]
                    df["Month"] = pd.Categorical(
                        df["Month"], categories=month_order, ordered=True
                    )
                    df = df.sort_values("Month")

                    if selected_month_norm:
                        df_filtered = df[
                            df["Month"].astype(str).str.lower()
                            == selected_month_norm.lower()
                        ]
                        if df_filtered.empty:
                            sub_tables.append(
                                {
                                    "title": "Miss Breakdown â€“ Roche Side",
                                    "columns": [],
                                    "data": [],
                                    "message": f"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø© Ù„Ù„Ø´Ù‡Ø± {selected_month_norm}.",
                                }
                            )
                        else:
                            df_melted = df_filtered.melt(
                                id_vars=["Month"], var_name="KPI", value_name="Count"
                            )
                            pivot_df = (
                                df_melted.groupby(["KPI", "Month"])["Count"]
                                .sum()
                                .unstack(fill_value=0)
                            )
                            pivot_df["2025"] = pivot_df.sum(axis=1)
                            total_row = pivot_df.sum(numeric_only=True)
                            total_row.name = "TOTAL"
                            pivot_df = pd.concat([pivot_df, pd.DataFrame([total_row])])
                            pivot_df.reset_index(inplace=True)
                            pivot_df.rename(columns={"index": "KPI"}, inplace=True)
                            keep_cols = [
                                col
                                for col in ["KPI", selected_month_norm]
                                if col in pivot_df.columns
                            ]
                            pivot_df = pivot_df[keep_cols]
                            sub_tables.append(
                                {
                                    "title": "Miss Breakdown â€“ Roche Side",
                                    "columns": list(pivot_df.columns),
                                    "data": pivot_df.to_dict(orient="records"),
                                }
                            )
                    elif selected_months_norm:
                        df_filtered = df[
                            df["Month"]
                            .astype(str)
                            .str.lower()
                            .isin([m.lower() for m in selected_months_norm])
                        ]
                        if df_filtered.empty:
                            sub_tables.append(
                                {
                                    "title": "Miss Breakdown â€“ Roche Side",
                                    "columns": [],
                                    "data": [],
                                    "message": "âš ï¸ No data available for the selected quarter months.",
                                }
                            )
                        else:
                            df_melted = df_filtered.melt(
                                id_vars=["Month"], var_name="KPI", value_name="Count"
                            )
                            pivot_df = (
                                df_melted.groupby(["KPI", "Month"])["Count"]
                                .sum()
                                .unstack(fill_value=0)
                            )
                            ordered_months = [
                                m for m in selected_months_norm if m in pivot_df.columns
                            ]
                            for m in selected_months_norm:
                                if m not in pivot_df.columns:
                                    pivot_df[m] = 0
                            pivot_df = pivot_df[selected_months_norm]
                            pivot_df["2025"] = pivot_df.sum(axis=1)
                            total_row = pivot_df.sum(numeric_only=True)
                            total_row.name = "TOTAL"
                            pivot_df = pd.concat([pivot_df, pd.DataFrame([total_row])])
                            pivot_df.reset_index(inplace=True)
                            pivot_df.rename(columns={"index": "KPI"}, inplace=True)
                            sub_tables.append(
                                {
                                    "title": "Miss Breakdown â€“ Roche Side",
                                    "columns": list(pivot_df.columns),
                                    "data": pivot_df.to_dict(orient="records"),
                                }
                            )
                    else:
                        df_melted = df.melt(
                            id_vars=["Month"], var_name="KPI", value_name="Count"
                        )
                        pivot_df = (
                            df_melted.groupby(["KPI", "Month"])["Count"]
                            .sum()
                            .unstack(fill_value=0)
                            .reindex(columns=month_order, fill_value=0)
                        )
                        pivot_df["2025"] = pivot_df.sum(axis=1)
                        total_row = pivot_df.sum(numeric_only=True)
                        total_row.name = "TOTAL"
                        pivot_df = pd.concat([pivot_df, pd.DataFrame([total_row])])
                        pivot_df.reset_index(inplace=True)
                        pivot_df.rename(columns={"index": "KPI"}, inplace=True)
                        pivot_df = pivot_df.loc[:, (pivot_df != 0).any(axis=0)]

                        sub_tables.append(
                            {
                                "title": "Miss Breakdown â€“ Roche Side",
                                "columns": list(pivot_df.columns),
                                "data": pivot_df.to_dict(orient="records"),
                            }
                        )

            # Outbound Shipments (Outbound1 + Outbound2, Hit/Miss) â€” Ù†ÙØ³ ÙÙƒØ±Ø© Inbound
            outbound_result = self.filter_outbound_shipments(
                request,
                selected_month if not selected_months_norm else None,
                selected_months_norm if selected_months_norm else None,
            )
            # âœ… Ø¬Ù„Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ù€ Hit Ù…Ù† Outbound (Ù‡ÙŠ Ø§Ù„Ù„ÙŠ Ù‡Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§ ÙƒÙ€ KPI Ù„Ù„ØªØ§Ø¨ Ø¯Ù‡)
            outbound_stats = outbound_result.get("stats", {}) or {}
            outbound_hit_pct = outbound_stats.get("hit_pct", 0) or 0
            # âœ… Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ statsØŒ Ù†Ø­Ø§ÙˆÙ„ Ø¬Ù„Ø¨Ù‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† outbound_result
            if not outbound_hit_pct:
                outbound_hit_pct = outbound_result.get("hit_pct", 0) or 0
            print(
                f"ğŸ” Total Lead Time Performance - Outbound hit_pct: {outbound_hit_pct}% (from stats: {outbound_stats.get('hit_pct', 'N/A')})"
            )

            if outbound_result.get("sub_tables"):
                outbound_tab = {
                    "name": "Outbound Shipments",
                    "stats": outbound_result.get("stats", {}),
                    "sub_tables": outbound_result["sub_tables"],
                    "chart_data": outbound_result.get("chart_data", []),
                }
                outbound_html = render_to_string(
                    "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
                    {
                        "tab": outbound_tab,
                        "selected_month": selected_month
                        or (selected_months_norm[0] if selected_months_norm else None),
                    },
                )
            else:
                outbound_html = outbound_result.get("detail_html", "")

            # Ù„Ø§ Ù†Ø±Ø¬Ø¹ "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª" Ø¥Ù„Ø§ Ù„Ùˆ Ù…ÙÙŠØ´ Ø¬Ø¯Ø§ÙˆÙ„ Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆÙ…ÙÙŠØ´ Ù…Ø­ØªÙˆÙ‰ Outbound
            has_outbound = bool(outbound_html and str(outbound_html).strip())
            if not sub_tables and not has_outbound:
                return {
                    "detail_html": "<p class='text-muted'>âš ï¸ No valid data was found in any sheets.</p>",
                    "chart_data": [],
                    "count": 0,
                }

            # âœ… Ù„Ø§ Ù†Ø­ØªØ§Ø¬ Ù„ØªØ¹ÙŠÙŠÙ† related_table Ù‡Ù†Ø§ Ù„Ø£Ù†Ù‡ ØªÙ… ØªØ¹ÙŠÙŠÙ†Ù‡ Ø¨Ø§Ù„ÙØ¹Ù„ Ù„ÙƒÙ„ dataset
            # if chart_data:
            #     for dataset in chart_data:
            #         dataset.setdefault("related_table", "Total Lead Time Performance")

            tab_data = {
                "name": "Outbound",
                "sub_tables": sub_tables,
                "outbound_html": outbound_html,
                "chart_data": chart_data,
            }
            month_norm_tab = self.apply_month_filter_to_tab(
                tab_data,
                selected_month_norm if not selected_months_norm else None,
                selected_months_norm or None,
            )

            html = render_to_string(
                "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
                {
                    "tab": tab_data,
                    "selected_month": month_norm_tab,
                    "selected_months": selected_months_norm,
                },
            )

            total_count = sum(len(st["data"]) for st in sub_tables)

            # âœ… Ù†Ø³Ø¨Ø© Ø§Ù„Ù€ Hit Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù€ Outbound (Ù‡ÙŠ Ø§Ù„Ù„ÙŠ Ù‡Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§ ÙƒÙ€ KPI Ù„Ù„ØªØ§Ø¨ Ø¯Ù‡)
            try:
                hit_pct_calculated = (
                    float(outbound_hit_pct) if outbound_hit_pct else 0.0
                )
                hit_pct_calculated = round(hit_pct_calculated, 2)  # ØªÙ‚Ø±ÙŠØ¨ Ù„Ø±Ù‚Ù…ÙŠÙ† Ø¹Ø´Ø±ÙŠÙŠÙ†
            except (ValueError, TypeError):
                hit_pct_calculated = 0.0
            print(
                f"âœ… Total Lead Time Performance - Using Outbound hit_pct: {hit_pct_calculated}%"
            )

            # âœ… Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ chart_data Ù…Ù† 3PLØŒ Ù†Ø³ØªØ®Ø¯Ù… chart_data Ù…Ù† Outbound
            if not chart_data:
                outbound_chart_data = outbound_result.get("chart_data", []) or []
                if outbound_chart_data:
                    chart_data = outbound_chart_data
                    print(
                        f"âœ… Total Lead Time Performance - Using Outbound chart_data: {len(chart_data)} datasets"
                    )

            print(
                f"âœ… Total Lead Time Performance - Final chart_data: {len(chart_data)} datasets"
            )

            return {
                "detail_html": html,
                "chart_data": chart_data,
                "chart_title": "Total Lead Time Performance â€“ On-Time Delivery",
                "count": total_count,
                "hit_pct": hit_pct_calculated,  # âœ… Ù†Ø³Ø¨Ø© Ø§Ù„Ù€ Hit Ù…Ù† Outbound
                "tab_data": tab_data,
            }

        except Exception as e:
            import traceback

            print(traceback.format_exc())
            return {
                "detail_html": f"<p class='text-danger'>âš ï¸ Error while processing data: {e}</p>",
                "chart_data": [],
                "count": 0,
                "hit_pct": 0,  # âœ… Ø¥Ø¶Ø§ÙØ© hit_pct ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
            }

    def filter_dock_to_stock_combined(
        self, request, selected_month=None, selected_months=None
    ):
        """
        ğŸ”¹ ÙŠØ¹Ø±Ø¶ ØªØ§Ø¨ Dock to stock Ø¨Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Inbound (KPI â‰¤24h).
        """
        cache.clear()
        print("ğŸš€ Ù…Ø¹Ø§Ù„Ø¬Ø© Dock to stock â€” Inbound KPI")

        try:
            from django.template.loader import render_to_string

            inbound_result = self.filter_inbound(
                request, selected_month, selected_months
            )
            sub_tables = inbound_result.get("sub_tables", [])
            chart_data = inbound_result.get("chart_data", [])

            if not sub_tables:
                fallback_html = inbound_result.get("detail_html") or (
                    "<p class='text-warning'>âš ï¸ No inbound data available.</p>"
                )
                return {
                    "chart_data": chart_data,
                    "detail_html": fallback_html,
                    "count": 0,
                }

            tab_data = {
                "name": "Inbound",
                "sub_tables": sub_tables,
                "chart_data": chart_data,
                "canvas_id": "chart-inbound-kpi",
            }

            selected_months_norm = []
            if selected_months:
                if isinstance(selected_months, str):
                    selected_months = [selected_months]
                seen = set()
                for m in selected_months:
                    norm = self.normalize_month_label(m)
                    if norm and norm not in seen:
                        seen.add(norm)
                        selected_months_norm.append(norm)

            month_norm_tab = self.apply_month_filter_to_tab(
                tab_data,
                None if selected_months_norm else selected_month,
                selected_months_norm or None,
            )

            html = render_to_string(
                "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
                {"tab": tab_data, "selected_month": month_norm_tab},
            )

            stats = inbound_result.get("stats", {})
            total_count = stats.get(
                "total", sum(len(st.get("data", [])) for st in sub_tables)
            )
            hit_pct = stats.get("hit_pct", 0)

            result = {
                "chart_data": chart_data,
                "detail_html": html,
                "count": total_count,
                "canvas_id": tab_data["canvas_id"],
                "hit_pct": hit_pct,
                "target_pct": 100,
                "tab_data": tab_data,
            }
            return _sanitize_for_json(result)
        except Exception as e:
            import traceback

            print(traceback.format_exc())
            return {
                "chart_data": [],
                "detail_html": f"<p class='text-danger'>âš ï¸ Error: {e}</p>",
                "count": 0,
            }
        cache.clear()
        print("ğŸš€ Ø¯Ø®Ù„Ù†Ø§ Ø§Ù„Ø¯Ø§Ù„Ø© filter_dock_to_stock_combined")

        """
        âœ… ÙØµÙ„ Dock to stock Ø¥Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ÙŠÙ† (3PL + Roche)
        âœ… ØªØ±ØªÙŠØ¨ Ø§Ù„Ø´Ù‡ÙˆØ± Jan â†’ Dec
        âœ… Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ§Ø±Ø¬Øª Ø§Ù„ØµØ­ÙŠØ­ (on time / total * 100)
        âœ… Ø§Ù„Ø´Ø§Ø±Øª Ù…ÙˆØ­Ø¯ (On Time % + Target)
        âœ… Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ù†ÙØµÙ„Ø©
        """
        try:
            import pandas as pd
            import numpy as np
            import os
            from django.template.loader import render_to_string
            from django.utils.text import slugify

            if request and hasattr(request, "session"):
                excel_path = (
                    request.session.get("uploaded_excel_path") or self.get_excel_path()
                )
            else:
                excel_path = self.get_excel_path()

            if not excel_path or not os.path.exists(excel_path):
                return {
                    "chart_data": [],
                    "detail_html": "<p class='text-danger'>âš ï¸ Excel file not found.</p>",
                    "count": 0,
                }

            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø´Ù‡ÙˆØ±
            def order_months(months):
                month_map = {
                    "jan": 1,
                    "feb": 2,
                    "mar": 3,
                    "apr": 4,
                    "may": 5,
                    "jun": 6,
                    "jul": 7,
                    "aug": 8,
                    "sep": 9,
                    "oct": 10,
                    "nov": 11,
                    "dec": 12,
                }
                months_unique = list(dict.fromkeys(months))

                def month_key(m):
                    if m is None:
                        return 999
                    m_str = str(m).strip()
                    m_lower = m_str.lower()[:3]
                    if m_lower in month_map:
                        return month_map[m_lower]
                    if m_str.isdigit():
                        return 1000 + int(m_str)
                    return 2000 + months_unique.index(m)

                return sorted(months_unique, key=month_key)

            # =======================================
            # ğŸŸ¢ Ù…Ø¹Ø§Ù„Ø¬Ø© Dock to Stock (3PL)
            # =======================================
            selected_months_norm = []
            if selected_months:
                if isinstance(selected_months, str):
                    selected_months = [selected_months]
                seen = set()
                for m in selected_months:
                    norm = self.normalize_month_label(m)
                    if norm and norm not in seen:
                        seen.add(norm)
                        selected_months_norm.append(norm)

            result_3pl = self.filter_dock_to_stock_3pl(
                request, selected_month, selected_months
            )
            df_3pl_table = pd.DataFrame()
            df_chart_combined = {}
            selected_month_norm = None
            if selected_month and not selected_months_norm:
                raw_month = str(selected_month).strip()
                parsed = pd.to_datetime(raw_month, errors="coerce")
                if pd.isna(parsed):
                    selected_month_norm = raw_month[:3].capitalize()
                else:
                    selected_month_norm = parsed.strftime("%b")

            if "chart_data" in result_3pl and result_3pl["chart_data"]:
                df_kpi_full = pd.DataFrame(result_3pl["chart_data"])

                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¥Ù„Ù‰ int
                for col in df_kpi_full.columns:
                    if col != "KPI":
                        df_kpi_full[col] = df_kpi_full[col].apply(
                            lambda x: int(round(float(x))) if pd.notna(x) else 0
                        )

                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø³Ø¨ Ø§Ù„Ø´Ù‡Ø±ÙŠØ©
                on_time_rows = df_kpi_full[
                    df_kpi_full["KPI"].str.lower().str.contains("on time", na=False)
                ]
                total_rows = df_kpi_full[
                    df_kpi_full["KPI"].str.lower().str.contains("total", na=False)
                ]

                target_correct, on_time_percentage = {}, {}
                month_cols = [
                    c
                    for c in df_kpi_full.columns
                    if c not in ["KPI", "2025", "Total", "TOTAL"]
                ]

                for col in month_cols:
                    try:
                        on_time_val = float(on_time_rows[col].sum())
                        total_val = float(total_rows[col].sum())
                        percentage = (
                            int(round((on_time_val / total_val) * 100))
                            if total_val
                            else 0
                        )
                        target_correct[col] = percentage
                        on_time_percentage[col] = percentage
                    except Exception as e:
                        print(f"âš ï¸ Error in {col}: {e}")
                        target_correct[col] = on_time_percentage[col] = 0

                df_chart_combined["3PL On Time %"] = on_time_percentage
                df_chart_combined["Target"] = target_correct

                # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
                df_kpi = df_kpi_full[
                    ~df_kpi_full["KPI"].str.lower().str.contains("target", na=False)
                ].copy()
                ordered_cols = ["KPI"] + [
                    c for c in order_months(df_kpi.columns.tolist()) if c != "KPI"
                ]
                df_3pl_table = df_kpi[ordered_cols]
                if selected_months_norm:
                    keep_cols = ["KPI"] + [
                        m for m in selected_months_norm if m in df_3pl_table.columns
                    ]
                    if "2025" in df_3pl_table.columns:
                        keep_cols.append("2025")
                    df_3pl_table = df_3pl_table[
                        [col for col in keep_cols if col in df_3pl_table.columns]
                    ]
                elif selected_month_norm:
                    keep_cols = ["KPI", selected_month_norm]
                    if "2025" in df_3pl_table.columns:
                        keep_cols.append("2025")
                    df_3pl_table = df_3pl_table[
                        [col for col in keep_cols if col in df_3pl_table.columns]
                    ]

                # âœ… Ø¥Ø¶Ø§ÙØ© ØµÙ "3PL Delay" Ø¨Ø¹Ø¯ "On Time Receiving"
                on_time_receiving_idx = None
                for idx in df_3pl_table.index:
                    kpi_value = str(df_3pl_table.loc[idx, "KPI"]).strip()
                    if "on time receiving" in kpi_value.lower():
                        on_time_receiving_idx = idx
                        break

                if on_time_receiving_idx is not None:
                    # Ø¥Ù†Ø´Ø§Ø¡ ØµÙ Ø¬Ø¯ÙŠØ¯ Ø¨Ù‚ÙŠÙ… ØµÙØ±ÙŠØ©
                    delay_row = {"KPI": "3PL Delay"}
                    for col in df_3pl_table.columns:
                        if col != "KPI":
                            delay_row[col] = 0

                    # ØªØ­ÙˆÙŠÙ„ DataFrame Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³
                    rows_list = df_3pl_table.to_dict(orient="records")

                    # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙˆØ¶Ø¹ Ø§Ù„ØµÙ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
                    insert_position = None
                    for i, row_dict in enumerate(rows_list):
                        kpi_value = str(row_dict.get("KPI", "")).strip()
                        if "on time receiving" in kpi_value.lower():
                            insert_position = i + 1
                            break

                    # Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„ØµÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯
                    if insert_position is not None:
                        rows_list.insert(insert_position, delay_row)
                        df_3pl_table = pd.DataFrame(rows_list)

            reasons_3pl = result_3pl.get("reason", [])

            # =======================================
            # ğŸ”µ Ù…Ø¹Ø§Ù„Ø¬Ø© Dock to Stock (Roche)
            # =======================================
            reasons_roche = []
            try:

                # df_roche = pd.read_excel(excel_path, sheet_name="Dock to stock - Roche", engine="openpyxl")
                # Ù‚Ø±Ø§Ø¡Ø© ÙƒÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª Ø£ÙˆÙ„Ø§Ù‹
                xls = pd.ExcelFile(excel_path, engine="openpyxl")

                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ø´ÙŠØª Ø§Ù„ØµØ­ÙŠØ­ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ (Ø­ØªÙ‰ Ù„Ùˆ Ø§Ù„Ø§Ø³Ù… ÙÙŠÙ‡ Ù…Ø³Ø§ÙØ§Øª Ø£Ùˆ Ø§Ø®ØªÙ„Ø§Ù Ø­Ø±ÙˆÙ)
                sheet_name = None
                for name in xls.sheet_names:
                    if (
                        "dock" in name.lower()
                        and "stock" in name.lower()
                        and "roche" in name.lower()
                    ):
                        sheet_name = name
                        break

                if not sheet_name:
                    raise ValueError(
                        f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø´ÙŠØª Roche ÙÙŠ Ø§Ù„Ù…Ù„Ù. Ø§Ù„Ø´ÙŠØªØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©: {xls.sheet_names}"
                    )

                print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø´ÙŠØª: {sheet_name}")

                # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø´ÙŠØª Ø§Ù„ØµØ­ÙŠØ­
                df_roche = pd.read_excel(xls, sheet_name=sheet_name)
                df_roche.columns = df_roche.columns.astype(str).str.strip()

                print("ğŸ” Roche columns:", df_roche.columns.tolist())

                month_col = df_roche.columns[0]

                melted_df = df_roche.melt(
                    id_vars=[month_col], var_name="KPI", value_name="Value"
                )
                pivot_df = (
                    melted_df.pivot_table(
                        index="KPI", columns=month_col, values="Value", aggfunc="sum"
                    )
                    .reset_index()
                    .rename_axis(None, axis=1)
                )

                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ int
                for col in pivot_df.columns:
                    if col != "KPI":
                        pivot_df[col] = pivot_df[col].apply(
                            lambda x: int(round(float(x))) if pd.notna(x) else 0
                        )

                ordered_cols = ["KPI"] + [
                    c for c in order_months(pivot_df.columns.tolist()) if c != "KPI"
                ]
                pivot_df = pivot_df[ordered_cols]

                # Ø­Ø°Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© "Total" Ø¨Ø¹Ø¯ Ø§Ù„Ø´Ù‡ÙˆØ±
                pivot_df = pivot_df.loc[
                    :, ~pivot_df.columns.str.lower().str.contains("total")
                ]

                # Ø­Ø³Ø§Ø¨ Ø¹Ù…ÙˆØ¯ 2025 (Ø¥Ø¬Ù…Ø§Ù„ÙŠ ÙƒÙ„ Ø§Ù„Ø´Ù‡ÙˆØ±)
                # Ø­Ø³Ø§Ø¨ Ø¹Ù…ÙˆØ¯ 2025 (Ø¥Ø¬Ù…Ø§Ù„ÙŠ ÙƒÙ„ Ø§Ù„Ø´Ù‡ÙˆØ±)
                month_cols = [
                    c
                    for c in pivot_df.columns
                    if c not in ["KPI", "Reason Group", "2025"]
                ]
                pivot_df["2025"] = pivot_df[month_cols].sum(axis=1).astype(int)

                # Ø¥Ø¶Ø§ÙØ© ØµÙ Total ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¬Ø¯ÙˆÙ„
                total_row = {"KPI": "Total (Roche)"}
                for col in pivot_df.columns:
                    if col != "KPI":
                        total_row[col] = int(pivot_df[col].sum())
                pivot_df = pd.concat(
                    [pivot_df, pd.DataFrame([total_row])], ignore_index=True
                )

                # Ø­Ø°Ù Ø¹Ù…ÙˆØ¯ Reason Group Ù†Ù‡Ø§Ø¦ÙŠÙ‹Ø§ Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹
                if "Reason Group" in pivot_df.columns:
                    pivot_df = pivot_df.drop(columns=["Reason Group"])

                df_roche_table = pivot_df
                if selected_months_norm:
                    roche_cols = ["KPI"] + [
                        m for m in selected_months_norm if m in df_roche_table.columns
                    ]
                    if "2025" in df_roche_table.columns:
                        roche_cols.append("2025")
                    df_roche_table = df_roche_table[
                        [col for col in roche_cols if col in df_roche_table.columns]
                    ]
                elif selected_month_norm:
                    roche_cols = ["KPI", selected_month_norm]
                    if "2025" in df_roche_table.columns:
                        roche_cols.append("2025")
                    df_roche_table = df_roche_table[
                        [col for col in roche_cols if col in df_roche_table.columns]
                    ]
                # reasons_roche = self.filter_dock_to_stock_roche_reasons(request)
                reasons_roche = []

            except Exception as e:
                print(f"âš ï¸ Roche read error: {e}")
                df_roche_table = pd.DataFrame()

            # =======================================
            # ğŸŸ£ ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø´Ø§Ø±Øª
            # =======================================
            all_months = order_months(
                sorted(
                    set().union(*[list(v.keys()) for v in df_chart_combined.values()])
                )
            )
            if selected_months_norm:
                all_months = [m for m in selected_months_norm if m in all_months]
            on_time_values = df_chart_combined.get("3PL On Time %", {})
            target_values = df_chart_combined.get("Target", {})

            hit_pct = (
                min(round(float(np.mean(list(on_time_values.values()))), 2), 100)
                if on_time_values
                else 0
            )
            target_pct = (
                min(round(float(np.mean(list(target_values.values()))), 2), 100)
                if target_values
                else 100
            )

            chart_data = []
            if selected_month_norm or any(v != 0 for v in on_time_values.values()):
                chart_data.append(
                    {
                        "type": "column",
                        "name": "On time receiving (%)",
                        "color": "#d0e7ff",
                        "showInLegend": False,  # âœ… Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ù€ legend Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±
                        "dataPoints": [
                            {"label": m, "y": min(float(on_time_values.get(m, 0)), 100)}
                            for m in all_months
                        ],
                    }
                )

            # âœ… Ø¥Ø²Ø§Ù„Ø© dataset Ø§Ù„Ù€ target Ù„Ø£Ù†Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… Ø®Ø· Ù…Ø®ØµØµ ÙÙ‚Ø·
            # if selected_month_norm or any(v != 0 for v in target_values.values()):
            #     chart_data.append(...)

            inbound_result = self.filter_inbound(
                request, selected_month, selected_months
            )
            inbound_html = inbound_result.get("detail_html", "")
            inbound_sub_table = inbound_result.get("sub_table")
            combined_reasons = list(reasons_3pl) + list(reasons_roche)

            # =======================================
            # ğŸ§± Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            # =======================================
            if chart_data:
                for dataset in chart_data:
                    dataset.setdefault("related_table", "Inbound")

            # âœ… Ø¥Ø¶Ø§ÙØ© chart_data Ù„ÙƒÙ„ sub_table Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„
            chart_data_3pl = []
            chart_data_roche = []
            if chart_data:
                for dataset in chart_data:
                    dataset_3pl = dataset.copy()
                    dataset_3pl["related_table"] = "Inbound â€” 3PL"
                    chart_data_3pl.append(dataset_3pl)

                    dataset_roche = dataset.copy()
                    dataset_roche["related_table"] = "Inbound â€” Roche"
                    chart_data_roche.append(dataset_roche)

            tab_data = {
                "name": "Inbound",
                "sub_tables": [
                    {
                        "id": "sub-table-inbound-3pl",
                        "title": "Inbound â€” 3PL",
                        "columns": df_3pl_table.columns.tolist(),
                        "data": df_3pl_table.to_dict(orient="records"),
                        "chart_data": chart_data_3pl,
                    },
                    {
                        "id": "sub-table-inbound-roche",
                        "title": "Inbound â€” Roche",
                        "columns": df_roche_table.columns.tolist(),
                        "data": df_roche_table.to_dict(orient="records"),
                        "chart_data": chart_data_roche,
                    },
                ],
                "combined_reasons": combined_reasons,
                "canvas_id": f"chart-{slugify('inbound')}",
                "inbound_html": inbound_html,
                "chart_data": chart_data,  # âœ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù€ chart_data Ø§Ù„Ø¹Ø§Ù… Ø£ÙŠØ¶Ø§Ù‹
            }
            if inbound_sub_table:
                tab_data["sub_tables"].append(inbound_sub_table)
            month_norm_tab = self.apply_month_filter_to_tab(
                tab_data,
                (
                    (selected_month_norm or selected_month)
                    if not selected_months_norm
                    else None
                ),
                selected_months_norm or None,
            )

            html = render_to_string(
                "forms-table/table/bootstrap-table/basic-table/components/excel-sheet-table.html",
                {"tab": tab_data, "selected_month": month_norm_tab},
            )

            total_count = len(df_3pl_table) + len(df_roche_table)

            print(f"ğŸ“Š [RESULT] Inbound â€” Hit={hit_pct}%, Target={target_pct}")

            return {
                "chart_data": chart_data,
                "detail_html": html,
                "count": total_count,
                "canvas_id": tab_data["canvas_id"],
                "hit_pct": hit_pct,
                "target_pct": target_pct,
                "tab_data": tab_data,
            }

        except Exception as e:
            import traceback

            print(traceback.format_exc())
            return {
                "chart_data": [],
                "detail_html": f"<p class='text-danger'>âš ï¸ Error: {e}</p>",
                "count": 0,
            }

    def overview_tab(
        self,
        request=None,
        selected_month=None,
        selected_months=None,
        from_all_in_one=False,
    ):
        from concurrent.futures import ThreadPoolExecutor, as_completed

        cache.clear()
        tab_cards = []

        target_manual = {
            "inbound": 99,
            "outbound": 98,
            "total lead time performance": 98,
            "pods update": 98,
            "return & refusal": 100,
        }

        def process_tab(tab_name):
            detail_html, count, hit_pct = "", 0, 0
            try:
                res = {}
                tab_lower = tab_name.lower()
                month_for_filters = selected_month if not selected_months else None

                if tab_lower in ["rejections", "return & refusal"]:
                    res = self.filter_rejections_combined(
                        request,
                        month_for_filters,
                        selected_months=selected_months,
                    )
                elif tab_lower == "inbound":
                    res = self.filter_dock_to_stock_combined(
                        request,
                        month_for_filters,
                        selected_months=selected_months,
                    )
                elif "pods update" in tab_lower:
                    res = self.filter_pods_update(request, month_for_filters)
                elif tab_lower == "outbound" or "total lead time performance" in tab_lower:
                    res = self.filter_total_lead_time_performance(
                        request,
                        month_for_filters,
                        selected_months=selected_months,
                    )

                # Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø²ÙŠ Ù…Ø§ Ø±Ø§Ø¬Ø¹Ø© Ù…Ù† Ø§Ù„Ø¯Ø§Ù„Ø©
                hit_pct = res.get("hit_pct", 0)
                if isinstance(hit_pct, dict):
                    if selected_month and selected_month.capitalize() in hit_pct:
                        hit_pct_val = hit_pct[selected_month.capitalize()]
                    else:
                        # Ù†Ø­Ø³Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø·
                        hit_pct_val = int(round(sum(hit_pct.values()) / len(hit_pct)))
                else:
                    try:
                        hit_pct_val = int(round(float(hit_pct)))
                    except:
                        hit_pct_val = 0

                hit_pct_val = max(0, min(hit_pct_val, 100))

                target_pct = target_manual.get(tab_lower, 100)
                color_class = "bg-success" if hit_pct >= target_pct else "bg-danger"

                progress_html = f"""
                    <div class='mb-3'>
                        <div class='d-flex justify-content-between align-items-center mb-1'>
                            <strong class='text-capitalize'>{tab_name}</strong>
                            <small>{hit_pct}% / Target: {target_pct}%</small>
                        </div>
                        <div class='progress' style='height: 20px;'>
                            <div class='progress-bar {color_class}' role='progressbar'
                                 style='width: {hit_pct}%;' aria-valuenow='{hit_pct}'
                                 aria-valuemin='0' aria-valuemax='100'>
                                 {hit_pct}%
                            </div>
                        </div>
                    </div>
                """

                detail_html = progress_html + (res.get("detail_html", "") or "")
                count = res.get("count", 0)

            except Exception:
                detail_html = "<p class='text-muted'>No data available.</p>"
                hit_pct = 0
                target_pct = target_manual.get(tab_name.lower(), 100)

            return {
                "name": tab_name,
                "hit_pct": hit_pct_val,
                "target_pct": target_pct,
                "detail_html": detail_html,
                "count": count,
            }

        tabs_order = [
            "Inbound",
            "Outbound",
            "Return & Refusal",
            "PODs update",
        ]

        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = {executor.submit(process_tab, t): t for t in tabs_order}
            for future in as_completed(futures):
                tab_cards.append(future.result())

        tab_cards.sort(key=lambda x: tabs_order.index(x["name"]))

        if not from_all_in_one:
            tab_cards = [
                t
                for t in tab_cards
                if t.get("name", "").strip().lower()
                not in ["rejections", "return & refusal"]
            ]

        all_progress_html = "<div class='card p-4 shadow-sm rounded-4 mb-4'>"
        all_progress_html += (
            "<h5 class='fw-bold text-primary mb-3'>ğŸ“ˆ Ù†Ø³Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„ÙƒÙ„ Ø§Ù„ØªØ§Ø¨Ø§Øª</h5>"
        )
        for tab in tab_cards:
            color_class = (
                "bg-success" if tab["hit_pct"] >= tab["target_pct"] else "bg-danger"
            )
            all_progress_html += f"""
                <div class='mb-3'>
                    <div class='d-flex justify-content-between align-items-center mb-1'>
                        <strong>{tab['name']}</strong>
                        <small>{tab['hit_pct']}% / Target: {tab['target_pct']}%</small>
                    </div>
                    <div class='progress' style='height: 20px;'>
                        <div class='progress-bar {color_class}' role='progressbar'
                             style='width: {tab['hit_pct']}%;' aria-valuenow='{tab['hit_pct']}'
                             aria-valuemin='0' aria-valuemax='100'>
                             {tab['hit_pct']}%
                        </div>
                    </div>
                </div>
            """
        all_progress_html += "</div>"

        return {"tab_cards": tab_cards, "detail_html": all_progress_html}

    def _get_dashboard_include_context(self, request):
        """
        ÙŠÙØ±Ø¬Ø¹ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ (Ù†ÙØ³ Ù…Ù†Ø·Ù‚ dashboard_tab) Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ø¹Ù†Ø¯ include
        container-fluid-dashboard ÙÙŠ Ø§Ù„ØªÙ…Ø¨Ù„Øª Ø­ØªÙ‰ ØªÙˆØ±Ø« base ÙˆØ§Ù„Ù„ÙŠÙ†ÙƒØ§Øª ÙˆØ§Ù„Ø´Ø§Ø±ØªØ³.
        """
        context = get_dashboard_tab_context(request)
        context["title"] = self.DASHBOARD_TAB_NAME
        excel_path = _get_dashboard_excel_path(request) or _get_excel_path_for_request(request)
        if excel_path:
            inbound_data = _read_inbound_data_from_excel(excel_path)
            if inbound_data:
                context["inbound_kpi"] = inbound_data["inbound_kpi"]
                context["pending_shipments"] = inbound_data["pending_shipments"]
            # Ø´Ø§Ø±ØªØ§Øª Ø¯ÙŠÙ†Ø§Ù…Ùƒ Ù…Ù† Ø§Ù„Ø¥ÙƒØ³Ù„ (Ù†ÙØ³ ÙÙƒØ±Ø© chart_data ÙÙŠ rejection)
            charts_from_excel = _read_dashboard_charts_from_excel(excel_path)
            for key, value in charts_from_excel.items():
                if value is not None:
                    context[key] = value
            outbound_data = _read_outbound_data_from_excel(excel_path)
            if outbound_data:
                context.setdefault(
                    "outbound_kpi",
                    {
                        "released_orders": 146,
                        "picked_orders": 120,
                        "pod_compliance_pct": 94,
                        "insight_text": "Delays mainly caused by transportation issues or customer confirmation.",
                    },
                )
                context["outbound_kpi"]["released_orders"] = outbound_data["released_orders"]
                context["outbound_kpi"]["picked_orders"] = outbound_data["picked_orders"]
            pods_chart = _read_pods_data_from_excel(excel_path)
            if pods_chart:
                context["pod_compliance_chart_data"] = pods_chart
            returns_data = _read_returns_data_from_excel(excel_path)
            if returns_data:
                context["returns_kpi"] = returns_data["returns_kpi"]
                context["returns_chart_data"] = returns_data["returns_chart_data"]
            inventory_data = _read_inventory_data_from_excel(excel_path)
            if inventory_data:
                context["inventory_kpi"] = inventory_data["inventory_kpi"]
            capacity_data = _read_inventory_snapshot_capacity_from_excel(excel_path)
            if capacity_data:
                context["inventory_capacity_data"] = capacity_data["inventory_capacity_data"]
            warehouse_table = _read_inventory_warehouse_table_from_excel(excel_path)
            if warehouse_table:
                context["inventory_warehouse_table"] = warehouse_table["inventory_warehouse_table"]
            returns_region = _read_returns_region_table_from_excel(excel_path)
            if returns_region:
                context["returns_region_table"] = returns_region["returns_region_table"]
        context.setdefault("inbound_kpi", INBOUND_DEFAULT_KPI.copy())
        context.setdefault("pending_shipments", list(INBOUND_DEFAULT_PENDING_SHIPMENTS))
        context.setdefault(
            "outbound_kpi",
            {
                "released_orders": 146,
                "picked_orders": 120,
                "pod_compliance_pct": 94,
                "insight_text": "Delays mainly caused by transportation issues or customer confirmation.",
            },
        )
        context.setdefault("outbound_chart_data", DASHBOARD_DEFAULT_CHART_DATA["outbound_chart_data"].copy())
        context.setdefault(
            "pod_compliance_chart_data",
            {
                "categories": ["Jan", "Feb", "Mar", "Apr", "May", "Jun"],
                "series": [
                    {"name": "On Time", "data": [70, 72, 68, 75, 74, 78]},
                    {"name": "Pending", "data": [15, 14, 18, 12, 13, 10]},
                    {"name": "Late", "data": [15, 14, 14, 13, 13, 12]},
                ],
            },
        )
        context.setdefault("returns_kpi", {"total_skus": 2538, "total_lpns": 4810})
        context.setdefault("returns_chart_data", DASHBOARD_DEFAULT_CHART_DATA["returns_chart_data"].copy())
        context.setdefault(
            "returns_region_table",
            [
                {"region": "Main warehouse", "skus": "2,538", "available": "1118", "utilization_pct": "71%"},
                {"region": "Dammam DC", "skus": "501", "available": "200", "utilization_pct": "â€”"},
                {"region": "Riyadh DC", "skus": "3,996", "available": "209", "utilization_pct": "â€”"},
                {"region": "Jeddah DC", "skus": "7,996", "available": "300", "utilization_pct": "â€”"},
            ],
        )
        context.setdefault("inventory_kpi", {"total_skus": 2538, "total_lpns": 4810, "utilization_pct": "78"})
        context.setdefault("inventory_capacity_data", DASHBOARD_DEFAULT_CHART_DATA["inventory_capacity_data"].copy())
        context.setdefault(
            "inventory_warehouse_table",
            [
                {"warehouse": "Main Warehouse", "skus": "117", "available_space": "9,536,995", "utilization_pct": "223"},
                {"warehouse": "Dammam DC", "skus": "108", "available_space": "9,260,995", "utilization_pct": "553"},
                {"warehouse": "Riyadh DC", "skus": "145", "available_space": "9,827,955", "utilization_pct": "535"},
                {"warehouse": "Jeddah DC", "skus": "159", "available_space": "5,324,353", "utilization_pct": "279"},
            ],
        )
        # Override with DB models if available (Region, WarehouseMetric)
        regions_from_db = context_helpers.get_regions_table_from_db()
        if regions_from_db:
            context["returns_region_table"] = regions_from_db
        warehouse_metrics_from_db = context_helpers.get_warehouse_metrics_table_from_db()
        if warehouse_metrics_from_db:
            context["inventory_warehouse_table"] = warehouse_metrics_from_db
        context["dashboard_theme"] = context_helpers.get_dashboard_theme_dict()
        return context

    def dashboard_tab(self, request):
        """
        ğŸ”¹ ØªØ§Ø¨ Dashboard: ÙŠØ¹Ø±Ø¶ ØªØµÙ…ÙŠÙ… Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ (container-fluid-dashboard).
        Ø§Ù„ØªÙ…Ø¨Ù„Øª Ù…Ù†ÙØµÙ„ Ø¹Ù† excel-sheet-table ÙˆÙŠÙØ­Ù…Ù‘Ù„ Ø¯Ø§Ø®Ù„ Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¹Ù†Ø¯ Ø§Ø®ØªÙŠØ§Ø± ØªØ§Ø¨ Dashboard.
        Ù†ÙØ³ ÙÙƒØ±Ø© rejection: Ù†Ø±Ø¬Ø¹ detail_html + chart_data + chart_title Ø¹Ø´Ø§Ù† Ø§Ù„Ø´Ø§Ø±ØªØ§Øª ØªØ¨Ù‚Ù‰ Ø¯ÙŠÙ†Ø§Ù…Ùƒ.
        """
        try:
            context = self._get_dashboard_include_context(request)
            html = render_to_string(
                "container-fluid-dashboard.html",
                context,
                request=request,
            )
            # Ù†ÙØ³ Ø´ÙƒÙ„ Ø§Ù„Ù€ rejection: chart_data Ùˆ chart_title Ù„Ù„Ø´Ø§Ø±ØªØ§Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…Ùƒ
            outbound_chart = context.get("outbound_chart_data")
            chart_data = []
            if outbound_chart and isinstance(outbound_chart, dict):
                categories = outbound_chart.get("categories", [])
                series = outbound_chart.get("series", [])
                if categories and series is not None:
                    chart_data.append({
                        "type": "line",
                        "name": "POD Compliance",
                        "dataPoints": [{"label": c, "y": float(s)} for c, s in zip(categories, series)],
                    })
            return {
                "detail_html": html,
                "chart_data": chart_data,
                "chart_title": "Dashboard â€“ POD Compliance",
                "dashboard_charts": {
                    "outbound": context.get("outbound_chart_data"),
                    "returns": context.get("returns_chart_data"),
                    "inventory": context.get("inventory_capacity_data"),
                },
            }
        except Exception as e:
            import traceback

            traceback.print_exc()
            return {"error": f"An error occurred while loading Dashboard: {e}"}

    def warehouse_tab(self, request):
        """
        ğŸ”¹ ØªØ§Ø¨ Warehouse ÙÙ‚Ø·: ÙŠØ¹Ø±Ø¶ ÙƒØ±ÙˆØª Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹Ø§Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒ Ù…Ù† Ø§Ù„Ø£Ø¯Ù…Ù†.
        ÙƒÙ„ Ù…Ø³ØªÙˆØ¯Ø¹ Ù…Ø¶Ø§Ù ÙÙŠ Ø§Ù„Ø£Ø¯Ù…Ù† = ÙƒØ§Ø±Ø¯ ÙˆØ§Ø­Ø¯ ÙÙŠ Ø§Ù„ØµÙØ­Ø©.
        """
        try:
            warehouse_overview = context_helpers.get_warehouse_overview_list()
            clerk_interview_rows = context_helpers.get_clerk_interview_list()
            dashboard_theme = context_helpers.get_dashboard_theme_dict()
            phases_sections = context_helpers.get_phases_sections_list()
            html = render_to_string(
                "components/ui-kits/tab-bootstrap/components/warehouse-cards.html",
                {
                    "warehouse_overview": warehouse_overview,
                    "clerk_interview_rows": clerk_interview_rows,
                    "dashboard_theme": dashboard_theme,
                    "phases_sections": phases_sections,
                },
                request=request,
            )
            return {"detail_html": html}
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {"error": str(e), "detail_html": f"<div class='alert alert-danger'>âš ï¸ {e}</div>"}

    def meeting_points_tab(self, request):
        """
        ğŸ”¹ Ø¹Ø±Ø¶ ØªØ§Ø¨ Meeting Points & Action Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ù„Ø© (Ù…Ù†ØªÙ‡ÙŠØ© / ØºÙŠØ± Ù…Ù†ØªÙ‡ÙŠØ©)
        """
        if not request.session.get("meeting_points_unlocked"):
            return JsonResponse({"require_password": True})
        try:
            # âœ… Ø¬Ù„Ø¨ Ø§Ù„Ø­Ø§Ù„Ø© Ù…Ù† Ø§Ù„Ù€ GET parameter
            status_filter = request.GET.get(
                "status"
            )  # Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ù…ÙƒÙ†Ø©: done / pending / all

            # âœ… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ ÙƒÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨
            meeting_points = MeetingPoint.objects.all().order_by(
                "is_done", "-created_at"
            )

            # âœ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§Ù„Ø©
            if status_filter == "done":
                meeting_points = meeting_points.filter(is_done=True)
            elif status_filter == "pending":
                meeting_points = meeting_points.filter(is_done=False)
            # 'all' ÙŠØ¹Ø±Ø¶ ÙƒÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· (done + pending)
            # Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„ÙÙ„ØªØ±Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ø£Ù†Ù‡ Ø§Ø³ØªØ±Ø¬Ø¹Ù†Ø§ ÙƒÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©

            # âœ… Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            done_count = meeting_points.filter(is_done=True).count()
            total_count = meeting_points.count()

            # âœ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªÙ…Ø¨Ù„Øª Ù…Ø¹ assigned_to
            meeting_data = [
                {
                    "id": p.id,
                    "description": p.description,
                    "assigned_to": getattr(
                        p, "assigned_to", ""
                    ),  # âœ… Ø§Ù„Ø§Ø³Ù… Ù…Ù…ÙƒÙ† ÙŠÙƒÙˆÙ† ÙØ§Ø¶ÙŠ
                    "status": "Done" if p.is_done else "Pending",
                    "created_at": p.created_at,
                    "target_date": p.target_date,
                }
                for p in meeting_points
            ]

            context = {
                "meeting_points": meeting_points,
                "meeting_data": meeting_data,  # Ù„Ùˆ Ø­Ø§Ø¨Ø© ØªØ³ØªØ®Ø¯Ù…ÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙŠ JS
                "done_count": done_count,
                "total_count": total_count,
                "status_filter": status_filter,
            }

            # âœ… Ø¨Ù†Ø§Ø¡ HTML Ù…Ù† Ø§Ù„ØªÙ…Ø¨Ù„Øª
            html = render_to_string("meeting_points.html", context, request=request)

            # âœ… Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø©
            return JsonResponse(
                {
                    "detail_html": html,
                    "count": meeting_points.count(),
                    "done_count": done_count,
                    "total_count": total_count,
                },
                safe=False,
            )

        except Exception as e:
            import traceback

            traceback.print_exc()
            return JsonResponse(
                {"error": f"An error occurred while loading data: {e}"}, status=500
            )

    def project_tracker_tab(self, request):
        """ØªØ§Ø¨ Project Tracker: Ø¹Ø±Ø¶ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø£Ø¯Ù…Ù† (project_tracker_items)."""
        try:
            pt_filter = (request.GET.get("project_type") or "").strip().lower()
            if pt_filter not in ("idea", "automation"):
                pt_filter = None
            project_tracker_items = context_helpers.get_project_tracker_list(project_type=pt_filter)
            html = render_to_string(
                "components/ui-kits/tab-bootstrap/components/project-tracker-cards.html",
                {"project_tracker_items": project_tracker_items},
                request=request,
            )
            return {"detail_html": html}
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {"error": str(e), "detail_html": f"<div class='alert alert-danger'>âš ï¸ {e}</div>"}


def meeting_points_unlock(request):
    """
    ÙÙƒ Ù‚ÙÙ„ ØªØ§Ø¨ Meeting Points & Actions Ø¨Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„ØµØ­ÙŠØ­Ø©.
    ÙŠØ®Ø²Ù† ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø© Ø­ØªÙ‰ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…ØªØµÙØ­.
    """
    if request.method != "POST":
        return JsonResponse({"ok": False, "message": "Method not allowed"}, status=405)
    password = request.POST.get("password", "").strip()
    if not password:
        try:
            body = json.loads(request.body) if request.body else {}
            password = (body.get("password") or "").strip()
        except (ValueError, TypeError):
            pass
    if not password:
        return JsonResponse({"ok": False, "message": "Password required"}, status=400)
    expected = getattr(settings, "MEETING_POINTS_TAB_PASSWORD", None)
    if not expected:
        return JsonResponse({"ok": False, "message": "Not configured"}, status=500)
    if password != expected:
        return JsonResponse({"ok": False, "message": "Wrong password"}, status=400)
    request.session["meeting_points_unlocked"] = True
    return JsonResponse({"ok": True})


class MeetingPointListCreateView(View):
    template_name = "meeting_points.html"

    def get(self, request, *args, **kwargs):
        status_filter = request.GET.get("status")  # "done" Ø£Ùˆ "pending" Ø£Ùˆ None

        today = date.today()
        current_month, current_year = today.month, today.year

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚
        if current_month == 1:
            prev_month = 12
            prev_year = current_year - 1
        else:
            prev_month = current_month - 1
            prev_year = current_year

        # âœ… Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· (Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ ÙƒÙ„Ù‡ + pending Ù…Ù† Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚)
        meeting_points = MeetingPoint.objects.filter(
            Q(created_at__year=current_year, created_at__month=current_month)
            | Q(created_at__year=prev_year, created_at__month=prev_month, is_done=False)
        ).order_by("is_done", "-created_at")

        # âœ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ± Ù„Ùˆ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ø®ØªØ§Ø± Ø­Ø§Ø¬Ø©
        if status_filter == "done":
            meeting_points = meeting_points.filter(is_done=True)
        elif status_filter == "pending":
            meeting_points = meeting_points.filter(is_done=False)

        done_count = meeting_points.filter(is_done=True).count()
        total_count = meeting_points.count()

        return render(
            request,
            self.template_name,
            {
                "meeting_points": meeting_points,
                "done_count": done_count,
                "total_count": total_count,
                "status_filter": status_filter,
            },
        )

    def post(self, request, *args, **kwargs):
        description = request.POST.get("description", "").strip()
        target_date = request.POST.get("target_date", "").strip() or None
        assigned_to = request.POST.get("assigned_to", "").strip() or None

        if description:
            point = MeetingPoint.objects.create(
                description=description,
                target_date=target_date,
                assigned_to=assigned_to if assigned_to else None,
            )

            return JsonResponse(
                {
                    "id": point.id,
                    "description": point.description,
                    "assigned_to": point.assigned_to,
                    "created_at": str(point.created_at),
                    "target_date": str(point.target_date),
                    "is_done": point.is_done,
                }
            )

        return JsonResponse({"error": "Empty description"}, status=400)


class ToggleMeetingPointView(View):
    def post(self, request, pk, *args, **kwargs):
        point = get_object_or_404(MeetingPoint, pk=pk)
        point.is_done = not point.is_done
        point.save()
        return JsonResponse({"is_done": point.is_done})


class DoneMeetingPointView(View):
    def post(self, request, pk, *args, **kwargs):
        point = get_object_or_404(MeetingPoint, pk=pk)
        point.is_done = not point.is_done
        point.save()
        return JsonResponse({"is_done": point.is_done})
